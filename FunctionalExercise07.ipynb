{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate method for Exercise 7\n",
    "\n",
    "In this document I will try to show how the use of functional methods can make data analysis approachable and understandable while increasing the possible performance in various ways. This neccessiataes a fundamental shift in how the analysis is designed in terms of program structure. This however does not sacrifice any functionality in terms of possible analyses methods in comparison with the widely used object oriented method of writing Analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary directories present.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import itertools as itt\n",
    "from include.RandomHelper import check_data_state\n",
    "check_data_state(directory=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first step the data should be read in. This is done with the pandas module, a third party data analysis framework for python. The data is read into a `dataframe` object that is defined by the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import itertools as itt\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Background simulation\n",
    "bkgnd_sim_file_1 = \"./data/for_long_analysis/mc_init/MC_2012_ZZ_to_4L_2el2mu.csv\"\n",
    "bkgnd_sim_file_2 = \"./data/for_long_analysis/mc_init/MC_2012_ZZ_to_4L_4mu.csv\"\n",
    "bkgnd_sim_file_3 = \"./data/for_long_analysis/mc_init/MC_2012_ZZ_to_4L_4el.csv\"\n",
    "\n",
    "# Signal simulation\n",
    "sig_sim_file_1 = \"./data/for_long_analysis/mc_init/MC_2012_H_to_ZZ_to_4L_2el2mu.csv\"\n",
    "sig_sim_file_2 = \"./data/for_long_analysis/mc_init/MC_2012_H_to_ZZ_to_4L_4mu.csv\"\n",
    "sig_sim_file_3 = \"./data/for_long_analysis/mc_init/MC_2012_H_to_ZZ_to_4L_4el.csv\"\n",
    "\n",
    "bkgnd_sim_2el2mu = pd.read_csv(bkgnd_sim_file_1, delimiter=\";\")\n",
    "bkgnd_sim_4mu = pd.read_csv(bkgnd_sim_file_2, delimiter=\";\")\n",
    "bkgnd_sim_4el = pd.read_csv(bkgnd_sim_file_3, delimiter=\";\")\n",
    "sig_sim_2el2mu = pd.read_csv(sig_sim_file_1, delimiter=';')\n",
    "sig_sim_4mu = pd.read_csv(sig_sim_file_2, delimiter=';')\n",
    "sig_sim_4el = pd.read_csv(sig_sim_file_3, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the data\n",
    "The data described here is data generated by mote-carlo event generators and is split into background and signal simulation. To optimize our analysis we will use the monte-carlo data to make sure that the analysis is not artificially tuned to find a peak in the real data but only find a peak that we put there (in the simulation). If the peak is not there in the data we can be sure that our analysis would have picked it up and therefore can say if there was a peak at the predicted location or not without having to worry about if the analysis was skewed to find the peak because you thought there ought to be one and then made the analysis to produce data to fit your conclusion.\n",
    "\n",
    "The pandas dataframes that we loaded currently only describe the background (the background that we expect according to the predictions of the standard model). More precicely they describe the background that is expected in the 2e2mu channel. the other dataframe de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's examine the data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>muon_energy</th>\n",
       "      <th>muon_px</th>\n",
       "      <th>muon_py</th>\n",
       "      <th>muon_pz</th>\n",
       "      <th>muon_charge</th>\n",
       "      <th>muon_relPFIso</th>\n",
       "      <th>muon_dxy</th>\n",
       "      <th>muon_dz</th>\n",
       "      <th>muon_SIP3d</th>\n",
       "      <th>electron_energy</th>\n",
       "      <th>electron_px</th>\n",
       "      <th>electron_py</th>\n",
       "      <th>electron_pz</th>\n",
       "      <th>electron_charge</th>\n",
       "      <th>electron_relPFIso</th>\n",
       "      <th>electron_dxy</th>\n",
       "      <th>electron_dz</th>\n",
       "      <th>electron_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846714</td>\n",
       "      <td>2823</td>\n",
       "      <td>55.3949,35.6495</td>\n",
       "      <td>-48.399,31.2184</td>\n",
       "      <td>24.7739,-15.0449</td>\n",
       "      <td>-10.6009,8.36253</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.0209805,0.0524248</td>\n",
       "      <td>-0.00105939,-0.00198611</td>\n",
       "      <td>0.00580479,-0.000121758</td>\n",
       "      <td>1.6412,0.661312</td>\n",
       "      <td>254.196,36.8009</td>\n",
       "      <td>18.0862,-12.0845</td>\n",
       "      <td>-48.5142,24.8936</td>\n",
       "      <td>-248.867,-24.2607</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.0250167,0.0712457</td>\n",
       "      <td>-0.0028464,0.000602746</td>\n",
       "      <td>-0.00391345,0.00170042</td>\n",
       "      <td>0.47657,0.431616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846715</td>\n",
       "      <td>2823</td>\n",
       "      <td>46.227,17.1694</td>\n",
       "      <td>-2.8323,11.2507</td>\n",
       "      <td>-13.9613,-1.2918</td>\n",
       "      <td>-43.9771,-12.9046</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.191416,0.17468</td>\n",
       "      <td>0.00761235,-0.000309401</td>\n",
       "      <td>-0.00194986,0.00129964</td>\n",
       "      <td>0.946415,0.308535</td>\n",
       "      <td>82.9044,11.4583</td>\n",
       "      <td>1.71208,-8.54741</td>\n",
       "      <td>28.2926,2.83502</td>\n",
       "      <td>-77.9085,7.08491</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.15352,0.515702</td>\n",
       "      <td>-0.00206888,0.00300649</td>\n",
       "      <td>-0.00538221,7.12868e-05</td>\n",
       "      <td>0.937364,0.413622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846723</td>\n",
       "      <td>2823</td>\n",
       "      <td>19.461,10.3101</td>\n",
       "      <td>11.2609,9.16698</td>\n",
       "      <td>-10.3577,-2.32848</td>\n",
       "      <td>-12.0261,4.10262</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.155083,0.221734</td>\n",
       "      <td>0.000703356,0.00115165</td>\n",
       "      <td>0.000846168,-0.00065684</td>\n",
       "      <td>0.296126,0.240591</td>\n",
       "      <td>42.9922,71.6306</td>\n",
       "      <td>-16.5883,5.92063</td>\n",
       "      <td>38.9813,-30.8763</td>\n",
       "      <td>-7.32215,-64.3627</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.103053,0.0723279</td>\n",
       "      <td>-0.000581222,-0.023985</td>\n",
       "      <td>0.00161887,0.0172354</td>\n",
       "      <td>0.369838,4.44646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846753</td>\n",
       "      <td>2823</td>\n",
       "      <td>8.09622,7.72517</td>\n",
       "      <td>0.0821112,-2.40281</td>\n",
       "      <td>6.51906,-6.02051</td>\n",
       "      <td>4.79925,4.20085</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.216925,0.41674</td>\n",
       "      <td>0.000483781,-0.00335737</td>\n",
       "      <td>-0.00433865,-0.00260739</td>\n",
       "      <td>0.973179,0.868803</td>\n",
       "      <td>39.5647,98.4103</td>\n",
       "      <td>35.2052,-31.9606</td>\n",
       "      <td>18.029,-9.41048</td>\n",
       "      <td>0.956613,92.5988</td>\n",
       "      <td>1,-1</td>\n",
       "      <td>0.1432,0.049916</td>\n",
       "      <td>0.00165894,-0.000320531</td>\n",
       "      <td>0.0132108,0.00052476</td>\n",
       "      <td>1.92044,0.0866598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846763</td>\n",
       "      <td>2823</td>\n",
       "      <td>71.6791,80.8522</td>\n",
       "      <td>64.102,25.6134</td>\n",
       "      <td>-26.1167,41.6729</td>\n",
       "      <td>18.6209,64.3769</td>\n",
       "      <td>1,-1</td>\n",
       "      <td>0.014919,0.013307</td>\n",
       "      <td>-0.000143862,-0.000591512</td>\n",
       "      <td>-0.00487695,0.00341611</td>\n",
       "      <td>1.44616,0.757034</td>\n",
       "      <td>81.314,11.1153</td>\n",
       "      <td>-78.6539,-10.3513</td>\n",
       "      <td>-11.2899,-3.73267</td>\n",
       "      <td>17.2646,-1.57127</td>\n",
       "      <td>1,-1</td>\n",
       "      <td>0.0136104,0.250511</td>\n",
       "      <td>-0.000410155,-0.00214753</td>\n",
       "      <td>0.00174084,-0.00185153</td>\n",
       "      <td>0.465797,0.454134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run   event  luminosity_section      muon_energy             muon_px  \\\n",
       "0  194533.0  846714                2823  55.3949,35.6495     -48.399,31.2184   \n",
       "1  194533.0  846715                2823   46.227,17.1694     -2.8323,11.2507   \n",
       "2  194533.0  846723                2823   19.461,10.3101     11.2609,9.16698   \n",
       "3  194533.0  846753                2823  8.09622,7.72517  0.0821112,-2.40281   \n",
       "4  194533.0  846763                2823  71.6791,80.8522      64.102,25.6134   \n",
       "\n",
       "             muon_py            muon_pz muon_charge        muon_relPFIso  \\\n",
       "0   24.7739,-15.0449   -10.6009,8.36253        -1,1  0.0209805,0.0524248   \n",
       "1   -13.9613,-1.2918  -43.9771,-12.9046        -1,1     0.191416,0.17468   \n",
       "2  -10.3577,-2.32848   -12.0261,4.10262        -1,1    0.155083,0.221734   \n",
       "3   6.51906,-6.02051    4.79925,4.20085        -1,1     0.216925,0.41674   \n",
       "4   -26.1167,41.6729    18.6209,64.3769        1,-1    0.014919,0.013307   \n",
       "\n",
       "                    muon_dxy                  muon_dz         muon_SIP3d  \\\n",
       "0    -0.00105939,-0.00198611  0.00580479,-0.000121758    1.6412,0.661312   \n",
       "1    0.00761235,-0.000309401   -0.00194986,0.00129964  0.946415,0.308535   \n",
       "2     0.000703356,0.00115165  0.000846168,-0.00065684  0.296126,0.240591   \n",
       "3    0.000483781,-0.00335737  -0.00433865,-0.00260739  0.973179,0.868803   \n",
       "4  -0.000143862,-0.000591512   -0.00487695,0.00341611   1.44616,0.757034   \n",
       "\n",
       "   electron_energy        electron_px        electron_py        electron_pz  \\\n",
       "0  254.196,36.8009   18.0862,-12.0845   -48.5142,24.8936  -248.867,-24.2607   \n",
       "1  82.9044,11.4583   1.71208,-8.54741    28.2926,2.83502   -77.9085,7.08491   \n",
       "2  42.9922,71.6306   -16.5883,5.92063   38.9813,-30.8763  -7.32215,-64.3627   \n",
       "3  39.5647,98.4103   35.2052,-31.9606    18.029,-9.41048   0.956613,92.5988   \n",
       "4   81.314,11.1153  -78.6539,-10.3513  -11.2899,-3.73267   17.2646,-1.57127   \n",
       "\n",
       "  electron_charge    electron_relPFIso              electron_dxy  \\\n",
       "0            -1,1  0.0250167,0.0712457    -0.0028464,0.000602746   \n",
       "1            -1,1     0.15352,0.515702    -0.00206888,0.00300649   \n",
       "2            -1,1   0.103053,0.0723279    -0.000581222,-0.023985   \n",
       "3            1,-1      0.1432,0.049916   0.00165894,-0.000320531   \n",
       "4            1,-1   0.0136104,0.250511  -0.000410155,-0.00214753   \n",
       "\n",
       "               electron_dz     electron_SIP3d  \n",
       "0   -0.00391345,0.00170042   0.47657,0.431616  \n",
       "1  -0.00538221,7.12868e-05  0.937364,0.413622  \n",
       "2     0.00161887,0.0172354   0.369838,4.44646  \n",
       "3     0.0132108,0.00052476  1.92044,0.0866598  \n",
       "4   0.00174084,-0.00185153  0.465797,0.454134  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_2el2mu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>muon_energy</th>\n",
       "      <th>muon_px</th>\n",
       "      <th>muon_py</th>\n",
       "      <th>muon_pz</th>\n",
       "      <th>muon_charge</th>\n",
       "      <th>muon_relPFIso</th>\n",
       "      <th>muon_dxy</th>\n",
       "      <th>muon_dz</th>\n",
       "      <th>muon_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142211</td>\n",
       "      <td>3809</td>\n",
       "      <td>52.8881,104.397,29.9594,60.5544</td>\n",
       "      <td>-49.2137,16.0997,24.2971,14.3324</td>\n",
       "      <td>0.527564,-27.1821,11.0576,-1.76615</td>\n",
       "      <td>-19.3616,99.5022,-13.599,58.8072</td>\n",
       "      <td>1,-1,-1,1</td>\n",
       "      <td>0.0296542,0,0.0445055,0</td>\n",
       "      <td>-0.000377091,-0.000857253,0.00163948,-0.00102962</td>\n",
       "      <td>-0.000987451,0.00553847,0.000673754,-0.00563673</td>\n",
       "      <td>0.341185,1.17472,0.74423,0.727535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142219</td>\n",
       "      <td>3809</td>\n",
       "      <td>113.521,30.6528,11.4094,9.06379</td>\n",
       "      <td>37.3417,-30.5574,-3.5702,-7.26697</td>\n",
       "      <td>-15.5895,2.03743,8.37685,-2.60909</td>\n",
       "      <td>106.064,-1.29509,-6.87345,-4.74604</td>\n",
       "      <td>-1,1,1,-1</td>\n",
       "      <td>0.0125911,0.0117654,0.0899817,0.248405</td>\n",
       "      <td>0.000726053,-0.000136719,0.00150134,-0.00245663</td>\n",
       "      <td>-0.00287983,-0.000185169,0.00946114,0.00240733</td>\n",
       "      <td>0.441156,0.103343,1.74382,0.729126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142220</td>\n",
       "      <td>3809</td>\n",
       "      <td>37.5417,32.4731,12.4247,10.6322</td>\n",
       "      <td>-2.73565,7.73404,-6.42318,-4.64318</td>\n",
       "      <td>-32.3749,29.0231,10.0461,9.51578</td>\n",
       "      <td>-18.8082,12.3425,3.49,-0.961091</td>\n",
       "      <td>-1,1,-1,1</td>\n",
       "      <td>0.055162,0.188471,0.100481,0.0632636</td>\n",
       "      <td>0.000818172,0.00046863,0.00134882,-0.00210051</td>\n",
       "      <td>0.000417443,0.00251968,-0.00210166,0.00386756</td>\n",
       "      <td>0.284802,0.838615,0.697662,0.928048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142228</td>\n",
       "      <td>3809</td>\n",
       "      <td>264.068,79.0522,66.5292,86.7354</td>\n",
       "      <td>99.6408,-69.2727,-1.5023,-1.36519</td>\n",
       "      <td>-14.9597,13.4225,36.1747,-25.441</td>\n",
       "      <td>244.09,35.6422,55.8145,82.9091</td>\n",
       "      <td>1,1,-1,-1</td>\n",
       "      <td>0.0194944,0.023523,0.051396,0.0</td>\n",
       "      <td>-0.000898767,-0.000213138,-0.00100135,0.00651469</td>\n",
       "      <td>0.00257914,-0.00103711,-0.00125057,-0.0108969</td>\n",
       "      <td>0.617079,0.401096,0.416188,1.9014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142229</td>\n",
       "      <td>3809</td>\n",
       "      <td>56.8948,40.0339,28.6141,21.4495</td>\n",
       "      <td>27.7498,-24.7057,9.16045,-5.26999</td>\n",
       "      <td>-28.8856,18.0678,8.47077,6.4065</td>\n",
       "      <td>40.4052,25.8047,25.7505,19.7801</td>\n",
       "      <td>-1,1,-1,1</td>\n",
       "      <td>0,0.00768358,0.0969734,0</td>\n",
       "      <td>-0.000252906,-0.000368003,0.00109531,0.000284646</td>\n",
       "      <td>-0.00435722,0.00268917,-0.000446212,0.00316748</td>\n",
       "      <td>1.24902,0.757682,0.208022,0.445693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run    event  luminosity_section                      muon_energy  \\\n",
       "0  194533.0  1142211                3809  52.8881,104.397,29.9594,60.5544   \n",
       "1  194533.0  1142219                3809  113.521,30.6528,11.4094,9.06379   \n",
       "2  194533.0  1142220                3809  37.5417,32.4731,12.4247,10.6322   \n",
       "3  194533.0  1142228                3809  264.068,79.0522,66.5292,86.7354   \n",
       "4  194533.0  1142229                3809  56.8948,40.0339,28.6141,21.4495   \n",
       "\n",
       "                              muon_px                             muon_py  \\\n",
       "0    -49.2137,16.0997,24.2971,14.3324  0.527564,-27.1821,11.0576,-1.76615   \n",
       "1   37.3417,-30.5574,-3.5702,-7.26697   -15.5895,2.03743,8.37685,-2.60909   \n",
       "2  -2.73565,7.73404,-6.42318,-4.64318    -32.3749,29.0231,10.0461,9.51578   \n",
       "3   99.6408,-69.2727,-1.5023,-1.36519    -14.9597,13.4225,36.1747,-25.441   \n",
       "4   27.7498,-24.7057,9.16045,-5.26999     -28.8856,18.0678,8.47077,6.4065   \n",
       "\n",
       "                              muon_pz muon_charge  \\\n",
       "0    -19.3616,99.5022,-13.599,58.8072   1,-1,-1,1   \n",
       "1  106.064,-1.29509,-6.87345,-4.74604   -1,1,1,-1   \n",
       "2     -18.8082,12.3425,3.49,-0.961091   -1,1,-1,1   \n",
       "3      244.09,35.6422,55.8145,82.9091   1,1,-1,-1   \n",
       "4     40.4052,25.8047,25.7505,19.7801   -1,1,-1,1   \n",
       "\n",
       "                            muon_relPFIso  \\\n",
       "0                 0.0296542,0,0.0445055,0   \n",
       "1  0.0125911,0.0117654,0.0899817,0.248405   \n",
       "2    0.055162,0.188471,0.100481,0.0632636   \n",
       "3         0.0194944,0.023523,0.051396,0.0   \n",
       "4                0,0.00768358,0.0969734,0   \n",
       "\n",
       "                                           muon_dxy  \\\n",
       "0  -0.000377091,-0.000857253,0.00163948,-0.00102962   \n",
       "1   0.000726053,-0.000136719,0.00150134,-0.00245663   \n",
       "2     0.000818172,0.00046863,0.00134882,-0.00210051   \n",
       "3  -0.000898767,-0.000213138,-0.00100135,0.00651469   \n",
       "4  -0.000252906,-0.000368003,0.00109531,0.000284646   \n",
       "\n",
       "                                           muon_dz  \\\n",
       "0  -0.000987451,0.00553847,0.000673754,-0.00563673   \n",
       "1   -0.00287983,-0.000185169,0.00946114,0.00240733   \n",
       "2    0.000417443,0.00251968,-0.00210166,0.00386756   \n",
       "3    0.00257914,-0.00103711,-0.00125057,-0.0108969   \n",
       "4   -0.00435722,0.00268917,-0.000446212,0.00316748   \n",
       "\n",
       "                            muon_SIP3d  \n",
       "0    0.341185,1.17472,0.74423,0.727535  \n",
       "1   0.441156,0.103343,1.74382,0.729126  \n",
       "2  0.284802,0.838615,0.697662,0.928048  \n",
       "3    0.617079,0.401096,0.416188,1.9014  \n",
       "4   1.24902,0.757682,0.208022,0.445693  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_4mu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bkgnd_sim_2el2mu['muon_energy'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the some columns have been parsed as strings. We need to fix that and convert the strings to lists of floating point numbers. Depending on a few things there are (more or less) two approaches that can be used to perform this step and all further steps of the data processing.\n",
    "1. The first method is using a functional programming style. This means that as a first step a set of functions are applied that act on one single event, taking in the entire event, somehow modifying it and then returning that modified event. These functions will then be used with pythons internal filter and map methods. This is a data-flow centric approach where, using map and filter, the functions are combined into a data pipeline and then the data is fed through the pipeline. It uses iterators as central objects for the creation of the pipeline that then feed the data through one element at a time. This document will focus on the this first approach.\n",
    "\n",
    "2. The second method is an approach that is more like a spreadsheet. The original data is still kept and if a quantity needs to be calculated or some subset of the data needs to be altered for each and every event (such as the parsing of the string into an array of floats) then either a column is modified or a new column is added to the table. Further more the data in the table can be aggregated in various ways to \"answer questions about the data\" (that was using data science speak). This approach does not really think about \"flows\" of data but treats everything like a giant spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The functional / data-flow approach\n",
    "---\n",
    "So for this part I will demonstrate the data-flow approach using python iterators and the filter/map functions from python's core\n",
    "\n",
    "First of all we need to transform the data of the pandas dataframe into an iterator so that we can apply all further operations using map and filter (and a few other neat functions that are provided in the `itertools` module of the python standard library (these are a few functions that do neat things with iterators))\n",
    "\n",
    "But you legitamely might be asking what an iterator actually is. And the technical answer to that question is:\n",
    "\n",
    ">An iterator is something you can call next() on as in `next(something)`. By definition that something is an iterator\n",
    "\n",
    "Let me note that `next()` is not an attribute call here but an [built in function](https://docs.python.org/3/library/functions.html) of python. This is part of what makes iterators somewhat special in python.\n",
    "\n",
    "In less technical terms, an iterator is something that can produce a value of a certain structure (or type more precicely). That means if we have the iterator `something` and `next(something)` produces a `tuple(int, float, str)` then any subsequent calls should produce a `tuple(int, float, str)`. I say should here because there are exceptions to this but that will not be discussed here. If the iterator can't return anything anymore it raises the `StopIteration` exception, which essentially signals to the pipeline that no more data is coming.\n",
    "\n",
    "Iterators are essentially abstractions of lists. And sure enough a list in python is an iterator (anthing that can be used in a `for` loop is an iterator because 'under the hood' the for loop goes through an iterator one by one and applies whatever is specified in the for loop to each item it gets from the iterator. The difference is that iterators don't neccesarily need to be lists, they just need to know how to produce the next item.\n",
    "\n",
    "Let's look at a typical thing that python newcomers tend to write:\n",
    "\n",
    "```python\n",
    "data = [1, 2, 3, 4, 5, 6]\n",
    "for i in range(len(data)):\n",
    "    data[i] += 4\n",
    "```\n",
    "Now we could think that `range(len(data))` is a list but it is not, as discussed it is an iterator. because range knows when to stop and how to generate the next item from the current one (in this case it adds `1` to the current count) and returns it when `next()` is called on it.\n",
    "\n",
    "A similar thing can be done for random numbers, instead of fillig an array with random numbers an iterator can be used because the function that generates the random numbers must allways know how to generate the next random number from some internal state. So we could generate the next number exactly and only when we need it. This eliminates the need to keep massive amounts of random numbers in the main memory and makes programs a lot more recource efficient (with some caveats I won't go into). Essentially the only thing we need to be able to do is somehow 'pause' the random number function right after generating a random number and hit the proverbial 'play' button as soon as we want the next number and hit 'pause' again right after the number was generated. This way of writing a function has already been done for many things in python so I won't go into it here [they are called 'generators' just fyi](https://docs.python.org/3/glossary.html#term-generator).\n",
    "\n",
    "For more information you can also read [this document on functional programming in python](https://docs.python.org/3/howto/functional.html)\n",
    "\n",
    "The thing this enables is to wrap iterators around each other and we will allways get back an interator. This is what the `map` and `filter` methods do.\n",
    "Let's look at what happens when we have an example iterator (I'll use a simple list here as the iterator but it can easily be something different as long as it is an iterator) that returns a tuple of 3 numbers and that is wrapped with some map and filter methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x7fd656d30f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_first_two_nums(elem):\n",
    "    return (elem[0], elem[1], elem[2], elem[0]+elem[1])\n",
    "\n",
    "def sum_over_10(elem):\n",
    "    return True if elem[3] > 10 else False\n",
    "   \n",
    "def sub_3rd_from_1st(elem):\n",
    "    return (elem[0], elem[1], elem[2], elem[3], elem[0]-elem[2])\n",
    "\n",
    "def negative_difference(elem):\n",
    "    return True if elem[4] < 0 else False\n",
    "\n",
    "data = [(1,2,3), (4,5,6), (7,8,9), (3,2,1), (6,5,4), (9,8,7), (15, 0, 2)]\n",
    "data1 = map(add_first_two_nums, data)\n",
    "filtered_data1 = filter(sum_over_10, data1)\n",
    "data2 = map(sub_3rd_from_1st, filtered_data1)\n",
    "filtered_data2 = filter(negative_difference, data2)\n",
    "filtered_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see `filtered_data2` is not a list of tuples, which I would have expected if I had not known better. As I said before what we have built here is an iterator, not the data. we can however call `next()` on `filtered_data2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 9, 15, -2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(filtered_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives an item and as we can see it has 5 numbers as part of it. The fourth element is the sum of the first two elements (just as we have specified) and the last element is the difference between the first and third element. We can also see that the third element is larger than 10 and the fourth element is negative so the data also satisfies all our criteria that we defined in the filters. It is also not the first element of the sequence but the first element of the list that satisfies all criteria that we applied.\n",
    "\n",
    "As this is a pipeline, the sequence of operations is important any element that does not satisfy the first requirement is dropped at the first filter so cant even reach the second filter so even if it would pass the requirements of the second filter it won't be shown (just as water in a stream that is used or diverted can't be used downstream of the point of diversion/use). This may be obvious but I wanted to point this out just in case.\n",
    "\n",
    "calling `next()` again will subsequently result in either the next element that satisfies the all filteres or in a `StopIteration` exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4306937be14d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(filtered_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is no further data that meets the requirements `next()` raises an exception of the aforementioned type.\n",
    "\n",
    "It is also important to note that iterators are 'consumed' i.e. once the `StopIteration` exeption was raised by an iterator it can no longer be used. This also applies to all iterators that are passed to a subsequent iterator. So in our case `filtered_data1` will also raise a `StopIteration` exception even though we have not called `next()` explicitly on it (`next()` was implicitly called by the `data2` iterator on which `next()` was implicitly called by the `filtered_data2` iterator which we explicitly called `next()` on).\n",
    "\n",
    "But just to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-aeb41227be58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(filtered_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as expected, we get an `StopIteration` exception.\n",
    "\n",
    "The [itertools](https://docs.python.org/3/library/itertools.html) module of the standard library has a few iterators that take on the role of various 'flow management' tasks like splitting an iterator into two iterators or repeating a variable a few times, accumulate things and other tasks. This module is really useful and is definitely better than building your own iterator for a problem. Remember all these iterators can be chained to make more complex iterators that can then be reused on different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets start with the actual task. First of as before, we need to parse all entries that are strings into numpy arrays. I say numpy arrays explicitly because I am planning to use the methods defined for numpy arrays. Before that however we need to transform the dataframe into an iterator over the rows (events) of the dataframe. Thankfully pandas already came with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataframe into an iterator\n",
    "data = bkgnd_sim_2el2mu.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " run                                    194533\n",
       " event                                  846714\n",
       " luminosity_section                       2823\n",
       " muon_energy                   55.3949,35.6495\n",
       " muon_px                       -48.399,31.2184\n",
       " muon_py                      24.7739,-15.0449\n",
       " muon_pz                      -10.6009,8.36253\n",
       " muon_charge                              -1,1\n",
       " muon_relPFIso             0.0209805,0.0524248\n",
       " muon_dxy              -0.00105939,-0.00198611\n",
       " muon_dz               0.00580479,-0.000121758\n",
       " muon_SIP3d                    1.6412,0.661312\n",
       " electron_energy               254.196,36.8009\n",
       " electron_px                  18.0862,-12.0845\n",
       " electron_py                  -48.5142,24.8936\n",
       " electron_pz                 -248.867,-24.2607\n",
       " electron_charge                          -1,1\n",
       " electron_relPFIso         0.0250167,0.0712457\n",
       " electron_dxy           -0.0028464,0.000602746\n",
       " electron_dz            -0.00391345,0.00170042\n",
       " electron_SIP3d               0.47657,0.431616\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here from the first event the object returned from the iterator is a tuple where the first entry is an int (the index of the row) and the secon d element is a series containing the entries of that row. We now need to parse everything that is a string into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that parses all strings into lists\n",
    "def parse_strings(event):\n",
    "    ed = event[1]\n",
    "    ed['muon_energy'] = np.array([float(e) for e in ed['muon_energy'].split(',') if e != ''])\n",
    "    ed['muon_px'] = np.array([float(e) for e in ed['muon_px'].split(',') if e != ''])\n",
    "    ed['muon_py'] = np.array([float(e) for e in ed['muon_py'].split(',') if e != ''])\n",
    "    ed['muon_pz'] = np.array([float(e) for e in ed['muon_pz'].split(',') if e != ''])\n",
    "    ed['muon_charge'] = np.array([float(e) for e in ed['muon_charge'].split(',') if e != ''])\n",
    "    ed['muon_relPFIso'] = np.array([float(e) for e in ed['muon_relPFIso'].split(',') if e != ''])\n",
    "    ed['muon_dxy'] = np.array([float(e) for e in ed['muon_dxy'].split(',') if e != ''])\n",
    "    ed['muon_dz'] = np.array([float(e) for e in ed['muon_dz'].split(',') if e != ''])\n",
    "    ed['muon_SIP3d'] = np.array([float(e) for e in ed['muon_SIP3d'].split(',') if e != ''])\n",
    "    ed['electron_energy'] = np.array([float(e) for e in ed['electron_energy'].split(',') if e != ''])\n",
    "    ed['electron_px'] = np.array([float(e) for e in ed['electron_px'].split(',') if e != ''])\n",
    "    ed['electron_py'] = np.array([float(e) for e in ed['electron_py'].split(',') if e != ''])\n",
    "    ed['electron_pz'] = np.array([float(e) for e in ed['electron_pz'].split(',') if e != ''])\n",
    "    ed['electron_charge'] = np.array([float(e) for e in ed['electron_charge'].split(',') if e != ''])\n",
    "    ed['electron_relPFIso'] = np.array([float(e) for e in ed['electron_relPFIso'].split(',') if e != ''])\n",
    "    ed['electron_dxy'] = np.array([float(e) for e in ed['electron_dxy'].split(',') if e != ''])\n",
    "    ed['electron_dz'] = np.array([float(e) for e in ed['electron_dz'].split(',') if e != ''])\n",
    "    ed['electron_SIP3d'] = np.array([float(e) for e in ed['electron_SIP3d'].split(',') if e != ''])\n",
    "    return (event[0], ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = map(parse_strings, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " run                                       194533\n",
       " event                                     846715\n",
       " luminosity_section                          2823\n",
       " muon_energy                    [46.227, 17.1694]\n",
       " muon_px                       [-2.8323, 11.2507]\n",
       " muon_py                      [-13.9613, -1.2918]\n",
       " muon_pz                     [-43.9771, -12.9046]\n",
       " muon_charge                          [-1.0, 1.0]\n",
       " muon_relPFIso                [0.191416, 0.17468]\n",
       " muon_dxy              [0.00761235, -0.000309401]\n",
       " muon_dz                [-0.00194986, 0.00129964]\n",
       " muon_SIP3d                  [0.946415, 0.308535]\n",
       " electron_energy               [82.9044, 11.4583]\n",
       " electron_px                  [1.71208, -8.54741]\n",
       " electron_py                   [28.2926, 2.83502]\n",
       " electron_pz                  [-77.9085, 7.08491]\n",
       " electron_charge                      [-1.0, 1.0]\n",
       " electron_relPFIso            [0.15352, 0.515702]\n",
       " electron_dxy           [-0.00206888, 0.00300649]\n",
       " electron_dz           [-0.00538221, 7.12868e-05]\n",
       " electron_SIP3d              [0.937364, 0.413622]\n",
       " Name: 1, dtype: object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that all the data will be parsed when it emerges from this transformation we can start doing the actual data crunching.\n",
    "\n",
    "When thinking a bit about the problem we want to solve, it is possible to see that the organisation of the data is far from optimal. By rearranging the data into 4-vectors for the muons and electrons we can use general purose functions to calculate things like the center of mass and the angles phi and theta. So the best idea is to restructure the data so that we can potentally reuse code that may allready exist to calculate quantities on 4-vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing the data\n",
    "def build_4_vectors(event):\n",
    "    # ed stands for event-data\n",
    "    ed = event[1]\n",
    "    # transformed event-data (this will contain the data in the structure that we want)\n",
    "    ted = {}\n",
    "    e_keys = ['electron_energy', 'electron_px', 'electron_py', 'electron_pz']\n",
    "    mu_keys = ['muon_energy', 'muon_px', 'muon_py', 'muon_pz']\n",
    "    mu_vecs = np.array([[me, mpx, mpy, mpz] for me, mpx, mpy, mpz in zip(ed[mu_keys[0]], ed[mu_keys[1]], ed[mu_keys[2]], ed[mu_keys[3]])])\n",
    "    e_vecs = np.array([[ee, epx, epy, epz] for ee, epx, epy, epz in zip(ed[e_keys[0]], ed[e_keys[1]], ed[e_keys[2]], ed[e_keys[3]])])\n",
    "    ted['e_fourvector'] = e_vecs\n",
    "    ted['mu_fourvector'] = mu_vecs\n",
    "    \n",
    "    # copy the rest of the values as long as they are not redundant\n",
    "    for key in ed.keys():\n",
    "        if key not in e_keys and key not in mu_keys:\n",
    "            ted[key] = ed[key]\n",
    "        \n",
    "    return (event[0], ted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this definition I have used the [zip](https://docs.python.org/3/library/functions.html#zip) function that also works on iterators (and iterables (iterables are things that can trivially be transformed into an iterator (like lists))) please look up what it does at the link provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = map(build_4_vectors, parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " {'e_fourvector': array([[ 42.9922 , -16.5883 ,  38.9813 ,  -7.32215],\n",
       "         [ 71.6306 ,   5.92063, -30.8763 , -64.3627 ]]),\n",
       "  'mu_fourvector': array([[ 19.461  ,  11.2609 , -10.3577 , -12.0261 ],\n",
       "         [ 10.3101 ,   9.16698,  -2.32848,   4.10262]]),\n",
       "  'run': 194533.0,\n",
       "  'event': 846723,\n",
       "  'luminosity_section': 2823,\n",
       "  'muon_charge': array([-1.,  1.]),\n",
       "  'muon_relPFIso': array([0.155083, 0.221734]),\n",
       "  'muon_dxy': array([0.00070336, 0.00115165]),\n",
       "  'muon_dz': array([ 0.00084617, -0.00065684]),\n",
       "  'muon_SIP3d': array([0.296126, 0.240591]),\n",
       "  'electron_charge': array([-1.,  1.]),\n",
       "  'electron_relPFIso': array([0.103053 , 0.0723279]),\n",
       "  'electron_dxy': array([-0.00058122, -0.023985  ]),\n",
       "  'electron_dz': array([0.00161887, 0.0172354 ]),\n",
       "  'electron_SIP3d': array([0.369838, 4.44646 ])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(vectorized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small side note here, notice how every time we call next on one of the interators the index increases showing that the different iterators actually consume the data they transform and either pass it along or display it (when we call next on one of the earlier iterators it is shown rather than passed along to the next `map` function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it would also be useful, to group the rest of the values by lepton. We could also introduce a particle type so that we essentially have one entry and the entry tells us what kind of particle we are looking at. An event therefore would consist of meta information and a collection of particles. So now a map will be created to map the desired quantities to a list of particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_leptons(event):\n",
    "    data = event[1]\n",
    "    leptons = []\n",
    "    e_quantities = [data['e_fourvector'],\n",
    "                    data['electron_charge'],\n",
    "                    data['electron_relPFIso'],\n",
    "                    data['electron_dxy'],\n",
    "                    data['electron_dz'],\n",
    "                    data['electron_SIP3d']]\n",
    "    mu_quantities = [data['mu_fourvector'],\n",
    "                     data['muon_charge'],\n",
    "                     data['muon_relPFIso'],\n",
    "                     data['muon_dxy'],\n",
    "                     data['muon_dz'],\n",
    "                     data['muon_SIP3d']]\n",
    "    for fourvec, charge, relPFIso, dxy, dz, SIP3d in zip(*e_quantities):\n",
    "        lepton_dict = {'p': fourvec, 'type': 'e', 'charge': charge,\n",
    "                       'dxy': dxy, 'dz': dz, 'relPFIso': relPFIso, 'SIP3d': SIP3d}\n",
    "        leptons.append(lepton_dict)\n",
    "    for fourvec, charge, relPFIso, dxy, dz, SIP3d in zip(*mu_quantities):\n",
    "        lepton_dict = {'p': fourvec, 'type': 'mu', 'charge': charge,\n",
    "                       'dxy': dxy, 'dz': dz, 'relPFIso': relPFIso, 'SIP3d': SIP3d}\n",
    "        leptons.append(lepton_dict)\n",
    "    return (event[0], {'run': data['run'], 'event':data['event'], 'leptons': leptons})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_data = map(map_to_leptons, vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " {'run': 194533.0,\n",
       "  'event': 846753,\n",
       "  'leptons': [{'p': array([39.5647  , 35.2052  , 18.029   ,  0.956613]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': 0.00165894,\n",
       "    'dz': 0.0132108,\n",
       "    'relPFIso': 0.1432,\n",
       "    'SIP3d': 1.92044},\n",
       "   {'p': array([ 98.4103 , -31.9606 ,  -9.41048,  92.5988 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000320531,\n",
       "    'dz': 0.00052476,\n",
       "    'relPFIso': 0.049916,\n",
       "    'SIP3d': 0.0866598},\n",
       "   {'p': array([8.09622  , 0.0821112, 6.51906  , 4.79925  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 0.000483781,\n",
       "    'dz': -0.00433865,\n",
       "    'relPFIso': 0.216925,\n",
       "    'SIP3d': 0.973179},\n",
       "   {'p': array([ 7.72517, -2.40281, -6.02051,  4.20085]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00335737,\n",
       "    'dz': -0.00260739,\n",
       "    'relPFIso': 0.41674,\n",
       "    'SIP3d': 0.868803}]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(reformatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building analysis pipelines\n",
    "To facilitate code reuse it is useful to structure these transformations and filters from single transformations into a structure I'll call a pipeline. A pipeline either produces a certain filtered and amended subset of the initial data or generates the answer to a question like the properties of some quantity. This pipeline can then be called with any data that fits the input format of the first tranformation in the pipeline.\n",
    "\n",
    "An arbitrary pipeline will generally consist of 3 steps.\n",
    "1. Format the data into the form that the pipeline (and subsequently you as the programmer) can work with best. This is essentially what we have been doing so far. We have parsed the strings and then reformed the data into a structure that is most useful/efficient/intuitive (depending on the needs).\n",
    "\n",
    "2. Filter the data: The next step in any analysis is to filter out all data that does not fit the requirements. This should be done as early as possible to avoid doing expensive computations on data that would be thrown out anyway. So the Idea is to start with the cheapest calculations that eliminate the largest amounts of data form the sample that was loaded into the front of the pipeline (think of this in the same sense as the refinement process of crude oil into it's destillates). If the refinery would perform a specific process to a compond that would later be dumped anyway the refinery just used up a lot of energy for nothing and needs larger processing facilities than would actually be neccesary (this analogy maps pretty much exactly to data processing, the crude oil being the inputs and the destillates the outputs. The energy would be the energy consumed by the computers during the processing and processing data at a specific throughput would require less compute power the more efficient it is).\n",
    "\n",
    "3. After the data has been filtered to the smallest possible dataset the expensive calculations (like the reconstruction of ancestor particles like B and D mesons and in this case hopefully the two Z bosons and finally the higgs boson) can commence.\n",
    "\n",
    "The results of the pipeline can then be used to visualize the behaviour or relationships of the quantity of interest.\n",
    "\n",
    "### Combining pipelines\n",
    "The nice thing about this approach is, that the results of one pipeline can be used as input for the next pipeline. So if new data becomes available to answer a particular question that allready has a pipline that can produce an answer the only thing that needs to be done is to write a pipeline that transforms the data from this particular source into a format that the original pipeline can work with.\n",
    "\n",
    "This task may however also involve some amount of filtering besides simple transformation and in that case the reqirements on the input data need to be known for any pipeline. Again these requirements don't only apply to the format of the data but also the ranges of values the data is allowed to take on to guarantee that the pipeline will work properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline will take care of transforming the data from the pandas dataframe we got in the begining\n",
    "# into the structure that we expect in all subsequent analysis steps\n",
    "def read_in_and_reformat(raw_data_iterator):\n",
    "    return map(map_to_leptons, map(build_4_vectors, map(parse_strings, raw_data_iterator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous statement should be read the same way that a mathematical function should be, from the inside out. We start with the `parse_strings` method on the right hand side work our way to the left. The output of the `parse_strings` method is then used as input into the `build_4_vectors` method and then that is in turn used as input into the `map_to_leptons` function.\n",
    "\n",
    "As what is returned by the `read_in_and_reformat` is still just an iterator we can now use that function as a building block for a possibly more complex data-processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's now do something a bit more physics-heavy and calculate the $p_t$ (transverse momentum) of all leptons in each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transverse_momentum(fourvector):\n",
    "    \"\"\" given a fourvector this function simply calcuates the corresponding transverse momentum\n",
    "    The fourvector should follow this convention: [e, px, py, pz]\"\"\"\n",
    "    return np.sqrt(fourvector[1]**2 + fourvector[2]**2)\n",
    "\n",
    "# now that we have a generic fourvector based calculation function we have to wrap this in a function that extracts\n",
    "# the neccessary information from the event\n",
    "def calc_pt(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'pt': calculate_transverse_momentum(l['p'])})\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I want to add an new entry to each lepton (remember a lepton in our case is a `dict` and update is defined for `dict`) I can use the update method on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pt = map(calc_pt, reformatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the transverse momentum, we can apply our first filter. In this scenario, we want all events where there are at least four leptons that have a transverst momentum larger than a given value $p_{t_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_min(event, min_pt):\n",
    "    data = event[1]\n",
    "    leptons = filter(lambda lepton: lepton['pt'] > min_pt, data['leptons'])\n",
    "    return True if len(list(leptons)) > 4 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code has a few things in it not quite covered yet. So I'll do that here.\n",
    "\n",
    "Remember that I said that a list is an iterator? Well in case you don't: A list is an iterator, so as we want to count the number of leptons that have a specific properties a filter can be used on the leptons to only return all leptons that have a transverse momentum larger than `min_pt` and then the filter that we actually want to write should only return the event when the amount of leptons meeting that requirement is larger than four.\n",
    "\n",
    "\n",
    "##### Side notes on the `lambda` function\n",
    "---\n",
    "As you might also stil remember, filter needs a function to determin which event to accept and pass along and which to reject and subsequently drop from the stream. The function that is passed to filter needs to return `True` if the value should be accepted and `False` if it should be rejected. As you can see our `pt_min` function does exactly that.\n",
    "\n",
    "The second thing I wanted to talk about briefly is the [lambda](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) expression, that was used in the lepton filter. `lambda` functions are a sort of short hand for defining functions. As you can see the function is not very long, it fits into less than one line. The `lambda` function ends at the `,` and is equivalent to the following 'proper' function definition:\n",
    "\n",
    "```python\n",
    "def filter_leptons(x, min_pt):\n",
    "    return lepton['pt'] > min_pt\n",
    "```\n",
    "\n",
    "There are a few noteworthy differences though:\n",
    "- A `lambda` function does not need a name. I have therefore given the previous equivalent function a fitting name.\n",
    "\n",
    "- lambda functions also 'capture their environment' that means lambda functions can use all variables that would be available inside the scope where the lambda function was defined (in the case of the `pt_min` function, the labmda expression there did not need to be passed the `min_pt` value as it automatically had access to it, whereas it needs to be passed explicitly to the `filter_leptons` function so it can be used inside the function body. The particulars of this kind of behavior (which is called 'scoping') are a bit more tricky and will not be covered further here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we take a look at the `pt_min` method, we can see that the signature of the function (the signature is the word for how the function 'looks' from the outside. So the  signature of the function is the name together with type and sequence of input parameters and the output parameters of the function) still does not fit the requirements for the `filter` method. We subsequently need to wrap this function somehow. This is similar but not quite the same to how we wrapped the function to calculate the `pt` for each lepton in an event. This time we have to wrap the function that takes an event together with a parameter to filter the event by. There are a few methods to do this. We shal talk about these now.\n",
    "\n",
    "1. **Tuple (un)wrapping**: Here the values neede are packed into a tuple and unpacked inside the wrapper function, passed to the function being wrapped (in this case `pt_min`) and then proceed as before. This obviously neccessitates the definition of a 'wrapper' function. This function could be defined in the fillowing way:\n",
    "\n",
    "```python\n",
    "def pt_min_wrapper(event_with_pt_min_tuple):\n",
    "    event, min_pt = event_with_pt_min_tuple\n",
    "    return pt_min(event, min_pt)\n",
    "```\n",
    "\n",
    "The problem with this method is that this makes the call of the filter a bit more complicated, as it is now neccessary to construct a `min_pt` object for each and every event that all have to be identical and combine the two objects into a tuple as follows `(event,     min_pt)`. The iterators and functions from the itertools can help here. The call would subsequently look like this:\n",
    "\n",
    "```python\n",
    "filter(pt_min_wrapper, zip(events, itertools.cycle(min_pt)))\n",
    "```\n",
    "\n",
    "Please check out what [cycle](https://docs.python.org/3/library/itertools.html#itertools.cycle) does at the link.\n",
    "\n",
    "2. **Using a `lambda`**: with a `lambda` all of that effort can be avoided. The lambda method acts as the wrapper, but because it has access to it's environment (the place where `min_pt` is defined) the `min_pt` argument is implicitly copied as part of the funcion call. This is (in my humble oppinion) the far more elegant solution. We will use this method when we filter the stream after the next text section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pt = 4\n",
    "min_pt_filtered_stream = filter(lambda e: pt_min(e, min_pt), data_with_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I'll start to focus more on the physics here. So lets define the functions needed to calculate a few other quantities that interesting for the later analysis. If neccesary we can use filters in between the calculatinon steps to remove data that no longer fits our needs and reduce processing load in all subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudorapidity(pt, pz):\n",
    "    \"\"\"calculate the pseudorapidity (eta) for a given fourvector\"\"\"\n",
    "    # remember opposite/adjacent = tan(theta)\n",
    "    return -np.log(np.abs(pt/(pz*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(fourvector):\n",
    "    vec = np.array([fourvector[1], fourvector[2]])\n",
    "    normed_vec = vec/np.linalg.norm(vec)\n",
    "    return np.arctan2(normed_vec[1], normed_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "* I'd make it an excercise for the students to implement the wrapper for these functions as seen in the example of the `pt_min` function these function wrappers are going to be provided in the following block as a reference\n",
    "\n",
    "* it is of course advisable to let the students implement the phi, mandelstam_s and pseudorapidity functions with the given input parameters as these functions encode the actual physical quantities.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the 'wrapper' functions I mentioned above and you can see that they are pretty straight forward to implement so I hope at this stage of the tutorial\n",
    "# with a pretty straight forward example they should be able to do it\n",
    "def calc_pseudorapidity(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'eta': pseudorapidity(l['pt'], l['p'][3])})\n",
    "    return event\n",
    "\n",
    "def calc_phi(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'phi': phi(l['p'])})\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three functions can't directly be inserted into the analysis pipeline, because they lack the right input and output parameters. Theses functions functions have to be 'wrapped' by a functions that does not really do anything else than transform the input quantities of the outer function (in this case the event that we want to calculate the quantity for) to the parameters needed by the function that actually does the work. It also takes care to embed the result into the object that was passed in from the outside. This type of function will be somewhat important in the coming stages of what we want to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Physics involved\n",
    "It may be fairly obvious but I will say it anyway, before we can tell the computer how to analyse things we first need to understand what it is that we are analysing. In this case we are analysing the decay of the Higgs Boson into four leptons via two $Z$ bosons. We are not considering anything else here so we don't have to look for photons or jets or anything of that sort.\n",
    "\n",
    "As the $Z$ boson can decay into 4 leptons the kind of lepton that is produced still varies but effectively comes down to either\n",
    "\n",
    "1. All four leptons are $\\mu$ s\n",
    "2. All four leptons are electorns\n",
    "3. There are two electrons and two $\\mu$ s.\n",
    "\n",
    "These three different modes of decay are typically called 'decay channels' (this nomenclature extends to all kind of decays).\n",
    "\n",
    "In any of the above mentioned cases the electron and/or muon can be either particle or antiparticle. Depending on the specific event.\n",
    "So first of we should probably eliminate all events where we can't find either four electrons, four $\\mu$ s or two $\\mu$ s and two electrons\n",
    "\n",
    "However we could split the pipeline here and filter out the events that have (at least) four leptons of the same type (one pipeline for electrons, one for muons) and one for all events that have (at least) two electrons and two muons. This could create multiple copies of the same event (at most one per pipeline bringing the total to 3) As we have kept the ID of each event we should not forget to then cross check if one event ended up being counted for two different decay channels.\n",
    "\n",
    "If you however read the [Paper](https://arxiv.org/pdf/1207.7235.pdf), you will find that the authors chose to first limit the electrons in each event to electrons with a $p_T > 7 \\text{ [GeV]}$ and $\\left|\\eta\\right| < 2.5$. The muons considered for each event also have to satisfy $p_T > 5\\text{ [GeV]}$ and $\\left|\\eta\\right| < 2.4$ So let's define these parameters here.\n",
    "\n",
    "Along with the requirements for the $\\eta$ and $p_T$ there are restrictions on the impact parameter (that have to be above 4 for every lepton) and also restrictions on the minimum relative isolation. The `max_dxy` and `max_dz` are quantities related to the impact parameter and describe the point of closest approach of the lepton track to the reconstructed vertex. If the lepton is to far away, we should not consider it part of the vertex and therefore discard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_pt_min = 7\n",
    "electron_max_eta = 2.5\n",
    "muon_pt_min = 5\n",
    "muon_max_eta = 2.4\n",
    "min_impact_param = .1\n",
    "max_dxy = .1\n",
    "max_dz = .1\n",
    "min_rel_iso = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be following that lead (see section 5.2) and starting with filtering out all electrons and muons that don't meet the stated requirements.\n",
    "\n",
    "So now we have to do something somewhat interesting. We are going to use filters *inside* an event to alter it before we pass the event along. The event itself will allways be passed on to the next stage of the pipeline, But the event may not contain any leptons because none of them where able to pass the requirements. So the counting of leptons will only happen *after* the leptons have been reduced to leptons that satisfy our reconstruction requirements.\n",
    "\n",
    "To be able to filter out events that don't meet the required number of leptons we can define the following function and then use a wrapper to be able to use it in a filter. (As I said, you will see wrappers again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_least_n_leptons_of_type(t, n, leptons):\n",
    "    \"\"\"function that can be used to filter out leptons of type t\"\"\"\n",
    "    type_t_leptons = list(filter(lambda l: l['type'] == t, leptons))\n",
    "    return len(type_t_leptons) >= n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please don't get things confused here (they can be quite confusing). The events have to mapped as we are not discarding entire events. However *inside* each event the individual leptons are going to be filtered.\n",
    "\n",
    "We also are going to have to define 4 different wrappers for this function. Each wrapper will pass different arguments to the `at_least_n_leptons_of_type` function.\n",
    "One wrapper is going to remove all events in the 4 muon processing pipeline that don't still have 4 muons left. One wrapper will do the same in the four electron pipeline and we are going to use two filters in series (one for two electrons and one for two muons) in the 2e2mu pipeline.\n",
    "\n",
    "---\n",
    "###### Side Note\n",
    "I'd like to point out the use of the `lambda` function here. It again is very similar to the last occurrence and we will see the `lambda` used more extensively throughout the coming steps.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first calculation and filter step.\n",
    "\n",
    "Now let's build the filter pipeline for the restriction of the leptons to leptons that meet the desired criteria and then split the single pipeline into three independedn ones. One for the four muon channel, one for the four electron channel and one for the 2el2mu channel. For this we need an unfiltered stream and will use `stream_2` for this purpose (`stream_2` was split off before the min_pt filter was applied. The good thing here is that `pt` has allready been calculated for each lepton. However we cant simply use the `min_pt` filter as it filters out events if it can't find at least four leptons that have a $p_T$ larger than `pt_min`, we however want to drop all leptons that don't satisfy the requirements in each event but keep the event. We also still need to calculate $\\eta$ for all leptons of every event but as we have already written a function that can be used in a map statement this is fairly strait forward.\n",
    "\n",
    "Let's first calculate $\\eta$ for the leptons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pt_and_eta = map(calc_pseudorapidity, data_with_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " {'run': 194533.0,\n",
       "  'event': 846763,\n",
       "  'leptons': [{'p': array([ 81.314 , -78.6539, -11.2899,  17.2646]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.000410155,\n",
       "    'dz': 0.00174084,\n",
       "    'relPFIso': 0.0136104,\n",
       "    'SIP3d': 0.465797,\n",
       "    'pt': 79.46003918461152,\n",
       "    'eta': -0.8334489006486171},\n",
       "   {'p': array([ 11.1153 , -10.3513 ,  -3.73267,  -1.57127]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00214753,\n",
       "    'dz': -0.00185153,\n",
       "    'relPFIso': 0.250511,\n",
       "    'SIP3d': 0.454134,\n",
       "    'pt': 11.003737411393459,\n",
       "    'eta': -1.2532035896431293},\n",
       "   {'p': array([ 71.6791,  64.102 , -26.1167,  18.6209]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.000143862,\n",
       "    'dz': -0.00487695,\n",
       "    'relPFIso': 0.014919,\n",
       "    'SIP3d': 1.44616,\n",
       "    'pt': 69.21812206994639,\n",
       "    'eta': -0.6198309215983585},\n",
       "   {'p': array([80.8522, 25.6134, 41.6729, 64.3769]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000591512,\n",
       "    'dz': 0.00341611,\n",
       "    'relPFIso': 0.013307,\n",
       "    'SIP3d': 0.757034,\n",
       "    'pt': 48.91499620740044,\n",
       "    'eta': 0.9678180332965066}]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_with_pt_and_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data is available we can apply the filters on the leptons in each event. The function that is used to filter out the leptons is defined below. As usual we will need a wrapper in the form of a lambda expression to be able to fit these functions into the normal `filter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lepton_pt_and_eta_requirements(lepton, pt_min, eta_max):\n",
    "    return lepton['pt'] >= pt_min and np.abs(lepton['eta']) <= eta_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impact_parameter_requirements(lepton, min_SIP, max_dxy, min_dz):\n",
    "    return lepton['SIP3d'] >= min_SIP and lepton['dxy'] <= max_dxy and lepton['dz'] <= max_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_isolation_requirements(lepton, min_relPFIso):\n",
    "    return lepton['relPFIso'] >= min_relPFIso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unfit_leptons(event, lepton_type, pt_min, eta_max, SIP_min, dxy_max, dz_max, rel_PFIso_min):\n",
    "    leptons = event[1]['leptons']\n",
    "    other_leptons = filter(lambda l: l['type'] != lepton_type, leptons)\n",
    "    leptons_of_specified_type = filter(lambda l: l['type'] == lepton_type, leptons)\n",
    "    event[1]['leptons'] = list(itt.chain(filter(lambda l: lepton_pt_and_eta_requirements(l, pt_min, eta_max),\n",
    "                                                filter(lambda l: impact_parameter_requirements(l, SIP_min, dxy_max, dz_max), \n",
    "                                                       filter(lambda l: relative_isolation_requirements(l, rel_PFIso_min),\n",
    "                                                              leptons_of_specified_type))),\n",
    "                                         other_leptons))\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wrap the inner function in a function that accepts an event and then applies the filter to the leptons of that event. However as the signature is still not fit for use in the `map` function (remember we are filtering the leptons not the events, which is why the events need to be mapped. We will filter the events in the next step) we still need to wrap that function, preferably in a lambda. It is also worth pointing out that I have used one of those neat itertools functions. In this case I used chain to take two iterators and chain them so that we get a single output iterator containin all elements of both input iterators.\n",
    "\n",
    "This double wrapping was done because the $p_T$ and $\\eta$ requirements are now values that exist as parameters for the entire pipeline. If we want to change these parameters because for example our search requirements have somehow changed we can simply change some global variables (like the ones defined above) in the analysis script and don't have to go hunting in the depths of the code for where the parameter was defined. It is therefore important to think about what parameters will probably be varied often and expose them to the outside. But be careful, simply exposing every parameter may become confusing (if also maybe neccesary). You will have to decide that for every pipeline and analysis you build at your discretion and taste. Some people will prefer a flat design exposing all parameters and again others will prefer a hirarchy where they define sub-pipelines that then have their values defined inside a smaller scope. Find what fits best for you.\n",
    "\n",
    "So now let's define the lepton filter, again with the `lambda` function to simplify the wrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with_filtered_electrons = map(lambda e: remove_unfit_leptons(e,\n",
    "                                                                    'e',\n",
    "                                                                    electron_pt_min,\n",
    "                                                                    electron_max_eta,\n",
    "                                                                    min_impact_param,\n",
    "                                                                    max_dxy,\n",
    "                                                                    max_dz,\n",
    "                                                                    min_rel_iso),\n",
    "                                     data_with_pt_and_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " {'run': 194533.0,\n",
       "  'event': 846787,\n",
       "  'leptons': [{'p': array([159.376  ,   1.60129, -64.9424 , 145.535  ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000772845,\n",
       "    'dz': -0.00466982,\n",
       "    'relPFIso': 0.0417984,\n",
       "    'SIP3d': 1.11682,\n",
       "    'pt': 64.9621385687394,\n",
       "    'eta': 1.4997591714438712},\n",
       "   {'p': array([95.0541  , 55.6391  ,  0.642879, 77.0659  ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': 0.00423916,\n",
       "    'dz': 0.00480899,\n",
       "    'relPFIso': 0.0236071,\n",
       "    'SIP3d': 1.32662,\n",
       "    'pt': 55.64281393152795,\n",
       "    'eta': 1.0188551408720814},\n",
       "   {'p': array([175.413 ,  30.3673, -59.5542, 162.175 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000409225,\n",
       "    'dz': -0.000506639,\n",
       "    'relPFIso': 0.0148671,\n",
       "    'SIP3d': 0.15078,\n",
       "    'pt': 66.8496495647509,\n",
       "    'eta': 1.579377118237778},\n",
       "   {'p': array([18.9466  ,  0.630108, 18.8462  ,  1.83977 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': 0.000924033,\n",
       "    'dz': -0.00541554,\n",
       "    'relPFIso': 0.043713,\n",
       "    'SIP3d': 1.11657,\n",
       "    'pt': 18.85673064270856,\n",
       "    'eta': -1.6340821690680747}]})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(events_with_filtered_electrons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with_filtered_leptons = map(lambda e: remove_unfit_leptons(e, 'mu',\n",
    "                                                                  muon_pt_min,\n",
    "                                                                  muon_max_eta,\n",
    "                                                                  min_impact_param,\n",
    "                                                                  max_dxy, max_dz,\n",
    "                                                                  min_rel_iso),\n",
    "                                   events_with_filtered_electrons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed all leptons that don't meet our requirements it is time to split the stream into three (identical) streams, one for each decay channel. Then we will apply the filters that restrict the events to only the events that match the lepton count of the different decay channels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Stream\n",
    "We now have the problem that we want to look at three streams independently. To accomplish this we have a few options:\n",
    "\n",
    "- we write two analysis pipelines that go from the input data in the pandas dataframe filter out everything except for the events matching the requirements to be in one of the three channels. So in effect the Pipeline is run thrice, once for each channel we want to look at. This has the drawback that we need to perform the parsing and reformatting, as well as the calculation of the transverse momentum thrice, once for each analysis. In our case the calculations and transformations where not particularly expensive, it is however imaginable that a situation arises where the analyses differ in a later stage where, for example, the reconstruction has allready taken place and used up large amount of CPU time and energy to run the computers. Doing that thrice is qite literaly an expensive thing to do (as in paying the power bills at the end of the month).\n",
    "\n",
    "- we could split the stream of data into three streams with identical copies. The first stream goes into the filter for the 2el2mu events, the second into the 4mu channel filter and the third into the 4el channel filter. This is exactly what the `itertools.tee` fuction allows us to do.\n",
    "\n",
    "In the following we shal split the stream into three streams, one for the each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_mu_channel, four_e_channel, two_e_two_mu_channel = itt.tee(events_with_filtered_leptons, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to demonstrate that we have actually split the stream into three identical streems we can call `next` once on every stream and then see what they spit out. They should all return the identical event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'run': 194533.0,\n",
       "  'event': 853714,\n",
       "  'leptons': [{'p': array([ 67.7235 , -36.0904 ,   6.38364, -56.949  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00106482,\n",
       "    'dz': 0.000487924,\n",
       "    'relPFIso': 0.276088,\n",
       "    'SIP3d': 0.32319,\n",
       "    'pt': 36.65061843693228,\n",
       "    'eta': 1.1338730087143165},\n",
       "   {'p': array([ 38.1787  ,  18.4771  ,   0.443387, -33.4066  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 6.84894e-06,\n",
       "    'dz': -0.00201422,\n",
       "    'relPFIso': 0.0233677,\n",
       "    'SIP3d': 0.445525,\n",
       "    'pt': 18.482419117685026,\n",
       "    'eta': 1.2850807035288545},\n",
       "   {'p': array([ 44.573  ,  15.4027 ,  -3.87256, -41.6475 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00345287,\n",
       "    'dz': 0.00424,\n",
       "    'relPFIso': 0.0271937,\n",
       "    'SIP3d': 0.266371,\n",
       "    'pt': 15.882061838552323,\n",
       "    'eta': 1.6571982372712366},\n",
       "   {'p': array([ 41.2259 ,  10.0007 ,   1.20899, -39.9762 ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00282081,\n",
       "    'dz': 0.0155539,\n",
       "    'relPFIso': 0.606938,\n",
       "    'SIP3d': 0.657479,\n",
       "    'pt': 10.073512659946381,\n",
       "    'eta': 2.071521987460627}]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(four_mu_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'run': 194533.0,\n",
       "  'event': 853714,\n",
       "  'leptons': [{'p': array([ 67.7235 , -36.0904 ,   6.38364, -56.949  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00106482,\n",
       "    'dz': 0.000487924,\n",
       "    'relPFIso': 0.276088,\n",
       "    'SIP3d': 0.32319,\n",
       "    'pt': 36.65061843693228,\n",
       "    'eta': 1.1338730087143165},\n",
       "   {'p': array([ 38.1787  ,  18.4771  ,   0.443387, -33.4066  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 6.84894e-06,\n",
       "    'dz': -0.00201422,\n",
       "    'relPFIso': 0.0233677,\n",
       "    'SIP3d': 0.445525,\n",
       "    'pt': 18.482419117685026,\n",
       "    'eta': 1.2850807035288545},\n",
       "   {'p': array([ 44.573  ,  15.4027 ,  -3.87256, -41.6475 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00345287,\n",
       "    'dz': 0.00424,\n",
       "    'relPFIso': 0.0271937,\n",
       "    'SIP3d': 0.266371,\n",
       "    'pt': 15.882061838552323,\n",
       "    'eta': 1.6571982372712366},\n",
       "   {'p': array([ 41.2259 ,  10.0007 ,   1.20899, -39.9762 ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00282081,\n",
       "    'dz': 0.0155539,\n",
       "    'relPFIso': 0.606938,\n",
       "    'SIP3d': 0.657479,\n",
       "    'pt': 10.073512659946381,\n",
       "    'eta': 2.071521987460627}]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(four_e_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'run': 194533.0,\n",
       "  'event': 853714,\n",
       "  'leptons': [{'p': array([ 67.7235 , -36.0904 ,   6.38364, -56.949  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00106482,\n",
       "    'dz': 0.000487924,\n",
       "    'relPFIso': 0.276088,\n",
       "    'SIP3d': 0.32319,\n",
       "    'pt': 36.65061843693228,\n",
       "    'eta': 1.1338730087143165},\n",
       "   {'p': array([ 38.1787  ,  18.4771  ,   0.443387, -33.4066  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 6.84894e-06,\n",
       "    'dz': -0.00201422,\n",
       "    'relPFIso': 0.0233677,\n",
       "    'SIP3d': 0.445525,\n",
       "    'pt': 18.482419117685026,\n",
       "    'eta': 1.2850807035288545},\n",
       "   {'p': array([ 44.573  ,  15.4027 ,  -3.87256, -41.6475 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00345287,\n",
       "    'dz': 0.00424,\n",
       "    'relPFIso': 0.0271937,\n",
       "    'SIP3d': 0.266371,\n",
       "    'pt': 15.882061838552323,\n",
       "    'eta': 1.6571982372712366},\n",
       "   {'p': array([ 41.2259 ,  10.0007 ,   1.20899, -39.9762 ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00282081,\n",
       "    'dz': 0.0155539,\n",
       "    'relPFIso': 0.606938,\n",
       "    'SIP3d': 0.657479,\n",
       "    'pt': 10.073512659946381,\n",
       "    'eta': 2.071521987460627}]})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(two_e_two_mu_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the event number, we get the same event in every channel, so everything is as we expected. Now we have to apply the different filters for the different decay channels to leave us only with events that could actually have been produced by a $Z$ pair decaying into that particular channel.\n",
    "\n",
    "When we take a look at the data we loaded into the front of the pipeline we can make a guess what should happen. As we have loaded a background simulation of ZZ to 2el2mu most to all of the events should end up in the 2el2mu processing pipeline and essentially none in the other two.\n",
    "\n",
    "so let's implement the filters for the different pipelines (corresponding to the different channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_4mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 4, e), four_mu_channel)\n",
    "filtered_4e_data = filter(lambda e: at_least_n_leptons_of_type('e', 4, e), four_e_channel)\n",
    "\n",
    "# the 2el 2mu channel needs two filters one for the minimum amount of electron and then one for the minimal amount of \n",
    "partially_filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('e', 2, e), two_e_two_mu_channel)\n",
    "filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 2, e), partially_filtered_2e2mu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now would be a good time to check if the assumption that we made (that most of the events end up in `filtered_2e2mu_data` and only a few make it into the other pipelines. To be able to do this in a repeatable way, we should probably combine all the previous work into one neat function.\n",
    "\n",
    "While we are at it we can first define parts of the pipeline that thematically belong together into their own functions. We have allready defined the `read_in_and_reformat` function grouping the early reformatting functions that simply reorganize the data that we get from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first a function can be defined that encapsulates the filtering of the three channels\n",
    "def filter_zz_decay_channels(channel_4mu, channel_4el, channel_2el2mu):\n",
    "    # filter out the events that don't have enough muons for the 4mu channel\n",
    "    filtered_4mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 4, e[1]['leptons']), channel_4mu)\n",
    "    \n",
    "    # filter out all events that don't have enough electrons for the 4el channel\n",
    "    filtered_4e_data = filter(lambda e: at_least_n_leptons_of_type('e', 4, e[1]['leptons']), channel_4el)\n",
    "    \n",
    "    # the 2el 2mu channel needs two filters one for the minimum amount of electron and then one for the minimal amount of\n",
    "    # muons that we want (two in each case)\n",
    "    partially_filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('e', 2, e[1]['leptons']), channel_2el2mu)\n",
    "    filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 2, e[1]['leptons']), partially_filtered_2e2mu_data)\n",
    "    \n",
    "    return filtered_4mu_data, filtered_4e_data, filtered_2e2mu_data\n",
    "\n",
    "# now we can also define a function that takes care of filtering out the\n",
    "# leptons that don't meet the requirements\n",
    "def filter_out_unfit_leptons(data_iterator, muon_pt_min, muon_eta_max, el_pt_min, el_eta_max):\n",
    "    \n",
    "    # remove all muons that dont meet the requirements\n",
    "    data_with_filtered_muons = map(lambda e: remove_unfit_leptons(e, 'mu',\n",
    "                                                                  muon_pt_min,\n",
    "                                                                  muon_max_eta,\n",
    "                                                                  min_impact_param,\n",
    "                                                                  max_dxy, max_dz,\n",
    "                                                                  min_rel_iso),\n",
    "                                     data_iterator)\n",
    "    \n",
    "    #remove all electrons that dont meet the requirements\n",
    "    data_with_filtered_leptons = map(lambda e: remove_unfit_leptons(e, 'e',\n",
    "                                                                    el_pt_min,\n",
    "                                                                    el_eta_max,\n",
    "                                                                    min_impact_param,\n",
    "                                                                    max_dxy, max_dz,\n",
    "                                                                    min_rel_iso),\n",
    "                                     data_with_filtered_muons)\n",
    "    \n",
    "    return data_with_filtered_leptons\n",
    "    \n",
    "def read_in_reformat_split_and_filter_into_channels(raw_data_iterator, muon_pt_min, muon_eta_max, el_pt_min, el_eta_max):\n",
    "    # parse the strings, and reformat into list of leptons\n",
    "    parsed_and_formatted_data = read_in_and_reformat(raw_data_iterator)\n",
    "    \n",
    "    # calculate the needed quantities\n",
    "    data_with_pt_and_eta = map(calc_pseudorapidity, map(calc_pt, parsed_and_formatted_data))\n",
    "    \n",
    "    # now we filter out the leptons that don't meet the requirements from each event\n",
    "    data_with_pre_filtered_leptons = filter_out_unfit_leptons(data_with_pt_and_eta,\n",
    "                                                              muon_pt_min,\n",
    "                                                              muon_eta_max,\n",
    "                                                              el_pt_min,\n",
    "                                                              el_eta_max)\n",
    "    \n",
    "    # now we need to split the stream (the sequence of the channels is currently still arbitrary because they are identical\n",
    "    # after creation)\n",
    "    channel_4mu, channel_4el, channel_2el2mu = itt.tee(data_with_pre_filtered_leptons, 3)\n",
    "    filtered_channel_4mu, filtered_channel_4el, filtered_channel_2el2mu = filter_zz_decay_channels(channel_4mu,\n",
    "                                                                                                   channel_4el,\n",
    "                                                                                                   channel_2el2mu)\n",
    "    return filtered_channel_4mu, filtered_channel_4el, filtered_channel_2el2mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the definition of the `read_in_reformat_split_and_filter_into_channels` in place we can easily test the hypothesis that most events should end up in the `filtered_channel_2el2mu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu, c4el, c2el2mu = read_in_reformat_split_and_filter_into_channels(bkgnd_sim_2el2mu.head(10000).iterrows(),\n",
    "                                                                      muon_pt_min,\n",
    "                                                                      muon_max_eta,\n",
    "                                                                      electron_pt_min,\n",
    "                                                                      electron_max_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for the parameters `muon_pt_min` to `electron_max_eta` where defined when we talked about the ZZ-> 4l process.\n",
    "\n",
    "So now for the test of all our previous work a drum roll please:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "7019\n"
     ]
    }
   ],
   "source": [
    "print(len(list(c4mu)))\n",
    "print(len(list(c4el)))\n",
    "print(len(list(c2el2mu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see, we have indeed ended up with most of the 10000 events that we started with in the 2el2mu channel just as we would have expected. \n",
    "\n",
    ">Just FYI I did not test any of the code befor running this test and except for some minor variable misnaming errors everything just worked.\n",
    "\n",
    "I have to use list here because the thing that is returned by the function at the beginning was just the iterator. The iterator had not actually done any work yet but was simply defined.\n",
    "\n",
    "Iterators in python are 'lazy' that means that they only do work when an item is requested of them via the next method. This is why the call of the function was nearly instant even though we did pass the data and all the needed information to it.\n",
    "\n",
    "This is also why I used the `len(list(iterator))` call. the `list` function turns the iterator back into a list by calling next on the iterator until it raises the `StopIteration` exception and stores the values the iterator returns in a list in the order it got them from the iterator. Subsequently an iterator does not know it's length, but a list of course does so we need the list before we can call `len` to determin how many events made it into the different channels.\n",
    "\n",
    "Now let's try the different simulation setst for the other two decay channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu_2, c4el_2, c2el2mu = read_in_reformat_split_and_filter_into_channels(bkgnd_sim_4mu.head(10000).iterrows(),\n",
    "                                                                          muon_pt_min,\n",
    "                                                                          muon_max_eta,\n",
    "                                                                          electron_pt_min,\n",
    "                                                                          electron_max_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This went fine but when we try and evaluate the iterators we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'electron_energy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'electron_energy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-c39c385c5017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc4mu_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc4el_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2el2mu_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5133efcba601>\u001b[0m in \u001b[0;36mparse_strings\u001b[0;34m(event)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_dz'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_dz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_SIP3d'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_SIP3d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_energy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_energy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_px'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_px'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_py'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_py'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'electron_energy'"
     ]
    }
   ],
   "source": [
    "print(len(list(c4mu_2)))\n",
    "print(len(list(c4el_2)))\n",
    "print(len(list(c2el2mu_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a `KeyError`. It took me a minute to figure this one out but the error here allready points in a good direction. If we take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>muon_energy</th>\n",
       "      <th>muon_px</th>\n",
       "      <th>muon_py</th>\n",
       "      <th>muon_pz</th>\n",
       "      <th>muon_charge</th>\n",
       "      <th>muon_relPFIso</th>\n",
       "      <th>muon_dxy</th>\n",
       "      <th>muon_dz</th>\n",
       "      <th>muon_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142211</td>\n",
       "      <td>3809</td>\n",
       "      <td>52.8881,104.397,29.9594,60.5544</td>\n",
       "      <td>-49.2137,16.0997,24.2971,14.3324</td>\n",
       "      <td>0.527564,-27.1821,11.0576,-1.76615</td>\n",
       "      <td>-19.3616,99.5022,-13.599,58.8072</td>\n",
       "      <td>1,-1,-1,1</td>\n",
       "      <td>0.0296542,0,0.0445055,0</td>\n",
       "      <td>-0.000377091,-0.000857253,0.00163948,-0.00102962</td>\n",
       "      <td>-0.000987451,0.00553847,0.000673754,-0.00563673</td>\n",
       "      <td>0.341185,1.17472,0.74423,0.727535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run    event  luminosity_section                      muon_energy  \\\n",
       "0  194533.0  1142211                3809  52.8881,104.397,29.9594,60.5544   \n",
       "\n",
       "                            muon_px                             muon_py  \\\n",
       "0  -49.2137,16.0997,24.2971,14.3324  0.527564,-27.1821,11.0576,-1.76615   \n",
       "\n",
       "                            muon_pz muon_charge            muon_relPFIso  \\\n",
       "0  -19.3616,99.5022,-13.599,58.8072   1,-1,-1,1  0.0296542,0,0.0445055,0   \n",
       "\n",
       "                                           muon_dxy  \\\n",
       "0  -0.000377091,-0.000857253,0.00163948,-0.00102962   \n",
       "\n",
       "                                           muon_dz  \\\n",
       "0  -0.000987451,0.00553847,0.000673754,-0.00563673   \n",
       "\n",
       "                          muon_SIP3d  \n",
       "0  0.341185,1.17472,0.74423,0.727535  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_4mu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>electron_energy</th>\n",
       "      <th>electron_px</th>\n",
       "      <th>electron_py</th>\n",
       "      <th>electron_pz</th>\n",
       "      <th>electron_charge</th>\n",
       "      <th>electron_relPFIso</th>\n",
       "      <th>electron_dxy</th>\n",
       "      <th>electron_dz</th>\n",
       "      <th>electron_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200519.0</td>\n",
       "      <td>1002510</td>\n",
       "      <td>3343</td>\n",
       "      <td>55.0788,41.0337,71.266,40.9315</td>\n",
       "      <td>-44.9139,27.7747,-23.2093,24.2694</td>\n",
       "      <td>-31.722,-29.3722,24.2607,20.2583</td>\n",
       "      <td>-3.1829,-7.04291,-62.8616,-25.9997</td>\n",
       "      <td>1,-1,1,-1</td>\n",
       "      <td>0.0240287,0.00756904,0.129509,0.0101338</td>\n",
       "      <td>0.00150606,0.000130401,0.00381629,0.0155896</td>\n",
       "      <td>0.00356076,-0.000555184,0.000691515,0.00287596</td>\n",
       "      <td>1.01486,0.234018,0.652992,2.33123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run    event  luminosity_section                 electron_energy  \\\n",
       "0  200519.0  1002510                3343  55.0788,41.0337,71.266,40.9315   \n",
       "\n",
       "                         electron_px                       electron_py  \\\n",
       "0  -44.9139,27.7747,-23.2093,24.2694  -31.722,-29.3722,24.2607,20.2583   \n",
       "\n",
       "                          electron_pz electron_charge  \\\n",
       "0  -3.1829,-7.04291,-62.8616,-25.9997       1,-1,1,-1   \n",
       "\n",
       "                         electron_relPFIso  \\\n",
       "0  0.0240287,0.00756904,0.129509,0.0101338   \n",
       "\n",
       "                                  electron_dxy  \\\n",
       "0  0.00150606,0.000130401,0.00381629,0.0155896   \n",
       "\n",
       "                                      electron_dz  \\\n",
       "0  0.00356076,-0.000555184,0.000691515,0.00287596   \n",
       "\n",
       "                      electron_SIP3d  \n",
       "0  1.01486,0.234018,0.652992,2.33123  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_4el.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no entries for electron as there are only muons present in the dataset. Normally this could mean that we can no longer use the entire analysis. However with the funcitonal approach it is possible to add a `map` function that simply adds empty strings for all electron entries. We will have to do the same for the muons in `bkgnd_sim_4el`but after that we have added empty strings we should have data structures that again fit the requirements that are placed at the data by the first filter of our already existing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_electron_entries_to_raw_data(event):\n",
    "    data = event[1]\n",
    "    data['electron_energy'] = ''\n",
    "    data['electron_px'] = ''\n",
    "    data['electron_py'] = ''\n",
    "    data['electron_pz'] = ''\n",
    "    data['electron_charge'] = ''\n",
    "    data['electron_relPFIso'] = ''\n",
    "    data['electron_dxy'] = ''\n",
    "    data['electron_dz'] = ''\n",
    "    data['electron_SIP3d'] = ''\n",
    "    return event\n",
    "\n",
    "\n",
    "def add_muon_entries_to_raw_data(event):\n",
    "    data = event[1]\n",
    "    data['muon_energy'] = ''\n",
    "    data['muon_px'] =  ''\n",
    "    data['muon_py'] = ''\n",
    "    data['muon_pz'] = ''\n",
    "    data['muon_charge'] = ''\n",
    "    data['muon_relPFIso'] = ''\n",
    "    data['muon_dxy'] = ''\n",
    "    data['muon_dz'] = ''\n",
    "    data['muon_SIP3d'] = ''\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two functions defined we should be able to first pass the raw data of `bkgnd_sim_4mu` through `add_electron_entries_to_raw_data` and then into our allready existing pipeline. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu_3, c4el_3, c2el2mu_3 = read_in_reformat_split_and_filter_into_channels(\n",
    "                              map(add_electron_entries_to_raw_data, bkgnd_sim_4mu.head(10000).iterrows()),\n",
    "                              muon_pt_min,\n",
    "                              muon_max_eta,\n",
    "                              electron_pt_min,\n",
    "                              electron_max_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6758\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(list(c4mu_3)))\n",
    "print(len(list(c4el_3)))\n",
    "print(len(list(c2el2mu_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it worked. That means that if we have a new data source we can simply write an adaptor for that data source and continue to use our initial data pipeline. How neat.\n",
    "\n",
    "So just to prove that it works here the whole thing again just this time for the simulated electron background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7139\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "c4mu_4, c4el_4, c2el2mu_4 = read_in_reformat_split_and_filter_into_channels(\n",
    "                                map(add_muon_entries_to_raw_data, bkgnd_sim_4el.head(10000).iterrows()),\n",
    "                                muon_pt_min,\n",
    "                                muon_max_eta,\n",
    "                                electron_pt_min,\n",
    "                                electron_max_eta)\n",
    "\n",
    "print(len(list(c4mu_4)))\n",
    "print(len(list(c4el_4)))\n",
    "print(len(list(c2el2mu_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "---\n",
    "Now the last essential functionality that we want to have as physicists is the plotting of various quantities. Preferably before and after a filter step. This allows us to quickly verify that the program actually did what it was supposed to and gives us a bit of a 'feel' for our data. This will be implemented as a filter that only selects the data that we want to plot and possibly a mapping to bring the filtered data into a shape that is useful for plotting. Then all that is needed to be done is to assemble everything in a `list` and then we can plot the quantity(ies) of interest. So let's implement a simple hist for a quantity of the leptons in each event.\n",
    "\n",
    "Th\n",
    "\n",
    "The extraction of the leptons is such a simple task that it can easily be done with a `lambda` function. The next problem is that for every event we can have multiple leptons. Thankfully the [itertools](https://docs.python.org/3/library/itertools.html) library is here to help with the [`chain.from_iterable`](https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable) function. (The name of the function is a link you can use to have a quick look at what it does)\n",
    "\n",
    "The cool thing is that most of the work has actually allready beed done. The last step is to extract one or more quantities from every lepton. For this we need a function that can be used with the `map` function. But as this is quite straight forward, we can again simply use a `lambda`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `keys` argument has to be a list of keys (in this case the names of the values that we want to have as strings) that can be used with the lepton. We will need to wrap this function in a `lambda`, but by now you should be used to that. We also get a problem when we get an empty array (which happened to me when I was writing this, which is why I know this (the magic of hindsight). As we now have empty arrays in our stream we have to deal with them. We can do this simply by filtering out all arrays of length 0 in a filter that we amend to it.\n",
    "\n",
    "All in all we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_leptons(events):\n",
    "    return itt.chain.from_iterable(map(lambda e: e[1]['leptons'], events))\n",
    "\n",
    "def extract_plot_data_for_leptons(leptons, plot_keys):\n",
    "    plotable_quantities = map(lambda l: [l[key] for key in plot_keys], leptons)\n",
    "    return zip(*list(plotable_quantities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think about matplotlibs `hist` function it expects an array with all values belonging to the same quantity. However we have lot's of arrays with one member of each value. We have to produce one array per key in `plot_keys` and that is exactly what `zip` does (I had asked you to read up on it earlier but here it is just in case). However `zil` does not take an iterator as an argument but a list. So we have to turn the iterator into a list.\n",
    "\n",
    "Now that we have defined how we want our arrays, we can subject the code above to a prelimiary test. I'll take the pipeline up to the point where the leptons are filtered for $p_T$ and $\\eta$ and plot $p_T$ and $\\eta$ before and after the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to build the pipeline up to this point.\n",
    "data_from_pipeline_up_to_lepton_filter =  map(calc_pseudorapidity,\n",
    "                                              map(calc_pt,\n",
    "                                                  read_in_and_reformat(bkgnd_sim_2el2mu.head(10000).iterrows())))\n",
    "\n",
    "# now we have to split of one stream that we will run through the filter and generate our plot data from\n",
    "main_stream, unfiltered_plot_stream = itt.tee(data_from_pipeline_up_to_lepton_filter)\n",
    "\n",
    "# filter the leptons from our main stream\n",
    "filtered_stream = filter_out_unfit_leptons(main_stream, muon_pt_min, muon_max_eta, electron_pt_min, electron_max_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from the unfiltered and filtered stream (also actually run the iterators and turn them into lists)\n",
    "unfiltered_lepton_plot_arrays = list(extract_plot_data_for_leptons(extract_leptons(unfiltered_plot_stream), ['pt', 'eta']))\n",
    "filtered_lepton_plot_arrays = list(extract_plot_data_for_leptons(extract_leptons(filtered_stream), ['pt', 'eta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 41592\n"
     ]
    }
   ],
   "source": [
    "print(len(unfiltered_lepton_plot_arrays), len(unfiltered_lepton_plot_arrays[0]))\n",
    "# the shape of the resulting unfiltered data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 36588\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_lepton_plot_arrays), len(filtered_lepton_plot_arrays[0]))\n",
    "# shape of the resulting filtered data set, now we only need to plot it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see the amount of leptons that existed before the filter where about 40k and that would make about 4 leptons per event at 10000 events so that is good. After we apply the filter we can see that the amount of leptons has decreased even though not by much. Now all that is left is to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0, 20))\n",
    "hist, bins, bars = ax.hist(unfiltered_lepton_plot_arrays[0], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0, 20))\n",
    "hist, bins, p = plt.hist(filtered_lepton_plot_arrays[0], 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the second plot we can see two distict bumps one at 5 and one around 7. The fact that there are no more entries under 5 is clear, as they got filtered out. However there is another spike around 7 that was not there before. This is due to the filteing of the muons starting at 7GeV. Because of this it would be nice to see the fraction of electrons vs muons in the histogram. For that we need to adapt the histogram to show stacked histogarms and we need to filter out electrons and muons. So let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the pipeline up to this point in a function so it is easy to work with\n",
    "def raw_to_filtered_and_unfiltered_lepton_events(raw_data, muon_pt_min, muon_max_eta, electron_pt_min, electron_max_eta):\n",
    "    prepared_data = map(calc_pseudorapidity, map(calc_pt, read_in_and_reformat(raw_data)))\n",
    "    main_stream, unfiltered_stream = itt.tee(prepared_data, 2)\n",
    "    filtered_stream = filter_out_unfit_leptons(main_stream, muon_pt_min, muon_max_eta, electron_pt_min, electron_max_eta)\n",
    "    return filtered_stream, unfiltered_stream\n",
    "\n",
    "\n",
    "# write the function to plot the stacked histogram\n",
    "def plot(electron_energies, muon_energies, title):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim((0, 20))\n",
    "    hist, bins, bars = ax.hist([electron_energies, muon_energies], bins=1000, stacked=True, color=['blue', 'darkblue'], label=['electrons', 'muons'])\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so lets prepare (raw_to_filtered_lepton_events allready does the splitting)\n",
    "filtered_stream, unfiltered_stream= raw_to_filtered_and_unfiltered_lepton_events(bkgnd_sim_2el2mu.head(10000).iterrows(),\n",
    "                                                                                 muon_pt_min,\n",
    "                                                                                 muon_max_eta,\n",
    "                                                                                 electron_pt_min,\n",
    "                                                                                 electron_max_eta)\n",
    "\n",
    "filtered_leptons, unfiltered_leptons = (extract_leptons(filtered_stream), extract_leptons(unfiltered_stream))\n",
    "\n",
    "# now lets split each filtered and unfiltered lepton stream into muon and electron stream\n",
    "# note these streams still contain both lepton types\n",
    "filtered_lepton_stream1, filtered_lepton_stream2 = itt.tee(filtered_leptons)\n",
    "unfiltered_lepton_stream1, unfiltered_lepton_stream2 = itt.tee(unfiltered_leptons)\n",
    "\n",
    "filtered_muons, filtered_electrons = (filter(lambda l: l['type'] == 'mu', filtered_lepton_stream1), filter(lambda l: l['type'] == 'e', filtered_lepton_stream2))\n",
    "unfiltered_muons, unfiltered_electrons = (filter(lambda l: l['type'] == 'mu', unfiltered_lepton_stream1), filter(lambda l: l['type'] == 'e', unfiltered_lepton_stream2))\n",
    "\n",
    "# extract the data from the leptons\n",
    "uf_mu_energies, uf_el_energies = (extract_plot_data_for_leptons(unfiltered_muons, ['pt']), extract_plot_data_for_leptons(unfiltered_electrons, ['pt']))\n",
    "f_mu_energies, f_el_energies = (extract_plot_data_for_leptons(filtered_muons, ['pt']), extract_plot_data_for_leptons(filtered_electrons, ['pt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(list(uf_mu_energies)[0], list(uf_el_energies)[0], 'Unfiltered lepton Energies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(list(f_mu_energies)[0], list(f_el_energies)[0], 'Filtered lepton Energies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we can see our filter works and we have been able to easily extract the neccessary values from the datastream to plot it (without the function definition it was only **8 lines** of code after all). Because we can split the stream off from any point in the pipeline, we can plot the same quantitiy over various steps without any extra code (except for say data conversion code if the format changed during the analysis process). We could also extract data from the pipeline with a similar mechanism and write it to disk rather than plot it. This is particularly useful if ther is a lot of data or there is allready a tool available to handle that aspect. It could technically also be piped directly into the tool via the operating system, but I'd generally not do that as it has a host of timing and buffer related issues that comes with it, however it still is an a possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing with the filtering process\n",
    "After this brief excursion into the land of plotting datastreams, we shal return to the task at hand, and that is finding the higgs boson after all.\n",
    "So the next thing we need to check is that we have charge parity in every event. That means that we can construct a combination of four leptons that don't have net charge. That is due to the Z boson not being charged and of course charge conservation being a fairly well established concept.\n",
    "\n",
    "By now you should know the drill, write a funciton that says `True` or `False` for an event and let the `filter` do the rest. If you need extra parameters wrap everything in a `lambda` before you throw it in the `filter` function and you are done.\n",
    "\n",
    "Lucky for you, I've allready written just that function and listed it in the cell below for your viewing pleasure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_charge_criteria(leptons, num_of_leptons_considered):\n",
    "    \"\"\"function checks if a neutral charge combination can be built from a (sub)set of leptons with length\n",
    "    num_of_leptons_considered (! the sequence of leptons in the event does not matter !)\n",
    "    \"\"\"\n",
    "    for combination in itt.combinations(leptons, num_of_leptons_considered): # itertools to the rescue (again) (you should know where to find the docs by now)\n",
    "        if sum([l['charge'] for l in leptons]) == 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the 2el2mu channel, we may notice that the electrons and muons must individually fulfill the combined charge criteria. So for that channel we again need to split the leptons of the event into the electrons and the muons and then apply the combined charge criteria to each lepton type individually and logically and the results. So we will wrap the function above so that this task can also be accomplished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_charge_criteria_for_2el2mu_channel(event):\n",
    "    electrons, muons = filter(lambda l: l['type'] == 'e', event[1]['leptons']), filter(lambda l: l['type'] == 'mu', event[1]['leptons'])\n",
    "    return combined_charge_criteria(electrons, 2) and combined_charge_criteria(muons, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the filter part from the function. As we have allready defined a function that gets the data preprocessed up to here we can attach that function to the three streams coming from that function.\n",
    "\n",
    "I would also like to say a quick word on the way to the style of code when processing three streams simultaneously. It can be done one line for one stream. I think however that that breaks the Idea that one 'logical' line in the code does one step so I use tuple unpacking and write the three function calls as part of a tuple and unpack the tuple on the other side of the assignment. You will see what I mean. I also allready have used the technique for the preperation of the filter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu, c4el, c2el2mu = read_in_reformat_split_and_filter_into_channels(\n",
    "                              map(add_electron_entries_to_raw_data, bkgnd_sim_4mu.head(10000).iterrows()),\n",
    "                              muon_pt_min,\n",
    "                              muon_max_eta,\n",
    "                              electron_pt_min,\n",
    "                              electron_max_eta)\n",
    "\n",
    "c4mu, c4el, c2el2mu = (filter(lambda e: combined_charge_criteria(e[1]['leptons'], 4), c4mu),\n",
    "                      filter(lambda e: combined_charge_criteria(e[1]['leptons'], 4), c4el),\n",
    "                      filter(combined_charge_criteria_for_2el2mu_channel, c2el2mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is possible to see in the cell above we are using the background simulation for what we are doing. As we are only interested in the signal events we actually want to reduce the background as far as possible. So after every filter step the number of events in the simulated background should decrease. The less background events after each filter the better. When we look at the signal however we hope to see that most of our simulated signal passes the tests without loosing to many events. So as you might expect the more signal after the filter the better (but it of course should never be more events than you started with, now that would be strange). Let's take a look then.\n",
    "\n",
    "---\n",
    "\n",
    "A quick sidenote here, as I don't want to reprocess the events over and over from start to this point, I'll store this intermediate result in a list so that I can use that list in all further tasks, so every time you see that list you can think of the pipeline having run up to the point indicated by the code above\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6692\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# this part is the background\n",
    "bkgnd4mu = list(c4mu)\n",
    "bkgnd4el = list(c4el)\n",
    "bkgnd2el2mu = list(c2el2mu)\n",
    "\n",
    "print(len(bkgnd4mu))\n",
    "print(len(bkgnd4el))\n",
    "print(len(bkgnd2el2mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7465\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# this is the signal exposed to the same filtering treatment\n",
    "c4mu, c4el, c2el2mu = read_in_reformat_split_and_filter_into_channels(\n",
    "                              map(add_electron_entries_to_raw_data, sig_sim_4mu.head(10000).iterrows()),\n",
    "                              muon_pt_min,\n",
    "                              muon_max_eta,\n",
    "                              electron_pt_min,\n",
    "                              electron_max_eta)\n",
    "\n",
    "c4mu, c4el, c2el2mu = (filter(lambda e: combined_charge_criteria(e[1]['leptons'], 4), c4mu),\n",
    "                      filter(lambda e: combined_charge_criteria(e[1]['leptons'], 4), c4el),\n",
    "                      filter(combined_charge_criteria_for_2el2mu_channel, c2el2mu))\n",
    "\n",
    "sig4mu = list(c4mu)\n",
    "sig4el = list(c4el)\n",
    "sig2el2mu = list(c2el2mu)\n",
    "\n",
    "print(len(sig4mu))\n",
    "print(len(sig4el))\n",
    "print(len(sig2el2mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'run': 194533.0,\n",
       "  'event': 1142211,\n",
       "  'leptons': [{'p': array([ 52.8881  , -49.2137  ,   0.527564, -19.3616  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.000377091,\n",
       "    'dz': -0.000987451,\n",
       "    'relPFIso': 0.0296542,\n",
       "    'SIP3d': 0.341185,\n",
       "    'pt': 49.21652762501735,\n",
       "    'eta': -0.23979059080346196},\n",
       "   {'p': array([104.397 ,  16.0997, -27.1821,  99.5022]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000857253,\n",
       "    'dz': 0.00553847,\n",
       "    'relPFIso': 0.0,\n",
       "    'SIP3d': 1.17472,\n",
       "    'pt': 31.592196829280486,\n",
       "    'eta': 1.8404167807158787},\n",
       "   {'p': array([ 29.9594,  24.2971,  11.0576, -13.599 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 0.00163948,\n",
       "    'dz': 0.000673754,\n",
       "    'relPFIso': 0.0445055,\n",
       "    'SIP3d': 0.74423,\n",
       "    'pt': 26.694935590295024,\n",
       "    'eta': 0.018669572037864745},\n",
       "   {'p': array([60.5544 , 14.3324 , -1.76615, 58.8072 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00102962,\n",
       "    'dz': -0.00563673,\n",
       "    'relPFIso': 0.0,\n",
       "    'SIP3d': 0.727535,\n",
       "    'pt': 14.440809381142733,\n",
       "    'eta': 2.097353293728317}]})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd4mu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'run': 1.0,\n",
       "  'event': 105642,\n",
       "  'leptons': [{'p': array([ 79.9449,  23.286 , -74.8249,  15.8164]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00312021,\n",
       "    'dz': -0.00676288,\n",
       "    'relPFIso': 0.0073249,\n",
       "    'SIP3d': 1.51874,\n",
       "    'pt': 78.3645548447128,\n",
       "    'eta': -0.9071771615996637},\n",
       "   {'p': array([ 40.1922 , -25.734  ,   5.08852,  30.4511 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000252894,\n",
       "    'dz': -0.00102557,\n",
       "    'relPFIso': 0.135003,\n",
       "    'SIP3d': 0.334146,\n",
       "    'pt': 26.232266234361074,\n",
       "    'eta': 0.8422791101464281},\n",
       "   {'p': array([14.2117 ,  3.05392, 12.0237 ,  6.933  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000425921,\n",
       "    'dz': 0.00159733,\n",
       "    'relPFIso': 0.123825,\n",
       "    'SIP3d': 0.59517,\n",
       "    'pt': 12.40547415685511,\n",
       "    'eta': 0.11130196106347652},\n",
       "   {'p': array([ 13.443   , -11.1535  ,  -0.720168,   7.46879 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00113233,\n",
       "    'dz': 0.00157865,\n",
       "    'relPFIso': 0.166812,\n",
       "    'SIP3d': 0.529128,\n",
       "    'pt': 11.176726005330183,\n",
       "    'eta': 0.29004660437429186}]})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig4mu[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news, there are more signal events then there are background events, so that is good. The bad news is that there is still very large amounts of background left. So our **SNR** or signal to noise ratio is still pretty low. The higher the SNR the easier it is to find what we are looking for.\n",
    "\n",
    "---\n",
    "Same disclaimer as above, only this time for the signal and not the background (note the different input into the pipeline here versus the one above)\n",
    "\n",
    "---\n",
    "\n",
    "To try and increase the signal to noise ratio, we can impose stricter reqirements on the transverse momentum of the leptons. This is done in the following funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_pt(leptons):\n",
    "    \"\"\"applies strict pt requirements to the leptons\"\"\"\n",
    "    pt = [l['pt'] for l in leptons]\n",
    "    pt = sorted(pt)\n",
    "    if pt[-1] < 20:\n",
    "        return False\n",
    "    if pt[-2] < 10:\n",
    "        return False\n",
    "    for momentum in pt[:-2]:\n",
    "        if momentum < 4:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What follows is again the usual dance of wrapping `strict_pt_in_event` in a `lambda` and putting that into the `filter` and then passing the stream through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1bkgnd4mu, f1bkgnd4el, f1bkgnd2el2mu = (filter(lambda e: strict_pt(e[1]['leptons']), bkgnd4mu),\n",
    "                                   filter(lambda e: strict_pt(e[1]['leptons']), bkgnd4el),\n",
    "                                   filter(lambda e: strict_pt(e[1]['leptons']), bkgnd2el2mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6426\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "f1bkgnd4mu = list(f1bkgnd4mu)\n",
    "f1bkgnd4el = list(f1bkgnd4el)\n",
    "f1bkgnd2el2mu = list(f1bkgnd2el2mu)\n",
    "print(len(f1bkgnd4mu))\n",
    "print(len(f1bkgnd4el))\n",
    "print(len(f1bkgnd2el2mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1sig4mu, f1sig4el, f1sig2el2mu = (filter(lambda e: strict_pt(e[1]['leptons']), sig4mu),\n",
    "                                   filter(lambda e: strict_pt(e[1]['leptons']), sig4el),\n",
    "                                   filter(lambda e: strict_pt(e[1]['leptons']), sig2el2mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7409\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "f1sig4mu = list(f1sig4mu)\n",
    "f1sig4el = list(f1sig4el)\n",
    "f1sig2el2mu = list(f1sig2el2mu)\n",
    "print(len(f1sig4mu))\n",
    "print(len(f1sig4el))\n",
    "print(len(f1sig2el2mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see the strict pt filter removed roughly 300 events from our background but only a few dozen from our signal events, thus making the SNR larger.\n",
    "\n",
    "Looking at this strict filter criteria, It still could be made a bit more efficient. We filtered out events that did not have a combinations of leptons where it was not possible to arrange the leptons in such a manner so that the sum of the charge was 0. We could have also added a list of tuples to the event where the numbers in the tuples would indicate the lepton that was part of a combination that had net 0 charge. Every tuple represents a combination that has net zero charge. If we had done that we could have now checked the strict pt_criteria for every possible combination and then filtered out the combinations that did not match the strict criteria and again eliminated all events that had an empty combinations list.\n",
    "\n",
    "I am doing this because the next step is Z boson mass reconstruction, where we want to know the mass of the (virtual) Z boson from which the leptons emerged. This reconstruction can be done for every combination and then the combination with the most fitting masses can be selected and all others discarded.\n",
    "\n",
    "For the reconstruction a few things are important. We need to find all combinations of two pairs of leptons that are of the same type and opposit charge.\n",
    "To do this we will build a 'mini pipeline' that will execute once per event, taking the leptons of the event as inputs and producing all valid pairings of leptons. This can be done in four steps:\n",
    "\n",
    "1. Sort the leptons by type\n",
    "2. For each lepton type sort the leptons by charge\n",
    "3. build all combinations of the differently charged leptons of the same type.\n",
    "\n",
    "So lets begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a function to generate the combinations of two pairs from two iterators\n",
    "def combinations_of_two_pairs(it1, it2):\n",
    "    product = list(itt.product(it1, it2))\n",
    "    combinations_of_two_pairs = []\n",
    "    for i, e1 in enumerate(product):\n",
    "        for e2 in product[i:]:\n",
    "            if hash(str(e1[0])) != hash(str(e2[0])) and\\\n",
    "               hash(str(e1[0])) != hash(str(e2[1])) and\\\n",
    "               hash(str(e1[1])) != hash(str(e2[0])) and\\\n",
    "               hash(str(e1[1])) != hash(str(e2[1])):\n",
    "                combinations_of_two_pairs.append((e1, e2))\n",
    "    return combinations_of_two_pairs\n",
    "\n",
    "def build_valid_combinations(leptons):\n",
    "    leptons1, leptons2 = itt.tee(leptons, 2)\n",
    "    muons = filter(lambda l: l['type'] == 'mu', leptons1)\n",
    "    electrons = filter(lambda l: l['type'] == 'e', leptons2)\n",
    "    es1, es2 = itt.tee(electrons)\n",
    "    mus1, mus2 = itt.tee(muons)\n",
    "    positrons = list(filter(lambda l: l['charge'] > 0, es1))\n",
    "    electrons = list(filter(lambda l: l['charge'] < 0, es2))\n",
    "    muons = list(filter(lambda l: l['charge'] < 0, mus1))\n",
    "    antimuons = list(filter(lambda l: l['charge'] > 0, mus2))\n",
    "    if len(positrons) == 1 and len(electrons) == 1 and\\\n",
    "       len(muons) == 1 and len(antimuons) == 1:\n",
    "        return [((positrons[0], electrons[0]), (antimuons[0], muons[0]))]  \n",
    "    return list(itt.chain(combinations_of_two_pairs(positrons, electrons), combinations_of_two_pairs(antimuons, muons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you looked closely you can see that I have diverged from the purely functional style in `combinations_of_two_paris`. I have done this as it is very difficult to do the thing I wanted to do here in fuctional style and for readability I have been pragmatic and chosen not to do that. We want to have a readable analysis, that is our primary goal. The need for a 'pure' style of the program is, I think, overly restrictive in the context of computing for physics.\n",
    "\n",
    "We still need a function that takes an event calculates the pairs and returns the event where the leptons have been removed and the lepton_combinations have been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_combinations(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    combinations = build_valid_combinations(leptons)\n",
    "    data = event[1]\n",
    "    data.pop('leptons')\n",
    "    data['lepton_combinations'] = combinations\n",
    "    return (event[0], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2bkgnd4mu, f2bkgnd4el, f2bkgnd2el2mu = (map(calculate_combinations, bkgnd4mu),\n",
    "                                         map(calculate_combinations, bkgnd4el),\n",
    "                                         map(calculate_combinations, bkgnd2el2mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2bkgnd4mu = list(f2bkgnd4mu)\n",
    "f2bkgnd4el = list(f2bkgnd4el)\n",
    "f2bkgnd2el2mu = list(f2bkgnd2el2mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the combinations now built, we have to still weed out all events that don't have a valid combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3bkgnd4mu = list(filter(lambda e: e[1]['lepton_combinations'], f2bkgnd4mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that is done, we have to calculate the invariant mass of each lepton pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandelstam_s(fourvectors):\n",
    "    vec = np.add.reduce(fourvectors)\n",
    "    minkovski_metric = np.diag(1, -1, -1, -1)\n",
    "    return vec @ (minkovski_metric @ vec)\n",
    "\n",
    "def calc_rest_enrgy_for_lepton_pair(event):\n",
    "    possible_combinations = event[1]['lepton_combinations']\n",
    "    event[1]['lepton_combinations'] = [list(map(lambda lp: (lp[0],\n",
    "                                                            lp[1],\n",
    "                                                            np.sqrt(mandelstam_s([lp[0]['p'], lp[1]['p']]))),\n",
    "                                                combination))\n",
    "                                       for combination in possible_combinations]\n",
    "    return event\n",
    "\n",
    "def pick_combination_closest_to_z_mass(event):\n",
    "    combinations = event[1]['lepton_combinations']\n",
    "    closest_combination = combinations[0]\n",
    "    for c in combinations:\n",
    "        if abs(c[0][2]-90) < abs(closest_combination[0][2]-90) or abs(c[1][2]-90) < abs(closest_combination[1][2]):\n",
    "            closest_combination = c\n",
    "    event[1]['lepton_combinations'] = c\n",
    "    return event\n",
    "\n",
    "\n",
    "def one_z_close_to_mass_shell(event, spread):\n",
    "    pairs = event[1]['lepton_combinations']\n",
    "    for p in pair:\n",
    "        if abs(p[2] - 90) < spread:\n",
    "            return True\n",
    "    return False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above function we can now construct a `map`/ `filter` sequence again. If the rest energy of both pairs lies outside of a specific range we reject the event, and accept it as signal otherwise. After this step, which we could call 'reconstruction', the only thing left to do is to aggregate the data and plot it similarly to the way it was done in the 'Plotting' Section.\n",
    "\n",
    "As this example code has gotten somewhat unweildy by now (I'm managing way to many variables for my own good), I'll compact everything (except the read in of the data as it's still fine) down into a single cell, so that you can see all the parts in action (and try and alter a few things yourself. The data that I'll load up will be a 'small' sample dataset for background and signal, and then the whole data from the different sources. I'll again do one for background data and one for signal data.\n",
    "\n",
    "As this is a single large cell, ill add comments into it to explain what is happening, for those places where it may not be obvious from the code. Also look at the docstrings of the functions (the comment right below the first line in every function).\n",
    "\n",
    "The following cell will be a very long cell, it contains however, every function that is needed from the above sections and defines the pipeline in one nice final function, that we can the fill the data into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define the functions needed. If we get them out of the way here, we can see the whole of the functional approach in (hopeffuly) comparatively few lines\n",
    "def add_electron_entries_to_raw_data(event):\n",
    "    \"\"\" Add the entries for the electrons to the events that only contain muons (4mu channel)\"\"\"\n",
    "    data = event[1]\n",
    "    data['electron_energy'] = ''\n",
    "    data['electron_px'] = ''\n",
    "    data['electron_py'] = ''\n",
    "    data['electron_pz'] = ''\n",
    "    data['electron_charge'] = ''\n",
    "    data['electron_relPFIso'] = ''\n",
    "    data['electron_dxy'] = ''\n",
    "    data['electron_dz'] = ''\n",
    "    data['electron_SIP3d'] = ''\n",
    "    return event\n",
    "\n",
    "\n",
    "def add_muon_entries_to_raw_data(event):\n",
    "    \"\"\" Add the entries for the muons to the events that only contain electrons (4el channel)\"\"\"\n",
    "    data = event[1]\n",
    "    data['muon_energy'] = ''\n",
    "    data['muon_px'] =  ''\n",
    "    data['muon_py'] = ''\n",
    "    data['muon_pz'] = ''\n",
    "    data['muon_charge'] = ''\n",
    "    data['muon_relPFIso'] = ''\n",
    "    data['muon_dxy'] = ''\n",
    "    data['muon_dz'] = ''\n",
    "    data['muon_SIP3d'] = ''\n",
    "    return event\n",
    "\n",
    "\n",
    "def parse_strings(event):\n",
    "    \"\"\" The events that are read in from the pandas dataframe contain only strings and we need\n",
    "    numbers so convert all the strings to numbers/arrays where appropriate \"\"\"\n",
    "    ed = event[1]\n",
    "    ed['muon_energy'] = np.array([float(e) for e in ed['muon_energy'].split(',') if e != ''])\n",
    "    ed['muon_px'] = np.array([float(e) for e in ed['muon_px'].split(',') if e != ''])\n",
    "    ed['muon_py'] = np.array([float(e) for e in ed['muon_py'].split(',') if e != ''])\n",
    "    ed['muon_pz'] = np.array([float(e) for e in ed['muon_pz'].split(',') if e != ''])\n",
    "    ed['muon_charge'] = np.array([float(e) for e in ed['muon_charge'].split(',') if e != ''])\n",
    "    ed['muon_relPFIso'] = np.array([float(e) for e in ed['muon_relPFIso'].split(',') if e != ''])\n",
    "    ed['muon_dxy'] = np.array([float(e) for e in ed['muon_dxy'].split(',') if e != ''])\n",
    "    ed['muon_dz'] = np.array([float(e) for e in ed['muon_dz'].split(',') if e != ''])\n",
    "    ed['muon_SIP3d'] = np.array([float(e) for e in ed['muon_SIP3d'].split(',') if e != ''])\n",
    "    ed['electron_energy'] = np.array([float(e) for e in ed['electron_energy'].split(',') if e != ''])\n",
    "    ed['electron_px'] = np.array([float(e) for e in ed['electron_px'].split(',') if e != ''])\n",
    "    ed['electron_py'] = np.array([float(e) for e in ed['electron_py'].split(',') if e != ''])\n",
    "    ed['electron_pz'] = np.array([float(e) for e in ed['electron_pz'].split(',') if e != ''])\n",
    "    ed['electron_charge'] = np.array([float(e) for e in ed['electron_charge'].split(',') if e != ''])\n",
    "    ed['electron_relPFIso'] = np.array([float(e) for e in ed['electron_relPFIso'].split(',') if e != ''])\n",
    "    ed['electron_dxy'] = np.array([float(e) for e in ed['electron_dxy'].split(',') if e != ''])\n",
    "    ed['electron_dz'] = np.array([float(e) for e in ed['electron_dz'].split(',') if e != ''])\n",
    "    ed['electron_SIP3d'] = np.array([float(e) for e in ed['electron_SIP3d'].split(',') if e != ''])\n",
    "    return (event[0], ed)\n",
    "\n",
    "\n",
    "def build_4_vectors(event):\n",
    "    \"\"\" from the various impulse numbers construct an energy-momentum fourvector \"\"\"\n",
    "    # ed stands for event-data\n",
    "    ed = event[1]\n",
    "    # transformed event-data (this will contain the data in the structure that we want)\n",
    "    ted = {}\n",
    "    e_keys = ['electron_energy', 'electron_px', 'electron_py', 'electron_pz']\n",
    "    mu_keys = ['muon_energy', 'muon_px', 'muon_py', 'muon_pz']\n",
    "    mu_vecs = np.array([[me, mpx, mpy, mpz] for me, mpx, mpy, mpz in zip(ed[mu_keys[0]], ed[mu_keys[1]], ed[mu_keys[2]], ed[mu_keys[3]])])\n",
    "    e_vecs = np.array([[ee, epx, epy, epz] for ee, epx, epy, epz in zip(ed[e_keys[0]], ed[e_keys[1]], ed[e_keys[2]], ed[e_keys[3]])])\n",
    "    ted['e_fourvector'] = e_vecs\n",
    "    ted['mu_fourvector'] = mu_vecs\n",
    "    \n",
    "    # copy the rest of the values as long as they are not redundant\n",
    "    for key in ed.keys():\n",
    "        if key not in e_keys and key not in mu_keys:\n",
    "            ted[key] = ed[key]\n",
    "        \n",
    "    return (event[0], ted)\n",
    "\n",
    "\n",
    "def to_leptons(event):\n",
    "    \"\"\" organize the data such that the information is grouped by the lepton that it belongs to. This will make the code\n",
    "    a *lot* more readable later on \"\"\"\n",
    "    data = event[1]\n",
    "    leptons = []\n",
    "    e_quantities = [data['e_fourvector'],\n",
    "                    data['electron_charge'],\n",
    "                    data['electron_relPFIso'],\n",
    "                    data['electron_dxy'],\n",
    "                    data['electron_dz'],\n",
    "                    data['electron_SIP3d']]\n",
    "    mu_quantities = [data['mu_fourvector'],\n",
    "                     data['muon_charge'],\n",
    "                     data['muon_relPFIso'],\n",
    "                     data['muon_dxy'],\n",
    "                     data['muon_dz'],\n",
    "                     data['muon_SIP3d']]\n",
    "    for fourvec, charge, relPFIso, dxy, dz, SIP3d in zip(*e_quantities):\n",
    "        lepton_dict = {'p': fourvec, 'type': 'e', 'charge': charge,\n",
    "                       'dxy': dxy, 'dz': dz, 'relPFIso': relPFIso, 'SIP3d': SIP3d}\n",
    "        leptons.append(lepton_dict)\n",
    "    for fourvec, charge, relPFIso, dxy, dz, SIP3d in zip(*mu_quantities):\n",
    "        lepton_dict = {'p': fourvec, 'type': 'mu', 'charge': charge,\n",
    "                       'dxy': dxy, 'dz': dz, 'relPFIso': relPFIso, 'SIP3d': SIP3d}\n",
    "        leptons.append(lepton_dict)\n",
    "    return (event[0], {'run': data['run'], 'event':data['event'], 'leptons': leptons})\n",
    "\n",
    "\n",
    "def calculate_transverse_momentum(fourvector):\n",
    "    \"\"\" given a fourvector this function simply calcuates the corresponding transverse momentum\n",
    "    The fourvector should follow this convention: [e, px, py, pz]\"\"\"\n",
    "    return np.sqrt(fourvector[1]**2 + fourvector[2]**2)\n",
    "\n",
    "\n",
    "def calc_pt(event):\n",
    "    \"\"\" calc the transverse momentum for each lepton of an event using the\n",
    "    calculate_transverse_momentum function to do the actual calculation. This is a 'wrapper'\n",
    "    type function \"\"\"\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'pt': calculate_transverse_momentum(l['p'])})\n",
    "    return event\n",
    "\n",
    "\n",
    "# this is the first 'filter' function as it returns True/False for an event given a criteris\n",
    "# this function needs a simple wrapper in the form of a 'lambda' function.\n",
    "def pt_min(event, min_pt):\n",
    "    \"\"\" function to be used in conjunction with a filter. filters out all\n",
    "    lepthons in an event with a transverse momentum below the min_pt threshhold\"\"\"\n",
    "    data = event[1]\n",
    "    leptons = filter(lambda lepton: lepton['pt'] > min_pt, data['leptons'])\n",
    "    return True if len(list(leptons)) > 4 else False\n",
    "\n",
    "\n",
    "def pseudorapidity(pt, pz):\n",
    "    \"\"\"calculate the pseudorapidity (eta) for a given fourvector\"\"\"\n",
    "    # remember opposite/adjacent = tan(theta)\n",
    "    return -np.log(np.abs(pt/(pz*2)))\n",
    "\n",
    "\n",
    "def phi(fourvector):\n",
    "    \"\"\" calculate the direction of the lepton in the plane vertical to the beam \"\"\"\n",
    "    vec = np.array([fourvector[1], fourvector[2]])\n",
    "    normed_vec = vec/np.linalg.norm(vec)\n",
    "    return np.arctan2(normed_vec[1], normed_vec[0])\n",
    "\n",
    "\n",
    "# the next two functions are more wrapper functions for eta and phi calculations\n",
    "def calc_pseudorapidity(event):\n",
    "    \"\"\" calculates pt for all leptons in an event \"\"\"\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'eta': pseudorapidity(l['pt'], l['p'][3])})\n",
    "    return event\n",
    "\n",
    "\n",
    "def calc_phi(event):\n",
    "    \"\"\" calculates phi for all leptons in an event \"\"\"\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'phi': phi(l['p'])})\n",
    "    return event\n",
    "\n",
    "\n",
    "# the next four functions only apply to leptons that are extracted from the event.\n",
    "# they check that the leptons satisfy some basic requirements so that they can be considered\n",
    "# in the signal reconstruction. A lot of the parameters have to do with the detector and how\n",
    "# well it can measure data in various areas.\n",
    "def lepton_pt_and_eta_requirements(lepton, pt_min, eta_max):\n",
    "    return lepton['pt'] >= pt_min and np.abs(lepton['eta']) <= eta_max\n",
    "\n",
    "\n",
    "def impact_parameter_requirements(lepton, min_SIP, max_dxy, min_dz):\n",
    "    return lepton['SIP3d'] >= min_SIP and lepton['dxy'] <= max_dxy and lepton['dz'] <= max_dz\n",
    "\n",
    "\n",
    "def relative_isolation_requirements(lepton, min_relPFIso):\n",
    "    return lepton['relPFIso'] >= min_relPFIso\n",
    "\n",
    "\n",
    "def remove_unfit_leptons(event, lepton_type, pt_min, eta_max, SIP_min, dxy_max, dz_max, rel_PFIso_min):\n",
    "    \"\"\" remove all the leptons from an event that don't meet the requirements specified by the parameters\n",
    "    that are passed into this function. This function is only a filter for the leptons in an event, but should be used\n",
    "    with a map() function as it takes in an event and should also return an event (with the leptons filtered) \"\"\"\n",
    "    leptons = event[1]['leptons']\n",
    "    other_leptons = filter(lambda l: l['type'] != lepton_type, leptons)\n",
    "    leptons_of_specified_type = filter(lambda l: l['type'] == lepton_type, leptons)\n",
    "    event[1]['leptons'] = list(itt.chain(filter(lambda l: lepton_pt_and_eta_requirements(l, pt_min, eta_max),\n",
    "                                                filter(lambda l: impact_parameter_requirements(l, SIP_min, dxy_max, dz_max), \n",
    "                                                       filter(lambda l: relative_isolation_requirements(l, rel_PFIso_min),\n",
    "                                                              leptons_of_specified_type))),\n",
    "                                         other_leptons))\n",
    "    return event\n",
    "\n",
    "\n",
    "# now that the leptons have been filtered out for each event, the event needs to have enough leptons left to do a propper\n",
    "# reconstruction, so here we filter out the events with to few leptons.\n",
    "def at_least_n_leptons_of_type(t, n, leptons):\n",
    "    \"\"\"function that can be used to filter out leptons of type t\"\"\"\n",
    "    type_t_leptons = list(filter(lambda l: l['type'] == t, leptons))\n",
    "    return len(type_t_leptons) >= n\n",
    "\n",
    "\n",
    "# these are functions that are handy to have for the plotting\n",
    "def extract_leptons(events):\n",
    "    \"\"\" turn an iterator over the events into an iterator over the leptons of all events\"\"\"\n",
    "    return itt.chain.from_iterable(map(lambda e: e[1]['leptons'], events))\n",
    "\n",
    "def extract_plot_data_for_leptons(leptons, plot_keys):\n",
    "    \"\"\" map an iterator over leptons to the quantiy/quantities of interest.\n",
    "    Be aware that this function does NOT return an iterator but a list of lists.\n",
    "    There is one list per plot key provided (the plot_keys must be iterable) \"\"\"\n",
    "    plotable_quantities = map(lambda l: [l[key] for key in plot_keys], leptons)\n",
    "    return list(zip(*list(plotable_quantities)))\n",
    "\n",
    "\n",
    "def plot(electron_energies, muon_energies, title):\n",
    "    \"\"\" Plot a histogram of the energies of the \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim((0, 20))\n",
    "    hist, bins, bars = ax.hist([electron_energies, muon_energies], bins=1000, stacked=True, color=['blue', 'darkblue'], label=['electrons', 'muons'])\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def combined_charge_criteria(leptons, num_of_leptons_considered):\n",
    "    \"\"\"function checks if a neutral charge combination can be built from a (sub)set of leptons with length\n",
    "    num_of_leptons_considered (! the sequence of leptons in the event does not matter !)\n",
    "    \"\"\"\n",
    "    for combination in itt.combinations(leptons, num_of_leptons_considered): # itertools to the rescue (again) (you should know where to find the docs by now)\n",
    "        if sum([l['charge'] for l in leptons]) == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# this is a specialized version of the function above, so it can be applied to the data in the 2el 2mu channel.\n",
    "def combined_charge_criteria_for_2el2mu_channel(event):\n",
    "    electrons, muons = filter(lambda l: l['type'] == 'e', event[1]['leptons']), filter(lambda l: l['type'] == 'mu', event[1]['leptons'])\n",
    "    return combined_charge_criteria(electrons, 2) and combined_charge_criteria(muons, 2)\n",
    "\n",
    "\n",
    "# this function, though it acts on leptons produces for True or False for an\n",
    "# entire sequence of leptons and can be used to filter out events in turn.\n",
    "def strict_pt(leptons):\n",
    "    \"\"\"applies strict pt requirements to the leptons\"\"\"\n",
    "    pt = [l['pt'] for l in leptons]\n",
    "    pt = sorted(pt)\n",
    "    if pt[-1] < 20:\n",
    "        return False\n",
    "    if pt[-2] < 10:\n",
    "        return False\n",
    "    for momentum in pt[:-2]:\n",
    "        if momentum < 4:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# we need a function to generate the combinations of two pairs from two iterators\n",
    "def combinations_of_two_pairs(it1, it2):\n",
    "    product = list(itt.product(it1, it2))\n",
    "    combinations_of_two_pairs = []\n",
    "    for i, e1 in enumerate(product):\n",
    "        for e2 in product[i:]:\n",
    "            if hash(str(e1[0])) != hash(str(e2[0])) and\\\n",
    "               hash(str(e1[0])) != hash(str(e2[1])) and\\\n",
    "               hash(str(e1[1])) != hash(str(e2[0])) and\\\n",
    "               hash(str(e1[1])) != hash(str(e2[1])):\n",
    "                combinations_of_two_pairs.append((e1, e2))\n",
    "    return combinations_of_two_pairs\n",
    "\n",
    "\n",
    "# This function is the one that we have defined moast recently, it takes a list of leptons\n",
    "# sorts it according to type and charge of the lepton into four lists and then build all\n",
    "# possible combinations that could represent a decay of two Z bosons.\n",
    "def build_valid_combinations(leptons):\n",
    "    leptons1, leptons2 = itt.tee(leptons, 2)\n",
    "    muons = filter(lambda l: l['type'] == 'mu', leptons1)\n",
    "    electrons = filter(lambda l: l['type'] == 'e', leptons2)\n",
    "    es1, es2 = itt.tee(electrons)\n",
    "    mus1, mus2 = itt.tee(muons)\n",
    "    positrons = list(filter(lambda l: l['charge'] > 0, es1))\n",
    "    electrons = list(filter(lambda l: l['charge'] < 0, es2))\n",
    "    muons = list(filter(lambda l: l['charge'] < 0, mus1))\n",
    "    antimuons = list(filter(lambda l: l['charge'] > 0, mus2))\n",
    "    if len(positrons) == 1 and len(electrons) == 1 and\\\n",
    "       len(muons) == 1 and len(antimuons) == 1:\n",
    "        return [((positrons[0], electrons[0]), (antimuons[0], muons[0]))]   \n",
    "    return list(itt.chain(combinations_of_two_pairs(positrons, electrons), combinations_of_two_pairs(antimuons, muons)))\n",
    "\n",
    "\n",
    "# another wrapper function, this time for the build_valid_combinations\n",
    "def calculate_combinations(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    combinations = build_valid_combinations(leptons)\n",
    "    data = event[1]\n",
    "    data.pop('leptons')\n",
    "    data['lepton_combinations'] = combinations\n",
    "    return (event[0], data)\n",
    "\n",
    "\n",
    "# calculate the energy in the rest frame of the particles\n",
    "# with the mentioned four vector\n",
    "def mandelstam_s(fourvectors):\n",
    "    fourvectors = np.array(fourvectors)\n",
    "    vec = np.add.reduce(fourvectors)\n",
    "    minkovski_metric = np.diag([1, -1, -1, -1])\n",
    "    return vec @ (minkovski_metric @ vec)\n",
    "\n",
    "\n",
    "# yet another wrapper function, this time we insert the energy of the rest frame into the\n",
    "# each lepton pair of each combination\n",
    "def calc_rest_enrgy_for_lepton_pairs(event):\n",
    "    possible_combinations = event[1]['lepton_combinations']\n",
    "    event[1]['lepton_combinations'] = [list(map(lambda lp: (lp[0],\n",
    "                                                            lp[1],\n",
    "                                                            np.sqrt(mandelstam_s([lp[0]['p'], lp[1]['p']]))),\n",
    "                                                combination))\n",
    "                                       for combination in possible_combinations]\n",
    "    return event\n",
    "\n",
    "\n",
    "# Here we filter out the combination of leptons (we know that the combinations conserve charge and group the leptons right)\n",
    "# to the combination that is closest to a signal like event with the rest energy of one lepton pair being close to the\n",
    "# rest mass of a Z boson.\n",
    "def pick_combination_closest_to_z_mass(event):\n",
    "    combinations = event[1]['lepton_combinations']\n",
    "    closest_combination = combinations[0]\n",
    "    for c in combinations:\n",
    "        if abs(c[0][2]-90) < abs(closest_combination[0][2]-90) or abs(c[1][2]-90) < abs(closest_combination[1][2]):\n",
    "            closest_combination = c\n",
    "    event[1]['lepton_combinations'] = c\n",
    "    return event\n",
    "\n",
    "\n",
    "# this will be an important parameter to distinguish signal from background\n",
    "def one_decay_close_to_z_mass_shell(event, spread):\n",
    "    pairs = event[1]['lepton_combinations']\n",
    "    for p in pairs:\n",
    "        if abs(p[2] - 90) < spread:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# the last thing to do is to specify global parameters that should be used with this analysis\n",
    "electron_pt_min = 7\n",
    "electron_max_eta = 2.5\n",
    "muon_pt_min = 5\n",
    "muon_max_eta = 2.4\n",
    "min_impact_param = .1\n",
    "max_dxy = .1\n",
    "max_dz = .1\n",
    "min_rel_iso = 0\n",
    "\n",
    "\n",
    "def higgs_to_4leptons_via_zz_analysis(raw_data, ept_min, eeta_max, mupt_min, mueta_max, impactparam_min, dxy_max, dz_max, reliso_min, spread):\n",
    "    # parse and reformat data\n",
    "    p_and_r_data = map(to_leptons, map(build_4_vectors, map(parse_strings, raw_data)))\n",
    "    \n",
    "    pt_and_eta_data = map(calc_pseudorapidity, map(calc_pt, p_and_r_data))\n",
    "    # filter the leptons of each event\n",
    "    # remove all muons that dont meet the requirements\n",
    "    data_with_filtered_muons = map(lambda e: remove_unfit_leptons(e, 'mu',\n",
    "                                                                  mupt_min,\n",
    "                                                                  mueta_max,\n",
    "                                                                  impactparam_min,\n",
    "                                                                  dxy_max,\n",
    "                                                                  dz_max,\n",
    "                                                                  reliso_min),\n",
    "                                     pt_and_eta_data)\n",
    "    \n",
    "    #remove all electrons that dont meet the requirements\n",
    "    data_with_filtered_leptons = map(lambda e: remove_unfit_leptons(e, 'e',\n",
    "                                                                    ept_min,\n",
    "                                                                    eeta_max,\n",
    "                                                                    impactparam_min,\n",
    "                                                                    dxy_max,\n",
    "                                                                    dz_max,\n",
    "                                                                    reliso_min),\n",
    "                                     data_with_filtered_muons)\n",
    "    \n",
    "    # now split the events into the three streams, one for each channel\n",
    "    c4mu_raw, c4el_raw, c2el2mu_raw = itt.tee(data_with_filtered_leptons, 3)\n",
    "    \n",
    "    # run the data from the unfiltered source through the filters that will only leave the data\n",
    "    # that should be in the channel\n",
    "    c4mu = filter(lambda e: at_least_n_leptons_of_type('mu', 4, e[1]['leptons']), c4mu_raw)\n",
    "    c4el = filter(lambda e: at_least_n_leptons_of_type('e', 4, e[1]['leptons']), c4el_raw)\n",
    "    c2el2mu = filter(lambda e: at_least_n_leptons_of_type('mu', 2, e[1]['leptons']),\n",
    "                     filter(lambda e: at_least_n_leptons_of_type('e', 2, e[1]['leptons']), c2el2mu_raw))\n",
    "    \n",
    "    # now all events get filtered out where no neutral charge can be constructed from the leptons\n",
    "    c4mu_f1 = filter(lambda e: combined_charge_criteria(e, 4), c4mu)\n",
    "    c4el_f1 = filter(lambda e: combined_charge_criteria(e, 4), c4el)\n",
    "    c2el2mu_f1 = filter(lambda e: combined_charge_criteria_for_2el2mu_channel, c2el2mu)\n",
    "    \n",
    "    # now we apply our strict_pt_requirements\n",
    "    c4mu_f2 = filter(lambda e: strict_pt(e[1]['leptons']), c4mu_f1)\n",
    "    c4el_f2 = filter(lambda e: strict_pt(e[1]['leptons']), c4el_f1)\n",
    "    c2el2mu_f2 = filter(lambda e: strict_pt(e[1]['leptons']), c2el2mu_f1)\n",
    "    \n",
    "    # now we determin possible combinations of the leptons into two z decays\n",
    "    c4mu_c = map(calculate_combinations, c4mu_f2)\n",
    "    c4el_c = map(calculate_combinations, c4el_f2)\n",
    "    c2el2mu_c = map(calculate_combinations, c2el2mu_f2)\n",
    "    \n",
    "    # remove all events that don't have any pairs\n",
    "    c4mu_f3 = filter(lambda e: len(e[1]['lepton_combinations']) > 0, c4mu_c)\n",
    "    c4el_f3 = filter(lambda e: len(e[1]['lepton_combinations']) > 0, c4el_c)\n",
    "    c2el2mu_f3 = filter(lambda e: len(e[1]['lepton_combinations']) > 0, c2el2mu_c)\n",
    "    \n",
    "    # calculate the rest energy for every pair\n",
    "    c4mu_re = map(calc_rest_enrgy_for_lepton_pairs, c4mu_f3)\n",
    "    c4el_re = map(calc_rest_enrgy_for_lepton_pairs, c4el_f3)\n",
    "    c2el2mu_re = map(calc_rest_enrgy_for_lepton_pairs, c2el2mu_f3)\n",
    "    \n",
    "    # chose the combination form all combinations, where the rest energy of one of the\n",
    "    # pairs is closest to the rest mass of a Z boson\n",
    "    c4mu_s = map(pick_combination_closest_to_z_mass, c4mu_re)\n",
    "    c4el_s = map(pick_combination_closest_to_z_mass, c4el_re)\n",
    "    c2el2mu_s = map(pick_combination_closest_to_z_mass, c2el2mu_re)\n",
    "    \n",
    "    # now all that's left is to filter out all the events that don't have one real and\n",
    "    # one virtual Z boson\n",
    "    c4mu_wz = filter(lambda e: one_decay_close_to_z_mass_shell(e, spread), c4mu_s)\n",
    "    c4el_wz = filter(lambda e: one_decay_close_to_z_mass_shell(e, spread), c4mu_s)\n",
    "    c2el2mu_wz = filter(lambda e: one_decay_close_to_z_mass_shell(e, spread), c2el2mu_s)\n",
    "    \n",
    "    # finally we calculate the invariant mass for every event that is left.\n",
    "    c4mu_energies = map(lambda e: sum(map(lambda pair: pair[2], e[1]['lepton_combinations'])), c4mu_wz)\n",
    "    c4el_energies = map(lambda e: sum(map(lambda pair: pair[2], e[1]['lepton_combinations'])), c4el_wz)\n",
    "    c2el2mu_energies = map(lambda e: sum(map(lambda pair: pair[2], e[1]['lepton_combinations'])), c2el2mu_wz)\n",
    "    \n",
    "    return list(c4mu_energies), list(c4el_energies), list(c2el2mu_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [],\n",
       " [186.24824592718682,\n",
       "  104.09380970282237,\n",
       "  102.14243274992775,\n",
       "  179.0295829192827,\n",
       "  180.91712043116905,\n",
       "  181.6859381603278,\n",
       "  186.95027122629944,\n",
       "  148.08600594834581,\n",
       "  185.03597465075865,\n",
       "  182.09059695670862,\n",
       "  178.8580510495828,\n",
       "  217.97626762225678,\n",
       "  185.5514487884925,\n",
       "  129.31332290428725,\n",
       "  185.0345002775197,\n",
       "  187.41199970165485,\n",
       "  185.4517067200348,\n",
       "  176.685897294707,\n",
       "  181.35551481779459,\n",
       "  177.88923715129104,\n",
       "  174.19288642556862,\n",
       "  182.40701659196145,\n",
       "  178.57936104083447,\n",
       "  175.8461980284822,\n",
       "  189.5841743902975,\n",
       "  186.12720958175578,\n",
       "  119.6461808308129,\n",
       "  176.66235465070906,\n",
       "  176.5523257392432,\n",
       "  151.08705222163073,\n",
       "  106.21885383505057,\n",
       "  178.14018715857753,\n",
       "  161.99594797480108,\n",
       "  96.65072795462676,\n",
       "  178.90394439263838,\n",
       "  187.4887789592685,\n",
       "  188.16475122405978])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbkgnd = bkgnd_sim_2el2mu.head(100).iterrows()\n",
    "testout = higgs_to_4leptons_via_zz_analysis(testbkgnd, electron_pt_min, electron_max_eta, muon_pt_min, muon_max_eta, min_impact_param, max_dxy, max_dz, min_rel_iso, 5)\n",
    "testout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [],\n",
       " [105.01316908508092,\n",
       "  108.07682136836438,\n",
       "  123.53072989581375,\n",
       "  107.11065691235078,\n",
       "  121.95755069322453,\n",
       "  113.5025195264249,\n",
       "  112.51208706178684,\n",
       "  125.46026603461169,\n",
       "  108.08640114106166,\n",
       "  117.39725707878357,\n",
       "  117.43741400058057,\n",
       "  118.62150166785317,\n",
       "  111.38162907624783,\n",
       "  119.54697150058114,\n",
       "  120.97334289026028,\n",
       "  116.79958843828231,\n",
       "  127.16640200241295,\n",
       "  101.68695641673791,\n",
       "  113.55925469826119,\n",
       "  119.59003750519655,\n",
       "  108.33382480357113,\n",
       "  109.45511479179117,\n",
       "  111.67748724480028,\n",
       "  101.06113059303985,\n",
       "  121.19922198567997,\n",
       "  112.2614370640854,\n",
       "  123.23067103668251,\n",
       "  113.17194851126558,\n",
       "  116.48078770494091,\n",
       "  111.87346907880885,\n",
       "  114.56091961191987,\n",
       "  110.24969592876317,\n",
       "  123.6517993062561,\n",
       "  124.15301895369043,\n",
       "  120.20472984879073,\n",
       "  113.6759572670401,\n",
       "  116.63489074303472,\n",
       "  120.76580345846762,\n",
       "  118.50427883097913,\n",
       "  112.8347773722129,\n",
       "  113.6363521268543,\n",
       "  117.8353320800449,\n",
       "  105.10508986707308,\n",
       "  117.25431592168208,\n",
       "  124.82475228754213,\n",
       "  113.09995639553566,\n",
       "  123.238452225228])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsig = sig_sim_2el2mu.head(100).iterrows()\n",
    "testout = higgs_to_4leptons_via_zz_analysis(testsig, electron_pt_min, electron_max_eta, muon_pt_min, muon_max_eta, min_impact_param, max_dxy, max_dz, min_rel_iso, 5)\n",
    "testout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see from the preliminary tests that the background events that pass through the pipeline have an energy well above the 125 GeV range that we expect the higgs boson in. The signal events on the other hand end up right in that range. This means that we have been able to separate signal from background so that we can see the signal events clearly.\n",
    "\n",
    "We have done it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# The pros and cons of using Python\n",
    "After you have now seen the power of functional programming in python I would like to discuss with you the different aspects of using python for such a task. We have demonstrated that such a thing *can* be done with python, but that does not mean it *must* be done in python. There are powers to this method that python simply can't use because of how python itself works and I will go into the most important two here and discuss alternatives to python and their pros and cons in turn.\n",
    "\n",
    "I wan't to warn you here, that I am somewhat oppinionated what this topic is concerned. I don't want to tell you what to do or not to do. This method however has worked for me time and time again and 'just works' in nearly every data processing task I have encountered. Compunding this is the efficiencies that can be acheived when using not only the right methods but right tools. These things are important to me but not need to be important to you which is why you may come to a vastly different conclusion than me and that is totally fine. You (hopefully) make concious choices what tools to use for the job and how to go about your business. This part is meant to give a (maybe differing) perspective and offer reasons for that perspective. In the end it is up to you to choose how to do the things you want to do.\n",
    "\n",
    "Secondly I would like to stress that there are different tasks that profit from a different view on the data and data processing. Most namely here is the training of neural networks. As you may have noticed the previous code has mostly been focused on single events and the whole Idea of pipelines is that there is a queue of events and the events are fed into the front of the pipeline the pipeline produces some desired output from the input, if neccessary by aggregating the individual events at different stages. Neural networks need to see all the data 'simultaneously' during training to be able to see patterns and correlations that would go unnoticed where it only to look at one event at a time. This is where a 'column oriented view', so a view that emphesizes a single quantity for all events (if you would group events as rows and the properties of such an event as columns (like the dataframe in the beginning) it is understandable where the term 'column oriented view' comes from) is more helpful. For me it is important to emphesize that the task of training a neural network (at least to me) is a different task of designing a data processing pipeline and needs to be treated with different considerations. This 'functional style' is not and should not be the cure to all data processing problems.\n",
    "\n",
    "It is also worth noting that the job of a scientist mostly involves the development of ideas and not the production of a ready to use product (like a command line tool or a usable library). Scientists tend to use computers as tools to prove that their Idear works and as soon as it does a paper gets written and the code (at least this seems to be the case that I see) is abandoned afterwards.\n",
    "I have some problems with this because of the way I think about things and the habbits I have developed. This is not to say that this practice is not a valid way of conducting science. I just think that too much is 'implied by the author' meaning that the author has (in my oppinion that is) too many assumptions about her/his audience. I don't like implied things because I tend to think about things differently than others (and have done so for a long time) and this means that I often don't fit the assumptions of other authors and have to work hard to then figure out what I need to know to be able to understand what I am reading. This is why in science especially I prefer explicit statements and clean readable and most importantly understandable code because it is vital to transport the Idea with all of it's possible inticacies.\n",
    "I beleive science has the duty to communicate it's findings as clearly and understandably as possible. But as this is not the reality most of us live in (I mean there are allways new papers to publish and the quality of a paper is not neccesarilt measured in it's approachableness but in it's accuracy and conciceness (which implies prior knowledge in the field)) I can only try to convince you that the extra work put into explaining the Idea is worth your time. I beleive explicit writing comes with a host of benefits that I feel the 'need for speed' in the scientific realm and this 'first to publish gets the credit of discovery' thing disincentivies. Propper communication  of an idea is for me just as important as the idea itself. As scientsist it is all we do, that is think up Ideas and communicate them to others.\n",
    "I have tried and would like to see effort put in the clear communication of the ideas expressed in computer code. This is facilitated by the use of clear and concice coding style and the use of a fitting way to express ones problem in code. I hope I have been explicit enough that you where able to understand the ideas expressed in the code above and that you have able to gain something from this document. I hope to have empowered you to do cool things with this and other ideas. In turn I hope that you will take the time (just as I have) to express your idears with the care they deserve so that they may bear fruit in others minds to collectively advance our understanding of the universe, one tiny step at a time.\n",
    "\n",
    "So after this lengthy motivation, on to the things I would like to say:\n",
    "## Python is not parallel\n",
    "As you have seen a pipeline is made up of many different steps, (i'll switch analogies now) like a conveir belt passing the item to be produces (I'll use a car for this) through various different stations, in a pipeline data is similarly passed through various different stations. Each station performs a specific action on the data (mostly it either calculates a new property for the value or filters the data depending on a specific property). As each station only acts uppon one item at a time and then passes that item along to the next station, in principle there is nothing stopping us from running our data processing job the same way Toyota or Ford run their factories, effectively having every station running in parrallel on different items. As long as each station knows where to pass the item to when it is done parallelisation is trivial. On top of that we have the benefit of being able to simply open up new assembly lines if we want more data to be processed (just as Ford or Tesla would open a new factory to be able to produce more cars). As long as there is enough input to feed the pipelines with, it is trivial to have the processing run on a million cores all at once. Using this mental model, python will quickly throw a wrench in the proverbial conveir belt.\n",
    "\n",
    "### Meet the GIL\n",
    "The GIL (or more commonly known as the <u>G</u>lobal <u>I</u>nterpreter <u>L</u>ock) is something that is baked deep into the core of python. Let me explain.\n",
    "\n",
    "As you may have noticed, there is no memory management in python. What is memmory management you ask, well here is a short summary:\n",
    "\n",
    "- Memmory management is the task of tracking if a value or variable is still needed by the running program and dealing with the value in such a way that it is available when needed and that the variable has the value that the program would imply at the point where the value is needed. This is a bit more of a problem than it is made out to be. Memmory management means that all values and variables have to be tracked through the entire programs lifetime. It should not be able to alter the content of a variable in an unforseen way and last but not least the program should only need as much memmory as neccesary to perform it's task.\n",
    "\n",
    "The second requirement is the triky one for python. Namely making sure the variable has the value that the programmer was expecting when they wrote the code. To help you understand I'll show you an example:\n",
    "\n",
    "```python\n",
    "x = 5\n",
    "print(x)\n",
    "x = 42\n",
    "```\n",
    "\n",
    "Reading this code (or imagine you are the programmer and you have just written these three lines of code) you would expect python to print the following line\n",
    "\n",
    "```\n",
    "5\n",
    "```\n",
    "\n",
    "In a truly parallel environment however two or more python interpreters would be operating on the same data. this means that if python interpreter no. 1 executes the first line and the python interpreter no. 2 executes the third line before no. 1 can execute the second line we would automatically get the following output\n",
    "\n",
    "```\n",
    "5\n",
    "42\n",
    "```\n",
    "\n",
    "The first five comes from interpreter no. 2 that has executed line 1 and 2. Interpreter no. 1 is a bit slower (I'm not going into detail why here, so you best trust me that this is indeed something that is likely to happen, or at least likely enough that it can't be ignored) so during that time it was only able to execute line 1. Now No. 1 starts to interpret line 2 and starts working through the code of the `print` statement, but has not read the value of x yet. Now No 2. arrives at the third statement and changes `x` according to the statement to the value `42`. Now that No. 1 arrives at the point in the `print` statement where it wants to read `x` it does so but because No. 2 has allready changed the value to `42` it prints the second line of the output. After line 3 No. 2 is done and shuts down. No. 1 finally also sets `x` to `42` (which is redundant at this point but computers are stupid and do what they are told) and also shuts down.\n",
    "\n",
    "From this you can see that if truly parrallel programs operate on the same data mechanisms are needed to keep those kind of things from happening. As python does not force it's programmers to declare anything about the variables they are using and deducing that from the code written would mean that python could effectively not operate in interactive mode (along with a host of other considerations like execution time and so forth), the c-python developers opted for restricting a single running interpreter. So with that restriction the situation above is impossible as there can't be a No. 2 interpreter. On the other hand there cannot be a conveir belt style factory either as we cant have the different stations running in parallel. There is not enough 'snakes' to run such a factory (we have restricted ourselves to only one snake per factory after all). And if we need one snake to run one station, that means that only one station can be running in at a time (and the poor snake has to slither from one station to the next over and over (this is more of a real concern than you might think)).\n",
    "\n",
    "### Remedies for this while still using python\n",
    "We can't have multiple 'snakes' in one factory, or in more technical terms, we can't have more than one thread in a process. However the operating system is more than happy enough to let us start up more than one process. This means that we still can have more than one factory, each run by a single snake. That means that we still can spawn one process for each processor core of our computer, fully using the hardware that is there to be used. As we are effectively running the same program in parallel, we can increase performance by a factor equal to the number of cores available for the process. The thing is that moving data between processes and the snake slithering from one station to the next still causes delays that can be reduced, but the GIL is stopping us from being able to attack those problems.\n",
    "\n",
    "## Python is... well... slow!\n",
    "Python has some really cool features: well built and supported libraries, a clean and readable syntax that gets out of your way, automatic memmory management (that restricts us as you have seen in the previous section), support for different programming styles, interactive sessions ....\n",
    "\n",
    "It however is also rather slow, especially when compared to high performance code that the kind of things like data analysis pipelines for terrabytes of data usually should be. This is due to a few things (that are also some of the strengths of python) Let me again explain ...\n",
    "\n",
    "### Python is ... interpreted\n",
    "The main reason that python is slow compared to languages like C or Fortran (frankly these examples are actually some of the fastest languages out there) and this is due to the fact that python is closer to a [shell script](https://en.wikipedia.org/wiki/Shell_script) than an 'actual' program. With 'actual' program I don't want to imply that writing python code is not programming, nor do I want to communicate that python is somehow less able (in terms of functionality as opposed to performance) than C or FORTRAN code. In terms of features, python clearly wins out against these languages (at least in my oppinion). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate method for Exercise 7\n",
    "\n",
    "In this document I will try to show how the use of functional methods can make data analysis approachable and understandable while increasing the possible performance in various ways. This neccessiataes a fundamental shift in how the analysis is designed in terms of program structure. This however does not sacrifice any functionality in terms of possible analyses methods in comparison with the widely used object oriented method of writing Analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary directories present.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from include.RandomHelper import check_data_state\n",
    "check_data_state(directory=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first step the data should be read in. This is done with the pandas module, a third party data analysis framework for python. The data is read into a `dataframe` object that is defined by the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Background simulation\n",
    "bkgnd_sim_file_1 = \"./data/for_long_analysis/mc_init/MC_2012_ZZ_to_4L_2el2mu.csv\"\n",
    "bkgnd_sim_file_2 = \"./data/for_long_analysis/mc_init/MC_2012_ZZ_to_4L_4mu.csv\"\n",
    "bkgnd_sim_file_3 = \"./data/for_long_analysis/mc_init/MC_2012_ZZ_to_4L_4el.csv\"\n",
    "\n",
    "# Signal simulation\n",
    "sig_sim_file_1 = \"./data/for_long_analysis/mc_init/MC_2012_H_to_ZZ_to_4L_2el2mu.csv\"\n",
    "sig_sim_file_2 = \"./data/for_long_analysis/mc_init/MC_2012_H_to_ZZ_to_4L_4mu.csv\"\n",
    "sig_sim_file_3 = \"./data/for_long_analysis/mc_init/MC_2012_H_to_ZZ_to_4L_4el.csv\"\n",
    "\n",
    "bkgnd_sim_2el2mu = pd.read_csv(bkgnd_sim_file_1, delimiter=\";\")\n",
    "bkgnd_sim_4mu = pd.read_csv(bkgnd_sim_file_2, delimiter=\";\")\n",
    "bkgnd_sim_4el = pd.read_csv(bkgnd_sim_file_3, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the data\n",
    "The data described here is data generated by mote-carlo event generators and is split into background and signal simulation. To optimize our analysis we will use the monte-carlo data to make sure that the analysis is not artificially tuned to find a peak in the real data but only find a peak that we put there (in the simulation). If the peak is not there in the data we can be sure that our analysis would have picked it up and therefore can say if there was a peak at the predicted location or not without having to worry about if the analysis was skewed to find the peak because you thought there ought to be one and then made the analysis to produce data to fit your conclusion.\n",
    "\n",
    "The pandas dataframes that we loaded currently only describe the background (the background that we expect according to the predictions of the standard model). More precicely they describe the background that is expected in the 2e2mu channel. the other dataframe de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's examine the data in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>muon_energy</th>\n",
       "      <th>muon_px</th>\n",
       "      <th>muon_py</th>\n",
       "      <th>muon_pz</th>\n",
       "      <th>muon_charge</th>\n",
       "      <th>muon_relPFIso</th>\n",
       "      <th>muon_dxy</th>\n",
       "      <th>muon_dz</th>\n",
       "      <th>muon_SIP3d</th>\n",
       "      <th>electron_energy</th>\n",
       "      <th>electron_px</th>\n",
       "      <th>electron_py</th>\n",
       "      <th>electron_pz</th>\n",
       "      <th>electron_charge</th>\n",
       "      <th>electron_relPFIso</th>\n",
       "      <th>electron_dxy</th>\n",
       "      <th>electron_dz</th>\n",
       "      <th>electron_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846714</td>\n",
       "      <td>2823</td>\n",
       "      <td>55.3949,35.6495</td>\n",
       "      <td>-48.399,31.2184</td>\n",
       "      <td>24.7739,-15.0449</td>\n",
       "      <td>-10.6009,8.36253</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.0209805,0.0524248</td>\n",
       "      <td>-0.00105939,-0.00198611</td>\n",
       "      <td>0.00580479,-0.000121758</td>\n",
       "      <td>1.6412,0.661312</td>\n",
       "      <td>254.196,36.8009</td>\n",
       "      <td>18.0862,-12.0845</td>\n",
       "      <td>-48.5142,24.8936</td>\n",
       "      <td>-248.867,-24.2607</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.0250167,0.0712457</td>\n",
       "      <td>-0.0028464,0.000602746</td>\n",
       "      <td>-0.00391345,0.00170042</td>\n",
       "      <td>0.47657,0.431616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846715</td>\n",
       "      <td>2823</td>\n",
       "      <td>46.227,17.1694</td>\n",
       "      <td>-2.8323,11.2507</td>\n",
       "      <td>-13.9613,-1.2918</td>\n",
       "      <td>-43.9771,-12.9046</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.191416,0.17468</td>\n",
       "      <td>0.00761235,-0.000309401</td>\n",
       "      <td>-0.00194986,0.00129964</td>\n",
       "      <td>0.946415,0.308535</td>\n",
       "      <td>82.9044,11.4583</td>\n",
       "      <td>1.71208,-8.54741</td>\n",
       "      <td>28.2926,2.83502</td>\n",
       "      <td>-77.9085,7.08491</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.15352,0.515702</td>\n",
       "      <td>-0.00206888,0.00300649</td>\n",
       "      <td>-0.00538221,7.12868e-05</td>\n",
       "      <td>0.937364,0.413622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846723</td>\n",
       "      <td>2823</td>\n",
       "      <td>19.461,10.3101</td>\n",
       "      <td>11.2609,9.16698</td>\n",
       "      <td>-10.3577,-2.32848</td>\n",
       "      <td>-12.0261,4.10262</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.155083,0.221734</td>\n",
       "      <td>0.000703356,0.00115165</td>\n",
       "      <td>0.000846168,-0.00065684</td>\n",
       "      <td>0.296126,0.240591</td>\n",
       "      <td>42.9922,71.6306</td>\n",
       "      <td>-16.5883,5.92063</td>\n",
       "      <td>38.9813,-30.8763</td>\n",
       "      <td>-7.32215,-64.3627</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.103053,0.0723279</td>\n",
       "      <td>-0.000581222,-0.023985</td>\n",
       "      <td>0.00161887,0.0172354</td>\n",
       "      <td>0.369838,4.44646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846753</td>\n",
       "      <td>2823</td>\n",
       "      <td>8.09622,7.72517</td>\n",
       "      <td>0.0821112,-2.40281</td>\n",
       "      <td>6.51906,-6.02051</td>\n",
       "      <td>4.79925,4.20085</td>\n",
       "      <td>-1,1</td>\n",
       "      <td>0.216925,0.41674</td>\n",
       "      <td>0.000483781,-0.00335737</td>\n",
       "      <td>-0.00433865,-0.00260739</td>\n",
       "      <td>0.973179,0.868803</td>\n",
       "      <td>39.5647,98.4103</td>\n",
       "      <td>35.2052,-31.9606</td>\n",
       "      <td>18.029,-9.41048</td>\n",
       "      <td>0.956613,92.5988</td>\n",
       "      <td>1,-1</td>\n",
       "      <td>0.1432,0.049916</td>\n",
       "      <td>0.00165894,-0.000320531</td>\n",
       "      <td>0.0132108,0.00052476</td>\n",
       "      <td>1.92044,0.0866598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>846763</td>\n",
       "      <td>2823</td>\n",
       "      <td>71.6791,80.8522</td>\n",
       "      <td>64.102,25.6134</td>\n",
       "      <td>-26.1167,41.6729</td>\n",
       "      <td>18.6209,64.3769</td>\n",
       "      <td>1,-1</td>\n",
       "      <td>0.014919,0.013307</td>\n",
       "      <td>-0.000143862,-0.000591512</td>\n",
       "      <td>-0.00487695,0.00341611</td>\n",
       "      <td>1.44616,0.757034</td>\n",
       "      <td>81.314,11.1153</td>\n",
       "      <td>-78.6539,-10.3513</td>\n",
       "      <td>-11.2899,-3.73267</td>\n",
       "      <td>17.2646,-1.57127</td>\n",
       "      <td>1,-1</td>\n",
       "      <td>0.0136104,0.250511</td>\n",
       "      <td>-0.000410155,-0.00214753</td>\n",
       "      <td>0.00174084,-0.00185153</td>\n",
       "      <td>0.465797,0.454134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run   event  luminosity_section      muon_energy             muon_px  \\\n",
       "0  194533.0  846714                2823  55.3949,35.6495     -48.399,31.2184   \n",
       "1  194533.0  846715                2823   46.227,17.1694     -2.8323,11.2507   \n",
       "2  194533.0  846723                2823   19.461,10.3101     11.2609,9.16698   \n",
       "3  194533.0  846753                2823  8.09622,7.72517  0.0821112,-2.40281   \n",
       "4  194533.0  846763                2823  71.6791,80.8522      64.102,25.6134   \n",
       "\n",
       "             muon_py            muon_pz muon_charge        muon_relPFIso  \\\n",
       "0   24.7739,-15.0449   -10.6009,8.36253        -1,1  0.0209805,0.0524248   \n",
       "1   -13.9613,-1.2918  -43.9771,-12.9046        -1,1     0.191416,0.17468   \n",
       "2  -10.3577,-2.32848   -12.0261,4.10262        -1,1    0.155083,0.221734   \n",
       "3   6.51906,-6.02051    4.79925,4.20085        -1,1     0.216925,0.41674   \n",
       "4   -26.1167,41.6729    18.6209,64.3769        1,-1    0.014919,0.013307   \n",
       "\n",
       "                    muon_dxy                  muon_dz         muon_SIP3d  \\\n",
       "0    -0.00105939,-0.00198611  0.00580479,-0.000121758    1.6412,0.661312   \n",
       "1    0.00761235,-0.000309401   -0.00194986,0.00129964  0.946415,0.308535   \n",
       "2     0.000703356,0.00115165  0.000846168,-0.00065684  0.296126,0.240591   \n",
       "3    0.000483781,-0.00335737  -0.00433865,-0.00260739  0.973179,0.868803   \n",
       "4  -0.000143862,-0.000591512   -0.00487695,0.00341611   1.44616,0.757034   \n",
       "\n",
       "   electron_energy        electron_px        electron_py        electron_pz  \\\n",
       "0  254.196,36.8009   18.0862,-12.0845   -48.5142,24.8936  -248.867,-24.2607   \n",
       "1  82.9044,11.4583   1.71208,-8.54741    28.2926,2.83502   -77.9085,7.08491   \n",
       "2  42.9922,71.6306   -16.5883,5.92063   38.9813,-30.8763  -7.32215,-64.3627   \n",
       "3  39.5647,98.4103   35.2052,-31.9606    18.029,-9.41048   0.956613,92.5988   \n",
       "4   81.314,11.1153  -78.6539,-10.3513  -11.2899,-3.73267   17.2646,-1.57127   \n",
       "\n",
       "  electron_charge    electron_relPFIso              electron_dxy  \\\n",
       "0            -1,1  0.0250167,0.0712457    -0.0028464,0.000602746   \n",
       "1            -1,1     0.15352,0.515702    -0.00206888,0.00300649   \n",
       "2            -1,1   0.103053,0.0723279    -0.000581222,-0.023985   \n",
       "3            1,-1      0.1432,0.049916   0.00165894,-0.000320531   \n",
       "4            1,-1   0.0136104,0.250511  -0.000410155,-0.00214753   \n",
       "\n",
       "               electron_dz     electron_SIP3d  \n",
       "0   -0.00391345,0.00170042   0.47657,0.431616  \n",
       "1  -0.00538221,7.12868e-05  0.937364,0.413622  \n",
       "2     0.00161887,0.0172354   0.369838,4.44646  \n",
       "3     0.0132108,0.00052476  1.92044,0.0866598  \n",
       "4   0.00174084,-0.00185153  0.465797,0.454134  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_2el2mu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>muon_energy</th>\n",
       "      <th>muon_px</th>\n",
       "      <th>muon_py</th>\n",
       "      <th>muon_pz</th>\n",
       "      <th>muon_charge</th>\n",
       "      <th>muon_relPFIso</th>\n",
       "      <th>muon_dxy</th>\n",
       "      <th>muon_dz</th>\n",
       "      <th>muon_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142211</td>\n",
       "      <td>3809</td>\n",
       "      <td>52.8881,104.397,29.9594,60.5544</td>\n",
       "      <td>-49.2137,16.0997,24.2971,14.3324</td>\n",
       "      <td>0.527564,-27.1821,11.0576,-1.76615</td>\n",
       "      <td>-19.3616,99.5022,-13.599,58.8072</td>\n",
       "      <td>1,-1,-1,1</td>\n",
       "      <td>0.0296542,0,0.0445055,0</td>\n",
       "      <td>-0.000377091,-0.000857253,0.00163948,-0.00102962</td>\n",
       "      <td>-0.000987451,0.00553847,0.000673754,-0.00563673</td>\n",
       "      <td>0.341185,1.17472,0.74423,0.727535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142219</td>\n",
       "      <td>3809</td>\n",
       "      <td>113.521,30.6528,11.4094,9.06379</td>\n",
       "      <td>37.3417,-30.5574,-3.5702,-7.26697</td>\n",
       "      <td>-15.5895,2.03743,8.37685,-2.60909</td>\n",
       "      <td>106.064,-1.29509,-6.87345,-4.74604</td>\n",
       "      <td>-1,1,1,-1</td>\n",
       "      <td>0.0125911,0.0117654,0.0899817,0.248405</td>\n",
       "      <td>0.000726053,-0.000136719,0.00150134,-0.00245663</td>\n",
       "      <td>-0.00287983,-0.000185169,0.00946114,0.00240733</td>\n",
       "      <td>0.441156,0.103343,1.74382,0.729126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142220</td>\n",
       "      <td>3809</td>\n",
       "      <td>37.5417,32.4731,12.4247,10.6322</td>\n",
       "      <td>-2.73565,7.73404,-6.42318,-4.64318</td>\n",
       "      <td>-32.3749,29.0231,10.0461,9.51578</td>\n",
       "      <td>-18.8082,12.3425,3.49,-0.961091</td>\n",
       "      <td>-1,1,-1,1</td>\n",
       "      <td>0.055162,0.188471,0.100481,0.0632636</td>\n",
       "      <td>0.000818172,0.00046863,0.00134882,-0.00210051</td>\n",
       "      <td>0.000417443,0.00251968,-0.00210166,0.00386756</td>\n",
       "      <td>0.284802,0.838615,0.697662,0.928048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142228</td>\n",
       "      <td>3809</td>\n",
       "      <td>264.068,79.0522,66.5292,86.7354</td>\n",
       "      <td>99.6408,-69.2727,-1.5023,-1.36519</td>\n",
       "      <td>-14.9597,13.4225,36.1747,-25.441</td>\n",
       "      <td>244.09,35.6422,55.8145,82.9091</td>\n",
       "      <td>1,1,-1,-1</td>\n",
       "      <td>0.0194944,0.023523,0.051396,0.0</td>\n",
       "      <td>-0.000898767,-0.000213138,-0.00100135,0.00651469</td>\n",
       "      <td>0.00257914,-0.00103711,-0.00125057,-0.0108969</td>\n",
       "      <td>0.617079,0.401096,0.416188,1.9014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142229</td>\n",
       "      <td>3809</td>\n",
       "      <td>56.8948,40.0339,28.6141,21.4495</td>\n",
       "      <td>27.7498,-24.7057,9.16045,-5.26999</td>\n",
       "      <td>-28.8856,18.0678,8.47077,6.4065</td>\n",
       "      <td>40.4052,25.8047,25.7505,19.7801</td>\n",
       "      <td>-1,1,-1,1</td>\n",
       "      <td>0,0.00768358,0.0969734,0</td>\n",
       "      <td>-0.000252906,-0.000368003,0.00109531,0.000284646</td>\n",
       "      <td>-0.00435722,0.00268917,-0.000446212,0.00316748</td>\n",
       "      <td>1.24902,0.757682,0.208022,0.445693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run    event  luminosity_section                      muon_energy  \\\n",
       "0  194533.0  1142211                3809  52.8881,104.397,29.9594,60.5544   \n",
       "1  194533.0  1142219                3809  113.521,30.6528,11.4094,9.06379   \n",
       "2  194533.0  1142220                3809  37.5417,32.4731,12.4247,10.6322   \n",
       "3  194533.0  1142228                3809  264.068,79.0522,66.5292,86.7354   \n",
       "4  194533.0  1142229                3809  56.8948,40.0339,28.6141,21.4495   \n",
       "\n",
       "                              muon_px                             muon_py  \\\n",
       "0    -49.2137,16.0997,24.2971,14.3324  0.527564,-27.1821,11.0576,-1.76615   \n",
       "1   37.3417,-30.5574,-3.5702,-7.26697   -15.5895,2.03743,8.37685,-2.60909   \n",
       "2  -2.73565,7.73404,-6.42318,-4.64318    -32.3749,29.0231,10.0461,9.51578   \n",
       "3   99.6408,-69.2727,-1.5023,-1.36519    -14.9597,13.4225,36.1747,-25.441   \n",
       "4   27.7498,-24.7057,9.16045,-5.26999     -28.8856,18.0678,8.47077,6.4065   \n",
       "\n",
       "                              muon_pz muon_charge  \\\n",
       "0    -19.3616,99.5022,-13.599,58.8072   1,-1,-1,1   \n",
       "1  106.064,-1.29509,-6.87345,-4.74604   -1,1,1,-1   \n",
       "2     -18.8082,12.3425,3.49,-0.961091   -1,1,-1,1   \n",
       "3      244.09,35.6422,55.8145,82.9091   1,1,-1,-1   \n",
       "4     40.4052,25.8047,25.7505,19.7801   -1,1,-1,1   \n",
       "\n",
       "                            muon_relPFIso  \\\n",
       "0                 0.0296542,0,0.0445055,0   \n",
       "1  0.0125911,0.0117654,0.0899817,0.248405   \n",
       "2    0.055162,0.188471,0.100481,0.0632636   \n",
       "3         0.0194944,0.023523,0.051396,0.0   \n",
       "4                0,0.00768358,0.0969734,0   \n",
       "\n",
       "                                           muon_dxy  \\\n",
       "0  -0.000377091,-0.000857253,0.00163948,-0.00102962   \n",
       "1   0.000726053,-0.000136719,0.00150134,-0.00245663   \n",
       "2     0.000818172,0.00046863,0.00134882,-0.00210051   \n",
       "3  -0.000898767,-0.000213138,-0.00100135,0.00651469   \n",
       "4  -0.000252906,-0.000368003,0.00109531,0.000284646   \n",
       "\n",
       "                                           muon_dz  \\\n",
       "0  -0.000987451,0.00553847,0.000673754,-0.00563673   \n",
       "1   -0.00287983,-0.000185169,0.00946114,0.00240733   \n",
       "2    0.000417443,0.00251968,-0.00210166,0.00386756   \n",
       "3    0.00257914,-0.00103711,-0.00125057,-0.0108969   \n",
       "4   -0.00435722,0.00268917,-0.000446212,0.00316748   \n",
       "\n",
       "                            muon_SIP3d  \n",
       "0    0.341185,1.17472,0.74423,0.727535  \n",
       "1   0.441156,0.103343,1.74382,0.729126  \n",
       "2  0.284802,0.838615,0.697662,0.928048  \n",
       "3    0.617079,0.401096,0.416188,1.9014  \n",
       "4   1.24902,0.757682,0.208022,0.445693  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_4mu.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bkgnd_sim_2el2mu['muon_energy'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the some columns have been parsed as strings. We need to fix that and convert the strings to lists of floating point numbers. Depending on a few things there are (more or less) two approaches that can be used to perform this step and all further steps of the data processing.\n",
    "1. The first method is using a functional programming style. This means that as a first step a set of functions are applied that act on one single event, taking in the entire event, somehow modifying it and then returning that modified event. These functions will then be used with pythons internal filter and map methods. This is a data-flow centric approach where, using map and filter, the functions are combined into a data pipeline and then the data is fed through the pipeline. It uses iterators as central objects for the creation of the pipeline that then feed the data through one element at a time. This document will focus on the this first approach.\n",
    "\n",
    "2. The second method is an approach that is more like a spreadsheet. The original data is still kept and if a quantity needs to be calculated or some subset of the data needs to be altered for each and every event (such as the parsing of the string into an array of floats) then either a column is modified or a new column is added to the table. Further more the data in the table can be aggregated in various ways to \"answer questions about the data\" (that was using data science speak). This approach does not really think about \"flows\" of data but treats everything like a giant spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The functional / data-flow approach\n",
    "---\n",
    "So for this part I will demonstrate the data-flow approach using python iterators and the filter/map functions from python's core\n",
    "\n",
    "First of all we need to transform the data of the pandas dataframe into an iterator so that we can apply all further operations using map and filter (and a few other neat functions that are provided in the `itertools` module of the python standard library (these are a few functions that do neat things with iterators)\n",
    "\n",
    "But you legitamely might be asking what an iterator actually is. And the technical answer to that question is:\n",
    "\n",
    ">An iterator is something you can call next() on as in `next(something)`. By definition that something is an iterator\n",
    "\n",
    "Let me note that `next()` is not an attribute call here but an [built in function](https://docs.python.org/3/library/functions.html) of python. This is part of what makes iterators somewhat special in python.\n",
    "\n",
    "In less technical terms, an iterator is something that can produce a value of a certain structure (or type more precicely). That means if we have the iterator `something` and `next(something)` produces a `tuple(int, float, str)` then any subsequent calls should produce a `tuple(int, float, str)`. I say should here because there are exceptions to this but that will not be discussed here. If the iterator can't return anything anymore it raises the `StopIteration` exception, which essentially signals to the pipeline that no more data is coming.\n",
    "\n",
    "Iterators are essentially abstractions of lists. And sure enough a list in python is an iterator (anthing that can be used in a `for` loop is an iterator because 'under the hood' the for loop goes through an iterator one by one and applies whatever is specified in the for loop to each item it gets from the iterator. The difference is that iterators don't neccesarily need to be lists, they just need to know how to produce the next item.\n",
    "\n",
    "Let's look at a typical thing that python newcomers tend to write:\n",
    "\n",
    "```python\n",
    "data = [1, 2, 3, 4, 5, 6]\n",
    "for i in range(len(data)):\n",
    "    data[i] += 4\n",
    "```\n",
    "Now we could think that `range(len(data))` is a list but it is not, as discussed it is an iterator. because range knows when to stop and how to generate the next item from the current one (in this case it adds `1` to the current count) and returns it when `next()` is called on it.\n",
    "\n",
    "A similar thing can be done for random numbers, instead of fillig an array with random numbers an iterator can be used because the function that generates the random numbers must allways know how to generate the next random number from some internal state. So we could generate the next number exactly and only when we need it. This eliminates the need to keep massive amounts of random numbers in the main memory and makes programs a lot more recource efficient (with some caveats I won't go into). Essentially the only thing we need to be able to do is somehow 'pause' the random number function right after generating a random number and hit the proverbial 'play' button as soon as we want the next number and hit 'pause' again right after the number was generated. This way of writing a function has already been done for many things in python so I won't go into it here [they are called 'generators' just fyi](https://docs.python.org/3/glossary.html#term-generator).\n",
    "\n",
    "For more information you can also read [this document on functional programming in python](https://docs.python.org/3/howto/functional.html)\n",
    "\n",
    "The thing this enables is to wrap iterators around each other and we will allways get back an interator. This is what the `map` and `filter` methods do.\n",
    "Let's look at what happens when we have an example iterator (I'll use a simple list here as the iterator but it can easily be something different as long as it is an iterator) that returns a tuple of 3 numbers and that is wrapped with some map and filter methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x7fe144d89690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_first_two_nums(elem):\n",
    "    return (elem[0], elem[1], elem[2], elem[0]+elem[1])\n",
    "\n",
    "def sum_over_10(elem):\n",
    "    return True if elem[3] > 10 else False\n",
    "   \n",
    "def sub_3rd_from_1st(elem):\n",
    "    return (elem[0], elem[1], elem[2], elem[3], elem[0]-elem[2])\n",
    "\n",
    "def negative_difference(elem):\n",
    "    return True if elem[4] < 0 else False\n",
    "\n",
    "data = [(1,2,3), (4,5,6), (7,8,9), (3,2,1), (6,5,4), (9,8,7), (15, 0, 2)]\n",
    "data1 = map(add_first_two_nums, data)\n",
    "filtered_data1 = filter(sum_over_10, data1)\n",
    "data2 = map(sub_3rd_from_1st, filtered_data1)\n",
    "filtered_data2 = filter(negative_difference, data2)\n",
    "filtered_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see `filtered_data2` is not a list of tuples, which I would have expected if I had not known better. As I said before what we have built here is an iterator, not the data. we can however call `next()` on `filtered_data2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 9, 15, -2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(filtered_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which gives an item and as we can see it has 5 numbers as part of it. The fourth element is the sum of the first two elements (just as we have specified) and the last element is the difference between the first and third element. We can also see that the third element is larger than 10 and the fourth element is negative so the data also satisfies all our criteria that we defined in the filters. It is also not the first element of the sequence but the first element of the list that satisfies all criteria that we applied.\n",
    "\n",
    "As this is a pipeline, the sequence of operations is important any element that does not satisfy the first requirement is dropped at the first filter so cant even reach the second filter so even if it would pass the requirements of the second filter it won't be shown (just as water in a stream that is used or diverted can't be used downstream of the point of diversion/use). This may be obvious but I wanted to point this out just in case.\n",
    "\n",
    "calling `next()` again will subsequently result in either the next element that satisfies the all filteres or in a `StopIteration` exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4306937be14d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(filtered_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is no further data that meets the requirements `next()` raises an exception of the aforementioned type.\n",
    "\n",
    "It is also important to note that iterators are 'consumed' i.e. once the `StopIteration` exeption was raised by an iterator it can no longer be used. This also applies to all iterators that are passed to a subsequent iterator. So in our case `filtered_data1` will also raise a `StopIteration` exception even though we have not called `next()` explicitly on it (`next()` was implicitly called by the `data2` iterator on which `next()` was implicitly called by the `filtered_data2` iterator which we explicitly called `next()` on).\n",
    "\n",
    "But just to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-aeb41227be58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(filtered_data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as expected, we get an `StopIteration` exception.\n",
    "\n",
    "The [itertools](https://docs.python.org/3/library/itertools.html) module of the standard library has a few iterators that take on the role of various 'flow management' tasks like splitting an iterator into two iterators or repeating a variable a few times, accumulate things and other tasks. This module is really useful and is definitely better than building your own iterator for a problem. Remember all these iterators can be chained to make more complex iterators that can then be reused on different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets start with the actual task. First of as before, we need to parse all entries that are strings into numpy arrays. I say numpy arrays explicitly because I am planning to use the methods defined for numpy arrays. Before that however we need to transform the dataframe into an iterator over the rows (events) of the dataframe. Thankfully pandas already came with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataframe into an iterator\n",
    "data = bkgnd_sim_2el2mu.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " run                                    194533\n",
       " event                                  846714\n",
       " luminosity_section                       2823\n",
       " muon_energy                   55.3949,35.6495\n",
       " muon_px                       -48.399,31.2184\n",
       " muon_py                      24.7739,-15.0449\n",
       " muon_pz                      -10.6009,8.36253\n",
       " muon_charge                              -1,1\n",
       " muon_relPFIso             0.0209805,0.0524248\n",
       " muon_dxy              -0.00105939,-0.00198611\n",
       " muon_dz               0.00580479,-0.000121758\n",
       " muon_SIP3d                    1.6412,0.661312\n",
       " electron_energy               254.196,36.8009\n",
       " electron_px                  18.0862,-12.0845\n",
       " electron_py                  -48.5142,24.8936\n",
       " electron_pz                 -248.867,-24.2607\n",
       " electron_charge                          -1,1\n",
       " electron_relPFIso         0.0250167,0.0712457\n",
       " electron_dxy           -0.0028464,0.000602746\n",
       " electron_dz            -0.00391345,0.00170042\n",
       " electron_SIP3d               0.47657,0.431616\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here from the first event the object returned from the iterator is a tuple where the first entry is an int (the index of the row) and the secon d element is a series containing the entries of that row. We now need to parse everything that is a string into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that parses all strings into lists\n",
    "def parse_strings(event):\n",
    "    ed = event[1]\n",
    "    ed['muon_energy'] = np.array([float(e) for e in ed['muon_energy'].split(',') if e != ''])\n",
    "    ed['muon_px'] = np.array([float(e) for e in ed['muon_px'].split(',') if e != ''])\n",
    "    ed['muon_py'] = np.array([float(e) for e in ed['muon_py'].split(',') if e != ''])\n",
    "    ed['muon_pz'] = np.array([float(e) for e in ed['muon_pz'].split(',') if e != ''])\n",
    "    ed['muon_charge'] = np.array([float(e) for e in ed['muon_charge'].split(',') if e != ''])\n",
    "    ed['muon_relPFIso'] = np.array([float(e) for e in ed['muon_relPFIso'].split(',') if e != ''])\n",
    "    ed['muon_dxy'] = np.array([float(e) for e in ed['muon_dxy'].split(',') if e != ''])\n",
    "    ed['muon_dz'] = np.array([float(e) for e in ed['muon_dz'].split(',') if e != ''])\n",
    "    ed['muon_SIP3d'] = np.array([float(e) for e in ed['muon_SIP3d'].split(',') if e != ''])\n",
    "    ed['electron_energy'] = np.array([float(e) for e in ed['electron_energy'].split(',') if e != ''])\n",
    "    ed['electron_px'] = np.array([float(e) for e in ed['electron_px'].split(',') if e != ''])\n",
    "    ed['electron_py'] = np.array([float(e) for e in ed['electron_py'].split(',') if e != ''])\n",
    "    ed['electron_pz'] = np.array([float(e) for e in ed['electron_pz'].split(',') if e != ''])\n",
    "    ed['electron_charge'] = np.array([float(e) for e in ed['electron_charge'].split(',') if e != ''])\n",
    "    ed['electron_relPFIso'] = np.array([float(e) for e in ed['electron_relPFIso'].split(',') if e != ''])\n",
    "    ed['electron_dxy'] = np.array([float(e) for e in ed['electron_dxy'].split(',') if e != ''])\n",
    "    ed['electron_dz'] = np.array([float(e) for e in ed['electron_dz'].split(',') if e != ''])\n",
    "    ed['electron_SIP3d'] = np.array([float(e) for e in ed['electron_SIP3d'].split(',') if e != ''])\n",
    "    return (event[0], ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = map(parse_strings, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " run                                       194533\n",
       " event                                     846715\n",
       " luminosity_section                          2823\n",
       " muon_energy                    [46.227, 17.1694]\n",
       " muon_px                       [-2.8323, 11.2507]\n",
       " muon_py                      [-13.9613, -1.2918]\n",
       " muon_pz                     [-43.9771, -12.9046]\n",
       " muon_charge                          [-1.0, 1.0]\n",
       " muon_relPFIso                [0.191416, 0.17468]\n",
       " muon_dxy              [0.00761235, -0.000309401]\n",
       " muon_dz                [-0.00194986, 0.00129964]\n",
       " muon_SIP3d                  [0.946415, 0.308535]\n",
       " electron_energy               [82.9044, 11.4583]\n",
       " electron_px                  [1.71208, -8.54741]\n",
       " electron_py                   [28.2926, 2.83502]\n",
       " electron_pz                  [-77.9085, 7.08491]\n",
       " electron_charge                      [-1.0, 1.0]\n",
       " electron_relPFIso            [0.15352, 0.515702]\n",
       " electron_dxy           [-0.00206888, 0.00300649]\n",
       " electron_dz           [-0.00538221, 7.12868e-05]\n",
       " electron_SIP3d              [0.937364, 0.413622]\n",
       " Name: 1, dtype: object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(parsed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that all the data will be parsed when it emerges from this transformation we can start doing the actual data crunching.\n",
    "\n",
    "When thinking a bit about the problem we want to solve, it is possible to see that the organisation of the data is far from optimal. By rearranging the data into 4-vectors for the muons and electrons we can use general purose functions to calculate things like the center of mass and the angles phi and theta. So the best idea is to restructure the data so that we can potentally reuse code that may allready exist to calculate quantities on 4-vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganizing the data\n",
    "def build_4_vectors(event):\n",
    "    # ed stands for event-data\n",
    "    ed = event[1]\n",
    "    # transformed event-data (this will contain the data in the structure that we want)\n",
    "    ted = {}\n",
    "    e_keys = ['electron_energy', 'electron_px', 'electron_py', 'electron_pz']\n",
    "    mu_keys = ['muon_energy', 'muon_px', 'muon_py', 'muon_pz']\n",
    "    mu_vecs = np.array([[me, mpx, mpy, mpz] for me, mpx, mpy, mpz in zip(ed[mu_keys[0]], ed[mu_keys[1]], ed[mu_keys[2]], ed[mu_keys[3]])])\n",
    "    e_vecs = np.array([[ee, epx, epy, epz] for ee, epx, epy, epz in zip(ed[e_keys[0]], ed[e_keys[1]], ed[e_keys[2]], ed[e_keys[3]])])\n",
    "    ted['e_fourvector'] = e_vecs\n",
    "    ted['mu_fourvector'] = mu_vecs\n",
    "    \n",
    "    # copy the rest of the values as long as they are not redundant\n",
    "    for key in ed.keys():\n",
    "        if key not in e_keys and key not in mu_keys:\n",
    "            ted[key] = ed[key]\n",
    "        \n",
    "    return (event[0], ted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this definition I have used the [zip](https://docs.python.org/3/library/functions.html#zip) function that also works on iterators (and iterables (iterables are things that can trivially be transformed into an iterator (like lists))) please look up what it does at the link provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = map(build_4_vectors, parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " {'e_fourvector': array([[ 42.9922 , -16.5883 ,  38.9813 ,  -7.32215],\n",
       "         [ 71.6306 ,   5.92063, -30.8763 , -64.3627 ]]),\n",
       "  'mu_fourvector': array([[ 19.461  ,  11.2609 , -10.3577 , -12.0261 ],\n",
       "         [ 10.3101 ,   9.16698,  -2.32848,   4.10262]]),\n",
       "  'run': 194533.0,\n",
       "  'event': 846723,\n",
       "  'luminosity_section': 2823,\n",
       "  'muon_charge': array([-1.,  1.]),\n",
       "  'muon_relPFIso': array([0.155083, 0.221734]),\n",
       "  'muon_dxy': array([0.00070336, 0.00115165]),\n",
       "  'muon_dz': array([ 0.00084617, -0.00065684]),\n",
       "  'muon_SIP3d': array([0.296126, 0.240591]),\n",
       "  'electron_charge': array([-1.,  1.]),\n",
       "  'electron_relPFIso': array([0.103053 , 0.0723279]),\n",
       "  'electron_dxy': array([-0.00058122, -0.023985  ]),\n",
       "  'electron_dz': array([0.00161887, 0.0172354 ]),\n",
       "  'electron_SIP3d': array([0.369838, 4.44646 ])})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(vectorized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small side note here, notice how every time we call next on one of the interators the index increases showing that the different iterators actually consume the data they transform and either pass it along or display it (when we call next on one of the earlier iterators it is shown rather than passed along to the next `map` function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it would also be useful, to group the rest of the values by lepton. We could also introduce a particle type so that we essentially have one entry and the entry tells us what kind of particle we are looking at. An event therefore would consist of meta information and a collection of particles. So now a map will be created to map the desired quantities to a list of particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_leptons(event):\n",
    "    data = event[1]\n",
    "    leptons = []\n",
    "    e_quantities = [data['e_fourvector'],\n",
    "                    data['electron_charge'],\n",
    "                    data['electron_relPFIso'],\n",
    "                    data['electron_dxy'],\n",
    "                    data['electron_dz'],\n",
    "                    data['electron_SIP3d']]\n",
    "    mu_quantities = [data['mu_fourvector'],\n",
    "                     data['muon_charge'],\n",
    "                     data['muon_relPFIso'],\n",
    "                     data['muon_dxy'],\n",
    "                     data['muon_dz'],\n",
    "                     data['muon_SIP3d']]\n",
    "    for fourvec, charge, relPFIso, dxy, dz, SIP3d in zip(*e_quantities):\n",
    "        lepton_dict = {'p': fourvec, 'type': 'e', 'charge': charge,\n",
    "                       'dxy': dxy, 'dz': dz, 'relPFIso': relPFIso, 'SIP3d': SIP3d}\n",
    "        leptons.append(lepton_dict)\n",
    "    for fourvec, charge, relPFIso, dxy, dz, SIP3d in zip(*mu_quantities):\n",
    "        lepton_dict = {'p': fourvec, 'type': 'mu', 'charge': charge,\n",
    "                       'dxy': dxy, 'dz': dz, 'relPFIso': relPFIso, 'SIP3d': SIP3d}\n",
    "        leptons.append(lepton_dict)\n",
    "    return (event[0], {'run': data['run'], 'event':data['event'], 'leptons': leptons})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_data = map(map_to_leptons, vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " {'run': 194533.0,\n",
       "  'event': 846753,\n",
       "  'leptons': [{'p': array([39.5647  , 35.2052  , 18.029   ,  0.956613]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': 0.00165894,\n",
       "    'dz': 0.0132108,\n",
       "    'relPFIso': 0.1432,\n",
       "    'SIP3d': 1.92044},\n",
       "   {'p': array([ 98.4103 , -31.9606 ,  -9.41048,  92.5988 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000320531,\n",
       "    'dz': 0.00052476,\n",
       "    'relPFIso': 0.049916,\n",
       "    'SIP3d': 0.0866598},\n",
       "   {'p': array([8.09622  , 0.0821112, 6.51906  , 4.79925  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 0.000483781,\n",
       "    'dz': -0.00433865,\n",
       "    'relPFIso': 0.216925,\n",
       "    'SIP3d': 0.973179},\n",
       "   {'p': array([ 7.72517, -2.40281, -6.02051,  4.20085]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00335737,\n",
       "    'dz': -0.00260739,\n",
       "    'relPFIso': 0.41674,\n",
       "    'SIP3d': 0.868803}]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(reformatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building analysis pipelines\n",
    "To facilitate code reuse it is useful to structure these transformations and filters from single transformations into a structure I'll call a pipeline. A pipeline either produces a certain filtered and amended subset of the initial data or generates the answer to a question like the properties of some quantity. This pipeline can then be called with any data that fits the input format of the first tranformation in the pipeline.\n",
    "\n",
    "An arbitrary pipeline will generally consist of 3 steps.\n",
    "1. Format the data into the form that the pipeline (and subsequently you as the programmer) can work with best. This is essentially what we have been doing so far. We have parsed the strings and then reformed the data into a structure that is most useful/efficient/intuitive (depending on the needs).\n",
    "\n",
    "2. Filter the data: The next step in any analysis is to filter out all data that does not fit the requirements. This should be done as early as possible to avoid doing expensive computations on data that would be thrown out anyway. So the Idea is to start with the cheapest calculations that eliminate the largest amounts of data form the sample that was loaded into the front of the pipeline (think of this in the same sense as the refinement process of crude oil into it's destillates). If the refinery would perform a specific process to a compond that would later be dumped anyway the refinery just used up a lot of energy for nothing and needs larger processing facilities than would actually be neccesary (this analogy maps pretty much exactly to data processing, the crude oil being the inputs and the destillates the outputs. The energy would be the energy consumed by the computers during the processing and processing data at a specific throughput would require less compute power the more efficient it is).\n",
    "\n",
    "3. After the data has been filtered to the smallest possible dataset the expensive calculations (like the reconstruction of ancestor particles like B and D mesons and in this case hopefully the two Z bosons and finally the higgs boson) can commence.\n",
    "\n",
    "The results of the pipeline can then be used to visualize the behaviour or relationships of the quantity of interest.\n",
    "\n",
    "### Combining pipelines\n",
    "The nice thing about this approach is, that the results of one pipeline can be used as input for the next pipeline. So if new data becomes available to answer a particular question that allready has a pipline that can produce an answer the only thing that needs to be done is to write a pipeline that transforms the data from this particular source into a format that the original pipeline can work with.\n",
    "\n",
    "This task may however also involve some amount of filtering besides simple transformation and in that case the reqirements on the input data need to be known for any pipeline. Again these requirements don't only apply to the format of the data but also the ranges of values the data is allowed to take on to guarantee that the pipeline will work properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline will take care of transforming the data from the pandas dataframe we got in the begining\n",
    "# into the structure that we expect in all subsequent analysis steps\n",
    "def read_in_and_reformat(raw_data_iterator):\n",
    "    return map(map_to_leptons, map(build_4_vectors, map(parse_strings, raw_data_iterator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous statement should be read the same way that a mathematical function should be, from the inside out. We start with the `parse_strings` method on the right hand side work our way to the left. The output of the `parse_strings` method is then used as input into the `build_4_vectors` method and then that is in turn used as input into the `map_to_leptons` function.\n",
    "\n",
    "As what is returned by the `read_in_and_reformat` is still just an iterator we can now use that function as a building block for a possibly more complex data-processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's now do something a bit more physics-heavy and calculate the $p_t$ (transverse momentum) of all leptons in each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transverse_momentum(fourvector):\n",
    "    \"\"\" given a fourvector this function simply calcuates the corresponding transverse momentum\n",
    "    The fourvector should follow this convention: [e, px, py, pz]\"\"\"\n",
    "    return np.sqrt(fourvector[1]**2 + fourvector[2]**2)\n",
    "\n",
    "# now that we have a generic fourvector based calculation function we have to wrap this in a function that extracts\n",
    "# the neccessary information from the event\n",
    "def calc_pt(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'pt': calculate_transverse_momentum(l['p'])})\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I want to add an new entry to each lepton (remember a lepton in our case is a `dict` and update is defined for `dict`) I can use the update method on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pt = map(calc_pt, reformatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the transverse momentum, we can apply our first filter. In this scenario, we want all events where there are at least four leptons that have a transverst momentum larger than a given value $p_{t_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_min(event, min_pt):\n",
    "    data = event[1]\n",
    "    leptons = filter(lambda lepton: lepton['pt'] > min_pt, data['leptons'])\n",
    "    return True if len(list(leptons)) > 4 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code has a few things in it not quite covered yet. So I'll do that here.\n",
    "\n",
    "Remember that I said that a list is an iterator? Well in case you don't: A list is an iterator, so as we want to count the number of leptons that have a specific properties a filter can be used on the leptons to only return all leptons that have a transverse momentum larger than `min_pt` and then the filter that we actually want to write should only return the event when the amount of leptons meeting that requirement is larger than four.\n",
    "\n",
    "\n",
    "##### Side notes on the `lambda` function\n",
    "---\n",
    "As you might also stil remember, filter needs a function to determin which event to accept and pass along and which to reject and subsequently drop from the stream. The function that is passed to filter needs to return `True` if the value should be accepted and `False` if it should be rejected. As you can see our `pt_min` function does exactly that.\n",
    "\n",
    "The second thing I wanted to talk about briefly is the [lambda](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) expression, that was used in the lepton filter. `lambda` functions are a sort of short hand for defining functions. As you can see the function is not very long, it fits into less than one line. The `lambda` function ends at the `,` and is equivalent to the following 'proper' function definition:\n",
    "\n",
    "```python\n",
    "def filter_leptons(x, min_pt):\n",
    "    return lepton['pt'] > min_pt\n",
    "```\n",
    "\n",
    "There are a few noteworthy differences though:\n",
    "- A `lambda` function does not need a name. I have therefore given the previous equivalent function a fitting name.\n",
    "\n",
    "- lambda functions also 'capture their environment' that means lambda functions can use all variables that would be available inside the scope where the lambda function was defined (in the case of the `pt_min` function, the labmda expression there did not need to be passed the `min_pt` value as it automatically had access to it, whereas it needs to be passed explicitly to the `filter_leptons` function so it can be used inside the function body. The particulars of this kind of behavior (which is called 'scoping') are a bit more tricky and will not be covered further here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we take a look at the `pt_min` method, we can see that the signature of the function (the signature is the word for how the function 'looks' from the outside. So the  signature of the function is the name together with type and sequence of input parameters and the output parameters of the function) still does not fit the requirements for the `filter` method. We subsequently need to wrap this function somehow. This is similar but not quite the same to how we wrapped the function to calculate the `pt` for each lepton in an event. This time we have to wrap the function that takes an event together with a parameter to filter the event by. There are a few methods to do this. We shal talk about these now.\n",
    "\n",
    "1. **Tuple (un)wrapping**: Here the values neede are packed into a tuple and unpacked inside the wrapper function, passed to the function being wrapped (in this case `pt_min`) and then proceed as before. This obviously neccessitates the definition of a 'wrapper' function. This function could be defined in the fillowing way:\n",
    "\n",
    "```python\n",
    "def pt_min_wrapper(event_with_pt_min_tuple):\n",
    "    event, min_pt = event_with_pt_min_tuple\n",
    "    return pt_min(event, min_pt)\n",
    "```\n",
    "\n",
    "The problem with this method is that this makes the call of the filter a bit more complicated, as it is now neccessary to construct a `min_pt` object for each and every event that all have to be identical and combine the two objects into a tuple as follows `(event,     min_pt)`. The iterators and functions from the itertools can help here. The call would subsequently look like this:\n",
    "\n",
    "```python\n",
    "filter(pt_min_wrapper, zip(events, itertools.cycle(min_pt)))\n",
    "```\n",
    "\n",
    "Please check out what [cycle](https://docs.python.org/3/library/itertools.html#itertools.cycle) does at the link.\n",
    "\n",
    "2. **Using a `lambda`**: with a `lambda` all of that effort can be avoided. The lambda method acts as the wrapper, but because it has access to it's environment (the place where `min_pt` is defined) the `min_pt` argument is implicitly copied as part of the funcion call. This is (in my humble oppinion) the far more elegant solution. We will use this method when we filter the stream after the next text section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Stream\n",
    "Imagine the following: You have multiple questions you would like to get answers to by analyzing the data.\n",
    "The problem now is that the one answer needs at least four leptons to have a transverse impulse of at least $p_{t_{min}}$ and the other answer needs these events that where rejected to be able to calculate the answer to our second question.\n",
    "\n",
    "Now to get those two answers there are a few options:\n",
    "\n",
    "- we write two analysis pipelines that go from the input data in the pandas dataframe to the answer. This has the drawback that we need to perform the parsing and reformatting, as well as the calculation of the transverse momentum twice, once for each analysis. In our case the calculations and transformations where not particularly expensive, it is however easy to imagine a situation where the analyses differ in a later stage where for example reconstruction have allready taken place and used up large amount of CPU time and energy to run the computers. Doing that twice is qite literaly an expensive thing to do (as in paying the power bills at the end of the month).\n",
    "\n",
    "- we could split the stream of data into two streams with identical copies. The first stream goes into the `pt_min` filter and the other can be used in a different analysis. This is exactly what the `itertools.tee` fuction allows us to do.\n",
    "\n",
    "In the following we shal split the stream into two streams, one for the pt_min filter and beyond and one stream to do something else with at a later time.\n",
    "\n",
    "Splitting the stream would also allow us to take a 'live' look at our data being processed. We could split the stream at various points in the pipeline and plot out relevant quantities. This can not only be useful for following the analysis but also in finding bugs in the code, as the plots and histograms should quickly show discrepencies between expected an actual result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "# stream_2 is an exact copy of stream_1, however the elements are only copied one at a time while\n",
    "# they are being processed, resulting in little memory overhead. (there are again a few caveats here)\n",
    "stream_1, stream_2 = itt.tee(data_with_pt, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pt = 4\n",
    "min_pt_filtered_stream = filter(lambda e: pt_min(e, min_pt), stream_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I'll start to focus more on the physics here. So lets define the functions needed to calculate a few other quantities that interesting for the later analysis. If neccesary we can use filters in between the calculatinon steps to remove data that no longer fits our needs and reduce processing load in all subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudorapidity(pt, pz):\n",
    "    \"\"\"calculate the pseudorapidity (eta) for a given fourvector\"\"\"\n",
    "    # remember opposite/adjacent = tan(theta)\n",
    "    return -np.log(np.abs(pt/(pz*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(fourvector):\n",
    "    vec = np.array([fourvector[1], fourvector[2]])\n",
    "    normed_vec = vec/np.linalg.norm(vec)\n",
    "    return np.arctan2(normed_vec[1], normed_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "* I'd make it an excercise for the students to implement the wrapper for these functions as seen in the example of the `pt_min` function these function wrappers are going to be provided in the following block as a reference\n",
    "\n",
    "* it is of course advisable to let the students implement the phi, mandelstam_s and pseudorapidity functions with the given input parameters as these functions encode the actual physical quantities.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the 'wrapper' functions I mentioned above and you can see that they are pretty straight forward to implement so I hope at this stage of the tutorial\n",
    "# with a pretty straight forward example they should be able to do it\n",
    "def calc_pseudorapidity(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'eta': pseudorapidity(l['pt'], l['p'][3])})\n",
    "    return event\n",
    "\n",
    "def calc_phi(event):\n",
    "    leptons = event[1]['leptons']\n",
    "    for l in leptons:\n",
    "        l.update({'phi': phi(l['p'])})\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three functions can't directly be inserted into the analysis pipeline, because they lack the right input and output parameters. Theses functions functions have to be 'wrapped' by a functions that does not really do anything else than transform the input quantities of the outer function (in this case the event that we want to calculate the quantity for) to the parameters needed by the function that actually does the work. It also takes care to embed the result into the object that was passed in from the outside. This type of function will be somewhat important in the coming stages of what we want to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Physics involved\n",
    "It may be fairly obvious but I will say it anyway, before we can tell the computer how to analyse things we first need to understand what it is that we are analysing. In this case we are analysing the decay of the Higgs Boson into four leptons via two $Z$ bosons. We are not considering anything else here so we don't have to look for photons or jets or anything of that sort.\n",
    "\n",
    "As the $Z$ boson can decay into 4 leptons the kind of lepton that is produced still varies but effectively comes down to either\n",
    "\n",
    "1. All four leptons are $\\mu$ s\n",
    "2. All four leptons are electorns\n",
    "3. There are two electrons and two $\\mu$ s.\n",
    "\n",
    "These three different modes of decay are typically called 'decay channels' (this nomenclature extends to all kind of decays).\n",
    "\n",
    "In any of the above mentioned cases the electron and/or muon can be either particle or antiparticle. Depending on the specific event.\n",
    "So first of we should probably eliminate all events where we can't find either four electrons, four $\\mu$ s or two $\\mu$ s and two electrons\n",
    "\n",
    "However we could split the pipeline here and filter out the events that have (at least) four leptons of the same type (one pipeline for electrons, one for muons) and one for all events that have (at least) two electrons and two muons. This could create multiple copies of the same event (at most one per pipeline bringing the total to 3) As we have kept the ID of each event we should not forget to then cross check if one event ended up being counted for two different decay channels.\n",
    "\n",
    "If you however read the [Paper](https://arxiv.org/pdf/1207.7235.pdf), you will find that the authors chose to first limit the electrons in each event to electrons with a $p_T > 7 \\text{ [GeV]}$ and $\\left|\\eta\\right| < 2.5$. The muons considered for each event also have to satisfy $p_T > 5\\text{ [GeV]}$ and $\\left|\\eta\\right| < 2.4$ So let's define these parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_pt_min = 7\n",
    "electron_max_eta = 2.5\n",
    "muon_pt_min = 5\n",
    "muon_max_eta = 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be following that lead (see section 5.2) and starting with filtering out all electrons and muons that don't meet the stated requirements.\n",
    "\n",
    "So now we have to do something somewhat interesting. We are going to use filters *inside* an event to alter it before we pass the event along. The event itself will allways be passed on to the next stage of the pipeline, But the event may not contain any leptons because none of them where able to pass the requirements. So the counting of leptons will only happen *after* the leptons have been reduced to leptons that satisfy our reconstruction requirements.\n",
    "\n",
    "To be able to filter out events that don't meet the required number of leptons we can define the following function and then use a wrapper to be able to use it in a filter. (As I said, you will see wrappers again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_least_n_leptons_of_type(t, n, leptons):\n",
    "    \"\"\"function that can be used to filter out leptons of type t\"\"\"\n",
    "    type_t_leptons = list(filter(lambda l: l['type'] == t, leptons))\n",
    "    return len(type_t_leptons) >= n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please don't get things confused here (they can be quite confusing). The events have to mapped as we are not discarding entire events. However *inside* each event the individual leptons are going to be filtered.\n",
    "\n",
    "We also are going to have to define 4 different wrappers for this function. Each wrapper will pass different arguments to the `at_least_n_leptons_of_type` function.\n",
    "One wrapper is going to remove all events in the 4 muon processing pipeline that don't still have 4 muons left. One wrapper will do the same in the four electron pipeline and we are going to use two filters in series (one for two electrons and one for two muons) in the 2e2mu pipeline.\n",
    "\n",
    "---\n",
    "###### Side Note\n",
    "I'd like to point out the use of the `lambda` function here. It again is very similar to the last occurrence and we will see the `lambda` used more extensively throughout the coming steps.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first calculation and filter step.\n",
    "\n",
    "Now let's build the filter pipeline for the restriction of the leptons to leptons that meet the desired criteria and then split the single pipeline into three independedn ones. One for the four muon channel, one for the four electron channel and one for the 2el2mu channel. For this we need an unfiltered stream and will use `stream_2` for this purpose (`stream_2` was split off before the min_pt filter was applied. The good thing here is that `pt` has allready been calculated for each lepton. However we cant simply use the `min_pt` filter as it filters out events if it can't find at least four leptons that have a $p_T$ larger than `pt_min`, we however want to drop all leptons that don't satisfy the requirements in each event but keep the event. We also still need to calculate $\\eta$ for all leptons of every event but as we have already written a function that can be used in a map statement this is fairly strait forward.\n",
    "\n",
    "Let's first calculate $\\eta$ for the leptons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_pt_and_eta = map(calc_pseudorapidity, data_with_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " {'run': 194533.0,\n",
       "  'event': 846763,\n",
       "  'leptons': [{'p': array([ 81.314 , -78.6539, -11.2899,  17.2646]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.000410155,\n",
       "    'dz': 0.00174084,\n",
       "    'relPFIso': 0.0136104,\n",
       "    'SIP3d': 0.465797,\n",
       "    'pt': 79.46003918461152,\n",
       "    'eta': -0.8334489006486171},\n",
       "   {'p': array([ 11.1153 , -10.3513 ,  -3.73267,  -1.57127]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00214753,\n",
       "    'dz': -0.00185153,\n",
       "    'relPFIso': 0.250511,\n",
       "    'SIP3d': 0.454134,\n",
       "    'pt': 11.003737411393459,\n",
       "    'eta': -1.2532035896431293},\n",
       "   {'p': array([ 71.6791,  64.102 , -26.1167,  18.6209]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.000143862,\n",
       "    'dz': -0.00487695,\n",
       "    'relPFIso': 0.014919,\n",
       "    'SIP3d': 1.44616,\n",
       "    'pt': 69.21812206994639,\n",
       "    'eta': -0.6198309215983585},\n",
       "   {'p': array([80.8522, 25.6134, 41.6729, 64.3769]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000591512,\n",
       "    'dz': 0.00341611,\n",
       "    'relPFIso': 0.013307,\n",
       "    'SIP3d': 0.757034,\n",
       "    'pt': 48.91499620740044,\n",
       "    'eta': 0.9678180332965066}]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_with_pt_and_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data is available we can apply the filters on the leptons in each event. The function that is used to filter out the leptons is defined below. As usual we will need a wrapper in the form of a lambda expression to be able to fit these functions into the normal `filter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lepton_requirements(lepton, lepton_type, pt_min, eta_max):\n",
    "    return lepton['type'] != lepton_type or (lepton['type'] == lepton_type\n",
    "                                             and lepton['pt'] >= pt_min\n",
    "                                             and np.abs(lepton['eta']) <= eta_max)\n",
    "\n",
    "def remove_unfit_leptons_of_lepton_type(event, pt_min, eta_max, lepton_type):\n",
    "    leptons = event[1]['leptons']\n",
    "    leptons_with_electrons_filtered = list(filter(lambda l: lepton_requirements(l, lepton_type, pt_min, eta_max), leptons))\n",
    "    event[1]['leptons'] = leptons_with_electrons_filtered\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wrap the inner function in a function that accepts an event and then applies the filter to the leptons of that event. However as the signature is still not fit for use in the `map` function (remember we are filtering the leptons not the events, which is why the events need to be mapped. We will filter the events in the next step) we still need to wrap that function, preferably in a lambda.\n",
    "\n",
    "This double wrapping was done because the $p_T$ and $\\eta$ requirements are now values that exist as parameters for the entire pipeline. If we want to change these parameters because for example our search requirements have somehow changed we can simply change some global variables (like the ones defined above) in the analysis script and don't have to go hunting in the depths of the code for where the parameter was defined. It is therefore important to think about what parameters will probably be varied often and expose them to the outside. But be careful, simply exposing every parameter may become confusing (if also maybe neccesary). You will have to decide that for every pipeline and analysis you build at your discretion and taste. Some people will prefer a flat design exposing all parameters and again others will prefer a hirarchy where they define sub-pipelines that then have their values defined inside a smaller scope. Find what fits best for you.\n",
    "\n",
    "So now let's define the lepton filter, again with the `lambda` function to simplify the wrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with_filtered_electrons = map(lambda e: remove_unfit_leptons_of_lepton_type(e, electron_pt_min, electron_max_eta, 'e'), data_with_pt_and_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " {'run': 194533.0,\n",
       "  'event': 846787,\n",
       "  'leptons': [{'p': array([159.376  ,   1.60129, -64.9424 , 145.535  ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000772845,\n",
       "    'dz': -0.00466982,\n",
       "    'relPFIso': 0.0417984,\n",
       "    'SIP3d': 1.11682,\n",
       "    'pt': 64.9621385687394,\n",
       "    'eta': 1.4997591714438712},\n",
       "   {'p': array([95.0541  , 55.6391  ,  0.642879, 77.0659  ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': 0.00423916,\n",
       "    'dz': 0.00480899,\n",
       "    'relPFIso': 0.0236071,\n",
       "    'SIP3d': 1.32662,\n",
       "    'pt': 55.64281393152795,\n",
       "    'eta': 1.0188551408720814},\n",
       "   {'p': array([175.413 ,  30.3673, -59.5542, 162.175 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.000409225,\n",
       "    'dz': -0.000506639,\n",
       "    'relPFIso': 0.0148671,\n",
       "    'SIP3d': 0.15078,\n",
       "    'pt': 66.8496495647509,\n",
       "    'eta': 1.579377118237778},\n",
       "   {'p': array([18.9466  ,  0.630108, 18.8462  ,  1.83977 ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': 0.000924033,\n",
       "    'dz': -0.00541554,\n",
       "    'relPFIso': 0.043713,\n",
       "    'SIP3d': 1.11657,\n",
       "    'pt': 18.85673064270856,\n",
       "    'eta': -1.6340821690680747}]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(events_with_filtered_electrons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with_filtered_leptons = map(lambda e: remove_unfit_leptons_of_lepton_type(e, muon_pt_min, muon_max_eta, 'mu'), events_with_filtered_electrons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed all leptons that don't meet our requirements it is time to split the stream into three (identical) streams, one for each decay channel. Then we will apply the filters that restrict the events to only the events that match the lepton count of the different decay channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_mu_channel, four_e_channel, two_e_two_mu_channel = itt.tee(events_with_filtered_leptons, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to demonstrate that we have actually split the stream into three identical streems we can call `next` once on every stream and then see what they spit out. They should all return the identical event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'run': 194533.0,\n",
       "  'event': 853714,\n",
       "  'leptons': [{'p': array([ 44.573  ,  15.4027 ,  -3.87256, -41.6475 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00345287,\n",
       "    'dz': 0.00424,\n",
       "    'relPFIso': 0.0271937,\n",
       "    'SIP3d': 0.266371,\n",
       "    'pt': 15.882061838552323,\n",
       "    'eta': 1.6571982372712366},\n",
       "   {'p': array([ 41.2259 ,  10.0007 ,   1.20899, -39.9762 ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00282081,\n",
       "    'dz': 0.0155539,\n",
       "    'relPFIso': 0.606938,\n",
       "    'SIP3d': 0.657479,\n",
       "    'pt': 10.073512659946381,\n",
       "    'eta': 2.071521987460627},\n",
       "   {'p': array([ 67.7235 , -36.0904 ,   6.38364, -56.949  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00106482,\n",
       "    'dz': 0.000487924,\n",
       "    'relPFIso': 0.276088,\n",
       "    'SIP3d': 0.32319,\n",
       "    'pt': 36.65061843693228,\n",
       "    'eta': 1.1338730087143165},\n",
       "   {'p': array([ 38.1787  ,  18.4771  ,   0.443387, -33.4066  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 6.84894e-06,\n",
       "    'dz': -0.00201422,\n",
       "    'relPFIso': 0.0233677,\n",
       "    'SIP3d': 0.445525,\n",
       "    'pt': 18.482419117685026,\n",
       "    'eta': 1.2850807035288545}]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(four_mu_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'run': 194533.0,\n",
       "  'event': 853714,\n",
       "  'leptons': [{'p': array([ 44.573  ,  15.4027 ,  -3.87256, -41.6475 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00345287,\n",
       "    'dz': 0.00424,\n",
       "    'relPFIso': 0.0271937,\n",
       "    'SIP3d': 0.266371,\n",
       "    'pt': 15.882061838552323,\n",
       "    'eta': 1.6571982372712366},\n",
       "   {'p': array([ 41.2259 ,  10.0007 ,   1.20899, -39.9762 ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00282081,\n",
       "    'dz': 0.0155539,\n",
       "    'relPFIso': 0.606938,\n",
       "    'SIP3d': 0.657479,\n",
       "    'pt': 10.073512659946381,\n",
       "    'eta': 2.071521987460627},\n",
       "   {'p': array([ 67.7235 , -36.0904 ,   6.38364, -56.949  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00106482,\n",
       "    'dz': 0.000487924,\n",
       "    'relPFIso': 0.276088,\n",
       "    'SIP3d': 0.32319,\n",
       "    'pt': 36.65061843693228,\n",
       "    'eta': 1.1338730087143165},\n",
       "   {'p': array([ 38.1787  ,  18.4771  ,   0.443387, -33.4066  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 6.84894e-06,\n",
       "    'dz': -0.00201422,\n",
       "    'relPFIso': 0.0233677,\n",
       "    'SIP3d': 0.445525,\n",
       "    'pt': 18.482419117685026,\n",
       "    'eta': 1.2850807035288545}]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(four_e_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " {'run': 194533.0,\n",
       "  'event': 853714,\n",
       "  'leptons': [{'p': array([ 44.573  ,  15.4027 ,  -3.87256, -41.6475 ]),\n",
       "    'type': 'e',\n",
       "    'charge': -1.0,\n",
       "    'dxy': -0.00345287,\n",
       "    'dz': 0.00424,\n",
       "    'relPFIso': 0.0271937,\n",
       "    'SIP3d': 0.266371,\n",
       "    'pt': 15.882061838552323,\n",
       "    'eta': 1.6571982372712366},\n",
       "   {'p': array([ 41.2259 ,  10.0007 ,   1.20899, -39.9762 ]),\n",
       "    'type': 'e',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00282081,\n",
       "    'dz': 0.0155539,\n",
       "    'relPFIso': 0.606938,\n",
       "    'SIP3d': 0.657479,\n",
       "    'pt': 10.073512659946381,\n",
       "    'eta': 2.071521987460627},\n",
       "   {'p': array([ 67.7235 , -36.0904 ,   6.38364, -56.949  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': 1.0,\n",
       "    'dxy': -0.00106482,\n",
       "    'dz': 0.000487924,\n",
       "    'relPFIso': 0.276088,\n",
       "    'SIP3d': 0.32319,\n",
       "    'pt': 36.65061843693228,\n",
       "    'eta': 1.1338730087143165},\n",
       "   {'p': array([ 38.1787  ,  18.4771  ,   0.443387, -33.4066  ]),\n",
       "    'type': 'mu',\n",
       "    'charge': -1.0,\n",
       "    'dxy': 6.84894e-06,\n",
       "    'dz': -0.00201422,\n",
       "    'relPFIso': 0.0233677,\n",
       "    'SIP3d': 0.445525,\n",
       "    'pt': 18.482419117685026,\n",
       "    'eta': 1.2850807035288545}]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(two_e_two_mu_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the event number, we get the same event in every channel, so everything is as we expected. Now we have to apply the different filters for the different decay channels to leave us only with events that could actually have been produced by a $Z$ pair decaying into that particular channel.\n",
    "\n",
    "When we take a look at the data we loaded into the front of the pipeline we can make a guess what should happen. As we have loaded a background simulation of ZZ to 2el2mu most to all of the events should end up in the 2el2mu processing pipeline and essentially none in the other two.\n",
    "\n",
    "so let's implement the filters for the different pipelines (corresponding to the different channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_4mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 4, e), four_mu_channel)\n",
    "filtered_4e_data = filter(lambda e: at_least_n_leptons_of_type('e', 4, e), four_e_channel)\n",
    "\n",
    "# the 2el 2mu channel needs two filters one for the minimum amount of electron and then one for the minimal amount of \n",
    "partially_filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('e', 2, e), two_e_two_mu_channel)\n",
    "filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 2, e), partially_filtered_2e2mu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now would be a good time to check if the assumption that we made (that most of the events end up in `filtered_2e2mu_data` and only a few make it into the other pipelines. To be able to do this in a repeatable way, we should probably combine all the previous work into one neat function.\n",
    "\n",
    "While we are at it we can first define parts of the pipeline that thematically belong together into their own functions. We have allready defined the `read_in_and_reformat` function grouping the early reformatting functions that simply reorganize the data that we get from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first a function can be defined that encapsulates the filtering of the three channels\n",
    "def filter_zz_decay_channels(channel_4mu, channel_4el, channel_2el2mu):\n",
    "    # filter out the events that don't have enough muons for the 4mu channel\n",
    "    filtered_4mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 4, e[1]['leptons']), channel_4mu)\n",
    "    \n",
    "    # filter out all events that don't have enough electrons for the 4el channel\n",
    "    filtered_4e_data = filter(lambda e: at_least_n_leptons_of_type('e', 4, e[1]['leptons']), channel_4el)\n",
    "    \n",
    "    # the 2el 2mu channel needs two filters one for the minimum amount of electron and then one for the minimal amount of\n",
    "    # muons that we want (two in each case)\n",
    "    partially_filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('e', 2, e[1]['leptons']), channel_2el2mu)\n",
    "    filtered_2e2mu_data = filter(lambda e: at_least_n_leptons_of_type('mu', 2, e[1]['leptons']), partially_filtered_2e2mu_data)\n",
    "    \n",
    "    return filtered_4mu_data, filtered_4e_data, filtered_2e2mu_data\n",
    "\n",
    "# now we can also define a function that takes care of filtering out the\n",
    "# leptons that don't meet the requirements\n",
    "def filter_out_unfit_leptons(data_iterator, muon_pt_min, muon_eta_max, el_pt_min, el_eta_max):\n",
    "    \n",
    "    # remove all muons that dont meet the requirements\n",
    "    data_with_filtered_muons = map(lambda e: remove_unfit_leptons_of_lepton_type(e, muon_pt_min, muon_max_eta, 'mu'),\n",
    "                                     data_iterator)\n",
    "    \n",
    "    #remove all electrons that dont meet the requirements\n",
    "    data_with_filtered_leptons = map(lambda e: remove_unfit_leptons_of_lepton_type(e, el_pt_min, el_eta_max, 'e'),\n",
    "                                     data_with_filtered_muons)\n",
    "    \n",
    "    return data_with_filtered_leptons\n",
    "    \n",
    "def read_in_reformat_split_and_filter_into_channels(raw_data_iterator, muon_pt_min, muon_eta_max, el_pt_min, el_eta_max):\n",
    "    # parse the strings, and reformat into list of leptons\n",
    "    parsed_and_formatted_data = read_in_and_reformat(raw_data_iterator)\n",
    "    \n",
    "    # calculate the needed quantities\n",
    "    data_with_pt_and_eta = map(calc_pseudorapidity, map(calc_pt, parsed_and_formatted_data))\n",
    "    \n",
    "    # now we filter out the leptons that don't meet the requirements from each event\n",
    "    data_with_pre_filtered_leptons = filter_out_unfit_leptons(data_with_pt_and_eta,\n",
    "                                                              muon_pt_min,\n",
    "                                                              muon_eta_max,\n",
    "                                                              el_pt_min,\n",
    "                                                              el_eta_max)\n",
    "    \n",
    "    # now we need to split the stream (the sequence of the channels is currently still arbitrary because they are identical\n",
    "    # after creation)\n",
    "    channel_4mu, channel_4el, channel_2el2mu = itt.tee(data_with_pre_filtered_leptons, 3)\n",
    "    filtered_channel_4mu, filtered_channel_4el, filtered_channel_2el2mu = filter_zz_decay_channels(channel_4mu,\n",
    "                                                                                                   channel_4el,\n",
    "                                                                                                   channel_2el2mu)\n",
    "    return filtered_channel_4mu, filtered_channel_4el, filtered_channel_2el2mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the definition of the `read_in_reformat_split_and_filter_into_channels` in place we can easily test the hypothesis that most events should end up in the `filtered_channel_2el2mu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu, c4el, c2el2mu = read_in_reformat_split_and_filter_into_channels(bkgnd_sim_2el2mu.head(10000).iterrows(),\n",
    "                                                                      muon_pt_min,\n",
    "                                                                      muon_max_eta,\n",
    "                                                                      electron_pt_min,\n",
    "                                                                      electron_max_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for the parameters `muon_pt_min` to `electron_max_eta` where defined when we talked about the ZZ-> 4l process.\n",
    "\n",
    "So now for the test of all our previous work a drum roll please:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "7594\n"
     ]
    }
   ],
   "source": [
    "print(len(list(c4mu)))\n",
    "print(len(list(c4el)))\n",
    "print(len(list(c2el2mu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see, we have indeed ended up with most of the 10000 events that we started with in the 2el2mu channel just as we would have expected. \n",
    "\n",
    ">Just FYI I did not test any of the code befor running this test and except for some minor variable misnaming errors everything just worked.\n",
    "\n",
    "I have to use list here because the thing that is returned by the function at the beginning was just the iterator. The iterator had not actually done any work yet but was simply defined.\n",
    "\n",
    "Iterators in python are 'lazy' that means that they only do work when an item is requested of them via the next method. This is why the call of the function was nearly instant even though we did pass the data and all the needed information to it.\n",
    "\n",
    "This is also why I used the `len(list(iterator))` call. the `list` function turns the iterator back into a list by calling next on the iterator until it raises the `StopIteration` exception and stores the values the iterator returns in a list in the order it got them from the iterator. Subsequently an iterator does not know it's length, but a list of course does so we need the list before we can call `len` to determin how many events made it into the different channels.\n",
    "\n",
    "Now let's try the different simulation setst for the other two decay channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu_2, c4el_2, c2el2mu = read_in_reformat_split_and_filter_into_channels(bkgnd_sim_4mu.head(10000).iterrows(),\n",
    "                                                                          muon_pt_min,\n",
    "                                                                          muon_max_eta,\n",
    "                                                                          electron_pt_min,\n",
    "                                                                          electron_max_eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This went fine but when we try and evaluate the iterators we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'electron_energy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'electron_energy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c39c385c5017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc4mu_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc4el_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2el2mu_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5133efcba601>\u001b[0m in \u001b[0;36mparse_strings\u001b[0;34m(event)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_dz'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_dz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_SIP3d'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'muon_SIP3d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_energy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_energy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_px'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_px'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_py'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'electron_py'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'electron_energy'"
     ]
    }
   ],
   "source": [
    "print(len(list(c4mu_2)))\n",
    "print(len(list(c4el_2)))\n",
    "print(len(list(c2el2mu_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a `KeyError`. It took me a minute to figure this one out but the error here allready points in a good direction. If we take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>muon_energy</th>\n",
       "      <th>muon_px</th>\n",
       "      <th>muon_py</th>\n",
       "      <th>muon_pz</th>\n",
       "      <th>muon_charge</th>\n",
       "      <th>muon_relPFIso</th>\n",
       "      <th>muon_dxy</th>\n",
       "      <th>muon_dz</th>\n",
       "      <th>muon_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194533.0</td>\n",
       "      <td>1142211</td>\n",
       "      <td>3809</td>\n",
       "      <td>52.8881,104.397,29.9594,60.5544</td>\n",
       "      <td>-49.2137,16.0997,24.2971,14.3324</td>\n",
       "      <td>0.527564,-27.1821,11.0576,-1.76615</td>\n",
       "      <td>-19.3616,99.5022,-13.599,58.8072</td>\n",
       "      <td>1,-1,-1,1</td>\n",
       "      <td>0.0296542,0,0.0445055,0</td>\n",
       "      <td>-0.000377091,-0.000857253,0.00163948,-0.00102962</td>\n",
       "      <td>-0.000987451,0.00553847,0.000673754,-0.00563673</td>\n",
       "      <td>0.341185,1.17472,0.74423,0.727535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run    event  luminosity_section                      muon_energy  \\\n",
       "0  194533.0  1142211                3809  52.8881,104.397,29.9594,60.5544   \n",
       "\n",
       "                            muon_px                             muon_py  \\\n",
       "0  -49.2137,16.0997,24.2971,14.3324  0.527564,-27.1821,11.0576,-1.76615   \n",
       "\n",
       "                            muon_pz muon_charge            muon_relPFIso  \\\n",
       "0  -19.3616,99.5022,-13.599,58.8072   1,-1,-1,1  0.0296542,0,0.0445055,0   \n",
       "\n",
       "                                           muon_dxy  \\\n",
       "0  -0.000377091,-0.000857253,0.00163948,-0.00102962   \n",
       "\n",
       "                                           muon_dz  \\\n",
       "0  -0.000987451,0.00553847,0.000673754,-0.00563673   \n",
       "\n",
       "                          muon_SIP3d  \n",
       "0  0.341185,1.17472,0.74423,0.727535  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_4mu.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>event</th>\n",
       "      <th>luminosity_section</th>\n",
       "      <th>electron_energy</th>\n",
       "      <th>electron_px</th>\n",
       "      <th>electron_py</th>\n",
       "      <th>electron_pz</th>\n",
       "      <th>electron_charge</th>\n",
       "      <th>electron_relPFIso</th>\n",
       "      <th>electron_dxy</th>\n",
       "      <th>electron_dz</th>\n",
       "      <th>electron_SIP3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200519.0</td>\n",
       "      <td>1002510</td>\n",
       "      <td>3343</td>\n",
       "      <td>55.0788,41.0337,71.266,40.9315</td>\n",
       "      <td>-44.9139,27.7747,-23.2093,24.2694</td>\n",
       "      <td>-31.722,-29.3722,24.2607,20.2583</td>\n",
       "      <td>-3.1829,-7.04291,-62.8616,-25.9997</td>\n",
       "      <td>1,-1,1,-1</td>\n",
       "      <td>0.0240287,0.00756904,0.129509,0.0101338</td>\n",
       "      <td>0.00150606,0.000130401,0.00381629,0.0155896</td>\n",
       "      <td>0.00356076,-0.000555184,0.000691515,0.00287596</td>\n",
       "      <td>1.01486,0.234018,0.652992,2.33123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        run    event  luminosity_section                 electron_energy  \\\n",
       "0  200519.0  1002510                3343  55.0788,41.0337,71.266,40.9315   \n",
       "\n",
       "                         electron_px                       electron_py  \\\n",
       "0  -44.9139,27.7747,-23.2093,24.2694  -31.722,-29.3722,24.2607,20.2583   \n",
       "\n",
       "                          electron_pz electron_charge  \\\n",
       "0  -3.1829,-7.04291,-62.8616,-25.9997       1,-1,1,-1   \n",
       "\n",
       "                         electron_relPFIso  \\\n",
       "0  0.0240287,0.00756904,0.129509,0.0101338   \n",
       "\n",
       "                                  electron_dxy  \\\n",
       "0  0.00150606,0.000130401,0.00381629,0.0155896   \n",
       "\n",
       "                                      electron_dz  \\\n",
       "0  0.00356076,-0.000555184,0.000691515,0.00287596   \n",
       "\n",
       "                      electron_SIP3d  \n",
       "0  1.01486,0.234018,0.652992,2.33123  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkgnd_sim_4el.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no entries for electron as there are only muons present in the dataset. Normally this could mean that we can no longer use the entire analysis. However with the funcitonal approach it is possible to add a `map` function that simply adds empty strings for all electron entries. We will have to do the same for the muons in `bkgnd_sim_4el`but after that we have added empty strings we should have data structures that again fit the requirements that are placed at the data by the first filter of our already existing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_electron_entries_to_raw_data(event):\n",
    "    data = event[1]\n",
    "    data['electron_energy'] = ''\n",
    "    data['electron_px'] = ''\n",
    "    data['electron_py'] = ''\n",
    "    data['electron_pz'] = ''\n",
    "    data['electron_charge'] = ''\n",
    "    data['electron_relPFIso'] = ''\n",
    "    data['electron_dxy'] = ''\n",
    "    data['electron_dz'] = ''\n",
    "    data['electron_SIP3d'] = ''\n",
    "    return event\n",
    "\n",
    "\n",
    "def add_muon_entries_to_raw_data(event):\n",
    "    data = event[1]\n",
    "    data['muon_energy'] = ''\n",
    "    data['muon_px'] =  ''\n",
    "    data['muon_py'] = ''\n",
    "    data['muon_pz'] = ''\n",
    "    data['muon_charge'] = ''\n",
    "    data['muon_relPFIso'] = ''\n",
    "    data['muon_dxy'] = ''\n",
    "    data['muon_dz'] = ''\n",
    "    data['muon_SIP3d'] = ''\n",
    "    return event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two functions defined we should be able to first pass the raw data of `bkgnd_sim_4mu` through `add_electron_entries_to_raw_data` and then into our allready existing pipeline. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4mu_3, c4el_3, c2el2mu_3 = read_in_reformat_split_and_filter_into_channels(\n",
    "                              map(add_electron_entries_to_raw_data, bkgnd_sim_4mu.head(10000).iterrows()),\n",
    "                              muon_pt_min,\n",
    "                              muon_max_eta,\n",
    "                              electron_pt_min,\n",
    "                              electron_max_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7524\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(list(c4mu_3)))\n",
    "print(len(list(c4el_3)))\n",
    "print(len(list(c2el2mu_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it worked. That means that if we have a new data source we can simply write an adaptor for that data source and continue to use our initial data pipeline. How neat.\n",
    "\n",
    "So just to prove that it works here the whole thing again just this time for the simulated electron background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "7533\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "c4mu_4, c4el_4, c2el2mu_4 = read_in_reformat_split_and_filter_into_channels(\n",
    "                                map(add_muon_entries_to_raw_data, bkgnd_sim_4el.head(10000).iterrows()),\n",
    "                                muon_pt_min,\n",
    "                                muon_max_eta,\n",
    "                                electron_pt_min,\n",
    "                                electron_max_eta)\n",
    "\n",
    "print(len(list(c4mu_4)))\n",
    "print(len(list(c4el_4)))\n",
    "print(len(list(c2el2mu_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "---\n",
    "Now the last essential functionality that we want to have as physicists is the plotting of various quantities. Preferably before and after a filter step. This allows us to quickly verify that the program actually did what it was supposed to and gives us a bit of a 'feel' for our data. This will be implemented as a filter that only selects the data that we want to plot and possibly a mapping to bring the filtered data into a shape that is useful for plotting. Then all that is needed to be done is to assemble everything in a `list` and then we can plot the quantity(ies) of interest. So let's implement a simple hist for a quantity of the leptons in each event.\n",
    "\n",
    "The extraction of the leptons is such a simple task that it can easily be done with a `lambda` function. The next problem is that for every event we can have multiple leptons. Thankfully the [itertools](https://docs.python.org/3/library/itertools.html) library is here to help with the [`chain.from_iterable`](https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable) function. (The name of the function is a link you can use to have a quick look at what it does)\n",
    "\n",
    "The cool thing is that most of the work has actually allready beed done. The last step is to extract one or more quantities from every lepton. For this we need a function that can be used with the `map` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vals_from_lepton(lepton, keys):\n",
    "    return [lepton[key] for key in keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `keys` argument has to be a list of keys (in this case the names of the values that we want to have as strings) that can be used with the lepton. We will need to wrap this function in a `lambda`, but by now you should be used to that. We also get a problem when we get an empty array (which happened to me when I was writing this, which is why I know this (the magic of hindsight). As we now have empty arrays in our stream we have to deal with them. We can do this simply by filtering out all arrays of length 0 in a filter that we amend to it.\n",
    "\n",
    "All in all we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_plot_data_for_leptons(events, plot_keys):\n",
    "    plotable_quantities = map(lambda l: extract_vals_from_lepton(l, plot_keys),\n",
    "                              itt.chain.from_iterable(\n",
    "                                  map(lambda e: e[1]['leptons'], events)))\n",
    "    return zip(*list(plotable_quantities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think about matplotlibs `hist` function it expects an array with all values belonging to the same quantity. However we have lot's of arrays with one member of each value. We have to produce one array per key in `plot_keys` and that is exactly what `zip` does (I had asked you to read up on it earlier but here it is just in case). However `zil` does not take an iterator as an argument but a list. So we have to turn the iterator into a list.\n",
    "\n",
    "Now that we have defined how we want our arrays, we can subject the code above to a prelimiary test. I'll take the pipeline up to the point where the leptons are filtered for $p_T$ and $\\eta$ and plot $p_T$ and $\\eta$ before and after the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to build the pipeline up to this point.\n",
    "data_from_pipeline_up_to_lepton_filter =  map(calc_pseudorapidity,\n",
    "                                              map(calc_pt,\n",
    "                                                  read_in_and_reformat(bkgnd_sim_2el2mu.head(10000).iterrows())))\n",
    "\n",
    "# now we have to split of one stream that we will run through the filter and generate our plot data from\n",
    "main_stream, unfiltered_plot_stream = itt.tee(data_from_pipeline_up_to_lepton_filter)\n",
    "\n",
    "# filter the leptons from our main stream\n",
    "filtered_stream = filter_out_unfit_leptons(main_stream, muon_pt_min, muon_max_eta, electron_pt_min, electron_max_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from the unfiltered and filtered stream (also actually run the iterators and turn them into lists)\n",
    "unfiltered_lepton_plot_arrays = list(extract_plot_data_for_leptons(unfiltered_plot_stream, ['pt', 'eta']))\n",
    "filtered_lepton_plot_arrays = list(extract_plot_data_for_leptons(filtered_stream, ['pt', 'eta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 41592\n"
     ]
    }
   ],
   "source": [
    "print(len(unfiltered_lepton_plot_arrays), len(unfiltered_lepton_plot_arrays[0]))\n",
    "# the shape of the resulting unfiltered data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 37420\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_lepton_plot_arrays), len(filtered_lepton_plot_arrays[0]))\n",
    "# shape of the resulting filtered data set, now we only need to plot it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see the amount of leptons that existed before the filter where about 40k and that would make about 4 leptons per event at 10000 events so that is good. After we apply the filter we can see that the amount of leptons has decreased even though not by much. Now all that is left is to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0, 20))\n",
    "hist, bins, bars = ax.hist(unfiltered_lepton_plot_arrays[0], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim((0, 20))\n",
    "hist, bins, p = plt.hist(filtered_lepton_plot_arrays[0], 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code that I have not yet incorporated and that is left over from a previous version of the script\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_charge_criteria(charges, num_of_leptons_considered):\n",
    "    \"\"\"function checks if a neutral charge combination can be built from a (sub)set of leptons with length\n",
    "    num_of_leptons_considered (! the sequence of leptons in the event does not matter !)\"\"\"\n",
    "    charges = sorted(charges)\n",
    "    charge_count = len(charges)\n",
    "    window_size = num_of_leptons_considered if charge_count > num_of_leptons_considered else charge_count\n",
    "    combinations_considered = charge_count - window_size + 1\n",
    "    for i in range(combinations_considered):\n",
    "        if sum(charges[i:i+window_size]) == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# this is effectively a wrapper function as discussed above\n",
    "def combined_charge(event, num_of_leptons):\n",
    "    charges = [lepton['charge'] for lepton in event[1]['leptons']]\n",
    "    return combined_charge_criteria(charges, num_of_leptons)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_pt_in_event(pt):\n",
    "    \"\"\"applies strict pt requirements to the leptons\"\"\"\n",
    "    pt = sorted(pt)\n",
    "    if pt[-1] < 20:\n",
    "        return False\n",
    "    if pt[-2] < 10:\n",
    "        return False\n",
    "    for momentum in pt[:-2]:\n",
    "        if momentum < 4:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def lepton_type(lepton, lepton_type):\n",
    "    \"\"\"filter function for lepton type\n",
    "    \n",
    "    this function is to be used as argument to the filter method\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lepton : dict\n",
    "        the dict with all the properties of the lepton, at least however\n",
    "        a 'type' entry that can take on one of the values in lepton_type\n",
    "    lepton_type : list or object\n",
    "        the types of leptons that the filter accepts the filter accepts a\n",
    "        lepton if the 'type' field of the lepton matches one of the objects\n",
    "        in the lepton_type list or the lepton_type object if lepton_type is\n",
    "        not a list\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(lepton_type, (list, np.ndarray)):\n",
    "        return True if lepton['type'] in lepton_type else False\n",
    "    else:\n",
    "        return True if lepton['type'] == lepton_type else False\n",
    "\n",
    "    \n",
    "def strict_pt_of_lepton_type(event, ltype):\n",
    "    leptons = event[1]['leptons']\n",
    "    leptons_of_specified_type = filter(lambda l: lepton_type(l, ltype), leptons)\n",
    "    return strict_pt_in_event([lepton['pt'] for lepton in leptons_of_specified_type])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last two code blocks a few rather complicated things happened in the code. As everything strange that happens `combined_charge_criteria` and `combined_charge` also happens in `strict_pt_in_event`, `lepton_type` and `strict_pt_of_lepton_type` I'll only go through the last three functions and leave it to you as excercise to figure out how the first two work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandelstam_s(fourvectors):\n",
    "    vec = np.add.reduce(fourvectors)\n",
    "    minkovski_metric = np.diag(1, -1, -1, -1)\n",
    "    return vec @ (minkovski_metric @ vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
